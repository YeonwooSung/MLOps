{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2.7_Classification_and_Regression.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP5BxX94CnKmHGRlTcMcwZb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexander-n-thomas/spark-nlp-book-prod/blob/master/2_7_Classification_and_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4zpDO5R1ox4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "6a941bbb-15d1-424c-e909-781d89643a90"
      },
      "source": [
        "import os\n",
        "\n",
        "# Install java\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "! java -version\n",
        "\n",
        "# Install pyspark\n",
        "! pip install --ignore-installed pyspark==2.4.4\n",
        "\n",
        "# Install Spark NLP\n",
        "! pip install --ignore-installed spark-nlp==2.5.1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"1.8.0_252\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_252-8u252-b09-1~18.04-b09)\n",
            "OpenJDK 64-Bit Server VM (build 25.252-b09, mixed mode)\n",
            "Collecting pyspark==2.4.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/21/f05c186f4ddb01d15d0ddc36ef4b7e3cedbeb6412274a41f26b55a650ee5/pyspark-2.4.4.tar.gz (215.7MB)\n",
            "\u001b[K     |████████████████████████████████| 215.7MB 61kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 54.7MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.4-py2.py3-none-any.whl size=216130388 sha256=784345438dcfa4cb75d871b2639d6f5131887a85f7349975accc7df6841e67c7\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.4\n",
            "Collecting spark-nlp==2.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/b4/db653f8080a446de8ce981b262d85c85c61de7e920930726da0d1c6b4c65/spark_nlp-2.5.1-py2.py3-none-any.whl (121kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 7.9MB/s \n",
            "\u001b[?25hInstalling collected packages: spark-nlp\n",
            "Successfully installed spark-nlp-2.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzgTx-7OuEnm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! mkdir -p data"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgBCSO9Fr-M5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "847728dd-8a8c-49ab-d16c-d15384c9774a"
      },
      "source": [
        "! wget https://archive.ics.uci.edu/ml/machine-learning-databases/20newsgroups-mld/mini_newsgroups.tar.gz"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-23 21:12:40--  https://archive.ics.uci.edu/ml/machine-learning-databases/20newsgroups-mld/mini_newsgroups.tar.gz\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1860687 (1.8M) [application/x-httpd-php]\n",
            "Saving to: ‘mini_newsgroups.tar.gz’\n",
            "\n",
            "mini_newsgroups.tar 100%[===================>]   1.77M  1.85MB/s    in 1.0s    \n",
            "\n",
            "2020-07-23 21:12:42 (1.85 MB/s) - ‘mini_newsgroups.tar.gz’ saved [1860687/1860687]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiqkXr6SITVJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! tar xzf mini_newsgroups.tar.gz -C ./data/"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Yv3HA3EhHj2",
        "colab_type": "text"
      },
      "source": [
        "# Classification and Regression\n",
        "\n",
        "The most common machine learning tasks performed on documents are classification and regression. From determining insurance billing codes for a clinical note (classification) to predicting the popularity of a social media post (regression), most document-level machine learning tasks fall into one of these categories, with classification being the much more common of the two.\n",
        "\n",
        "When beginning a machine learning task, it is very informative to try and manually label some documents, even if there are already labels in the data set. This will help you understand what content in the language of the documents can be used in your task. When labeling, note what you look for. For example, particular words or phrases, certain sections of the document, and even document length can be useful.\n",
        "\n",
        "In a chapter about classification and regression, you might expect most of the discussion to be about different modeling algorithms. With NLP, most of the work is in the featurization. Many of the general techniques for improving models will work with NLP, assuming you have created good features. We will go over some of the considerations for tuning modeling algorithms, but most of this chapter focuses on how to featurize text for classification and regression.\n",
        "\n",
        "We'll discuss the bag-of-words approach, regular expression-based features, and feature selection. After this, we will talk about how to iterate when building a model on text data.\n",
        "\n",
        "Let's load and process the mini_newsgroups data, so we can see examples of how to create these features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJz1_iZVhNyK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import expr\n",
        "from pyspark.sql import Row\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "import sparknlp\n",
        "from sparknlp import DocumentAssembler, Finisher\n",
        "from sparknlp.annotator import *\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "spark = sparknlp.start()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2UPKkIzhISs",
        "colab_type": "text"
      },
      "source": [
        "We will build a classifier to identify which newsgroup a document is from. The newsgroup is mentioned in the header of the documents, so let's remove those to be more sporting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyv9B7AxhReD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HEADER_PTN = re.compile(r'^[a-zA-Z-]+:.*')\n",
        "\n",
        "def remove_header(path_text_pair):\n",
        "    path, text = path_text_pair\n",
        "    lines = text.split('\\n')\n",
        "    line_iterator = iter(lines)\n",
        "    while HEADER_PTN.match(next(line_iterator)) is not None:\n",
        "        pass\n",
        "    return path, '\\n'.join(line_iterator)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlLEoHJLhSxU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = os.path.join('data', 'mini_newsgroups', '*')\n",
        "texts = spark.sparkContext.wholeTextFiles(path).map(remove_header)\n",
        "\n",
        "schema = StructType([\n",
        "    StructField('path', StringType()),\n",
        "    StructField('text', StringType()),\n",
        "])\n",
        "\n",
        "texts = spark.createDataFrame(texts, schema=schema) \\\n",
        "    .withColumn('newsgroup', expr('split(path, \"/\")[4]')) \\\n",
        "    .persist()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBbw6wFVhT-T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "e1979c67-8b1c-4192-e4bd-5ff7317556eb"
      },
      "source": [
        "texts.groupBy('newsgroup').count().collect()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(newsgroup='comp.windows.x', count=100),\n",
              " Row(newsgroup='misc.forsale', count=100),\n",
              " Row(newsgroup='rec.sport.hockey', count=100),\n",
              " Row(newsgroup='rec.sport.baseball', count=100),\n",
              " Row(newsgroup='talk.politics.guns', count=100),\n",
              " Row(newsgroup='talk.politics.misc', count=100),\n",
              " Row(newsgroup='comp.os.ms-windows.misc', count=100),\n",
              " Row(newsgroup='comp.sys.ibm.pc.hardware', count=100),\n",
              " Row(newsgroup='comp.graphics', count=100),\n",
              " Row(newsgroup='soc.religion.christian', count=100),\n",
              " Row(newsgroup='comp.sys.mac.hardware', count=100),\n",
              " Row(newsgroup='talk.religion.misc', count=100),\n",
              " Row(newsgroup='talk.politics.mideast', count=100),\n",
              " Row(newsgroup='rec.motorcycles', count=100),\n",
              " Row(newsgroup='rec.autos', count=100),\n",
              " Row(newsgroup='alt.atheism', count=100),\n",
              " Row(newsgroup='sci.electronics', count=100),\n",
              " Row(newsgroup='sci.space', count=100),\n",
              " Row(newsgroup='sci.med', count=100),\n",
              " Row(newsgroup='sci.crypt', count=100)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAVRBPgyhVmi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bf5b2588-2546-4802-c76c-a7713d1c8b97"
      },
      "source": [
        "print(texts.first()['path'])\n",
        "print(texts.first()['newsgroup'])\n",
        "print(texts.first()['text'])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "file:/content/data/mini_newsgroups/rec.sport.hockey/53625\n",
            "rec.sport.hockey\n",
            "In article <vzhivov.735059801@cunews>, vzhivov@superior.carleton.ca (Vladimir\n",
            "Zhivov) says:\n",
            ">\n",
            ">In <93107.091503RAP115@psuvm.psu.edu> Robbie Po <RAP115@psuvm.psu.edu> writes:\n",
            ">\n",
            ">>2-Red Wings vs. 3-Maple Leafs               Maple Leafs in 6\n",
            ">\n",
            ">>  Comment : It's kind of tough to rely on Yzerman as the team's main weapon.\n",
            ">>            He's a great palyer, but Dino knows all about choking, which\n",
            ">>            puts the burden on Steve even more.  Potvin's had a hell of a\n",
            ">>            season and goaltending is what you need in the playoffs.\n",
            ">\n",
            ">For a great prognosticator:), you seem to remember very little playoff\n",
            ">history. Dino always shows up in the playoffs, which is why he is a\n",
            ">great \"sleeper\" pick in pools. Don't forget about Fedorov, one of the\n",
            ">top players in the NHL, IMHO, and Coffey who has the most Stanley Cup\n",
            ">rings of any active players (correct me if I'm wrong). Wings in a\n",
            ">cakewalk.\n",
            "\n",
            "Oh yeah, how come Dino could never take the Caps out of the Patrick\n",
            "Division?  He choked up 3 games to 1 last year and got swept away in\n",
            "the second round two years ago.  He rarely, if ever, makes it out of the\n",
            "division.\n",
            "\n",
            ">>1-Canucks vs. 4-Jets                        Canucks in 5\n",
            ">\n",
            ">>  Comment : It's more like Vancouver vs. Selanne.  King and Domi (for\n",
            ">>            enforcing) help Winnipeg out a little, maybe a game.  Canucks\n",
            ">>            have their number.\n",
            ">\n",
            ">Except that the Canuck are playing like shit. Winnipeg can win this\n",
            ">one, though I think Vancouver will manage to slip by.\n",
            "\n",
            "So are the Islanders, but they can still pull it out.  Vancouver has Winnipeg's\n",
            " number, so it really doesn't matter.\n",
            "\n",
            ">>2-Flames vs. 3-Kings                        Flames in 7\n",
            ">\n",
            ">>  Comment : 7 games looks good as the Kings always seem to battle it out.\n",
            ">>            Flames are back in running and won't know memories of last year's\n",
            ">>            season.  Gretzky is on a tear, but there are too many ?????\n",
            ">>            surrounding the Kings.\n",
            "\n",
            ">Kings \"always seem to battle it out\"? When? Where?\n",
            "\n",
            " Kings always seem to go at least 6 or 7, they never play a four or five\n",
            "game serious.  There's a difference between battling it out and pulling it\n",
            "out, as I take Calgary to pull it out in 7.\n",
            "-------------------------------------------------------------------------\n",
            "** Robbie Po **          PGH PENGUINS!!!    \"We do what comes naturally!\n",
            "Patrick Division Semi's  '91 STANLEY CUP    You see now, wait for the\n",
            "PENGUINS 6, Devils 3     '92 CHAMPIONS      possibility, don't you see a\n",
            "Penguins lead, 1-0       12 STRAIGHT WINS!  strong resemblance...\"-DG '89\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOSfDDzfhW7Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "1d7fd886-81d1-423b-c36f-f092fd709fa2"
      },
      "source": [
        "assembler = DocumentAssembler()\\\n",
        "    .setInputCol('text')\\\n",
        "    .setOutputCol('document')\n",
        "sentence = SentenceDetector() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"sentences\")\n",
        "tokenizer = Tokenizer()\\\n",
        "    .setInputCols(['sentences'])\\\n",
        "    .setOutputCol('token')\n",
        "lemmatizer = LemmatizerModel.pretrained()\\\n",
        "    .setInputCols(['token'])\\\n",
        "    .setOutputCol('lemma')\n",
        "normalizer = Normalizer()\\\n",
        "    .setCleanupPatterns([\n",
        "        '[^a-zA-Z.-]+', \n",
        "        '^[^a-zA-Z]+', \n",
        "        '[^a-zA-Z]+$',\n",
        "    ])\\\n",
        "    .setInputCols(['lemma'])\\\n",
        "    .setOutputCol('normalized')\\\n",
        "    .setLowercase(True)\n",
        "finisher = Finisher()\\\n",
        "    .setInputCols(['normalized'])\\\n",
        "    .setOutputCols(['normalized'])\\\n",
        "    .setOutputAsArray(True)\n",
        "pipeline = Pipeline().setStages([\n",
        "    assembler, sentence, tokenizer, \n",
        "    lemmatizer, normalizer, finisher\n",
        "]).fit(texts)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lemma_antbnc download started this may take some time.\n",
            "Approximate size to download 907.6 KB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jf3ORzNehjjq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processed = pipeline.transform(texts).persist()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXN8IV0zhkvK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc356533-8345-425d-b409-f5b7db4cba44"
      },
      "source": [
        "print(processed.count()) # number of documents"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ISNcRZIhInM",
        "colab_type": "text"
      },
      "source": [
        "## Bag-of-Words Features\n",
        "\n",
        "In the previous chapter we discussed document vectors built with TF.IDF. These features are the most common kinds of features used in document classification and regression. There is some difficulty in using features like this, however. Depending on the size of your corpus, you could potentially have more than a hundred thousand features, where any example will have only a few hundred to a few thousand nonzero features. This can be handled by creating a sparse representation of your feature matrix, where 0 values are omitted. However, not all training algorithms support sparse matrices. This is where the vocabulary reduction techniques we discussed in #processing_words become important.\n",
        "\n",
        "\n",
        "If you have already reduced your vocabulary, but you still need to reduce the number of your features, it is time to consider using a restricted vocabulary. For example, when working with clinical data, it might be best to restrict your vocabulary to medical terminology. This can be done by using external resources like the Unified Medical Language Service (UMLS). If you are working in other domains, consider curating a wordlist. Curated vocabularies can be a filter for your features. There are some pros and cons to such vocabularies, though. They are not biased by the information in your data set, so they will not contribute to overfitting. Conversely, there may be features that are unlikely to show up in a generalized curated list that are genuinely useful. This is why it is important for you to label some examples during iterations of your model building. If you have filtered your vocabulary, you can sample the erroneously classified examples for additions to your vocabulary.\n",
        "\n",
        "The extension of this manual feature selection is trying to combine parts of the vocabulary into a smaller set of features. This can be done with regular expressions.\n",
        "\n",
        "Let's look at an example of bag-of-words in Spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sGRTpfmhquS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import CountVectorizer, IDF\n",
        "\n",
        "count_vectorizer = CountVectorizer(\n",
        "    inputCol='normalized', outputCol='tf', minDF=10)\n",
        "idf = IDF(inputCol='tf', outputCol='tfidf', minDocFreq=10)\n",
        "\n",
        "bow_pipeline = Pipeline(stages=[count_vectorizer, idf])\n",
        "bow_pipeline = bow_pipeline.fit(processed)\n",
        "\n",
        "bows = bow_pipeline.transform(processed)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ygu8APlhsJ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "126d046a-986b-4ebf-e65a-96fbde58f08a"
      },
      "source": [
        "bows.limit(5).toPandas()[['tf', 'tfidf']]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tf</th>\n",
              "      <th>tfidf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(16.0, 8.0, 8.0, 7.0, 12.0, 6.0, 3.0, 13.0, 1....</td>\n",
              "      <td>(1.1691290860237853, 0.7321541874305568, 1.053...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(30.0, 10.0, 3.0, 4.0, 10.0, 4.0, 8.0, 10.0, 4...</td>\n",
              "      <td>(2.192117036294597, 0.915192734288196, 0.39524...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(4.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, ...</td>\n",
              "      <td>(0.2922822715059463, 0.0915192734288196, 0.131...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(13.0, 6.0, 4.0, 10.0, 2.0, 3.0, 7.0, 4.0, 3.0...</td>\n",
              "      <td>(0.9499173823943255, 0.5491156405729176, 0.526...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(5.0, 9.0, 4.0, 7.0, 3.0, 3.0, 2.0, 3.0, 3.0, ...</td>\n",
              "      <td>(0.3653528393824329, 0.8236734608593764, 0.526...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  tf                                              tfidf\n",
              "0  (16.0, 8.0, 8.0, 7.0, 12.0, 6.0, 3.0, 13.0, 1....  (1.1691290860237853, 0.7321541874305568, 1.053...\n",
              "1  (30.0, 10.0, 3.0, 4.0, 10.0, 4.0, 8.0, 10.0, 4...  (2.192117036294597, 0.915192734288196, 0.39524...\n",
              "2  (4.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, ...  (0.2922822715059463, 0.0915192734288196, 0.131...\n",
              "3  (13.0, 6.0, 4.0, 10.0, 2.0, 3.0, 7.0, 4.0, 3.0...  (0.9499173823943255, 0.5491156405729176, 0.526...\n",
              "4  (5.0, 9.0, 4.0, 7.0, 3.0, 3.0, 2.0, 3.0, 3.0, ...  (0.3653528393824329, 0.8236734608593764, 0.526..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJ67tFtBhI5C",
        "colab_type": "text"
      },
      "source": [
        "## Regular Expression Features\n",
        "\n",
        "Let's say you are trying to separate short stories into genres. For this example, we have only three genres in our corpus: science fiction, fantasy, and horror. We can create specific features to help us classify. If we have word lists, we can combine them into a single feature. There are a couple of ways to do this.\n",
        "\n",
        "* Use bag-of-words features and create a feature that is the result of aggregating the TF.IDF values of the features with sum or max.\n",
        "* Create a new feature by creating a new token. You can preprocess the documents, adding a tag to any document that contains a word from the vocabulary. You can then calculate TF.IDF for this tag.\n",
        "\n",
        "We can add other kinds of features. For example, it is common in science fiction to refer to rare and fictional minerals—for example, dilithium (both a real substance and a fictional mineral in Star Trek) and adamantium (a fictional alloy in Marvel comics). We could create a regular expression that looks for the common endings to these minerals.\n",
        "\n",
        "* `(lith|ant|an)ium`\n",
        "\n",
        "Discovering which of these features will help us classify is a task on which the data scientist and the domain expert should collaborate. The data scientist can find features that are potentially helpful to the model. The domain expert can identify which features are actually related to the problem and which are spuriously correlated with the target variable.\n",
        "\n",
        "These features are useful for a first version of a model, but they have some serious drawbacks. If you wish to build a similar model on text in another language, it is very likely that you will not be able to reuse regular expression features.\n",
        "\n",
        "Let's use the RegexMatcher from Spark NLP for finding matches in the text of the document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1CHhgQGh6SK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "60e0efd7-70dd-4a7d-de6f-53585a6b33fc"
      },
      "source": [
        "%%writefile scifi_rules.tsv\n",
        "\\w+(lith|ant|an)ium,mineral\n",
        "(alien|cosmic|quantum|dimension(al)?),space_word"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing scifi_rules.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJrj7137h706",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "regex_matcher = RegexMatcher() \\\n",
        "    .setOutputCol(\"regex\") \\\n",
        "    .setExternalRules('./scifi_rules.tsv', ',')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vzho1vrIhJDB",
        "colab_type": "text"
      },
      "source": [
        "Because the RegexMatcher works on the raw text, it does not need the other stages. Normally, you would extract the regex matches along with other text-based features. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kISRqnDyh-dX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "regex_finisher = Finisher()\\\n",
        "    .setInputCols(['regex'])\\\n",
        "    .setOutputCols(['regex'])\\\n",
        "    .setOutputAsArray(True)\n",
        "\n",
        "regex_rule_pipeline = Pipeline().setStages([\n",
        "    assembler, regex_matcher, regex_finisher\n",
        "]).fit(texts)\n",
        "\n",
        "regex_matches = regex_rule_pipeline.transform(texts)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz_Oefa1h_oS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "de8767b3-26fe-4ffe-9c36-e918d2589178"
      },
      "source": [
        "regex_matches.orderBy(expr('size(regex)').desc())\\\n",
        "    .limit(5).toPandas()[['newsgroup', 'regex']]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>newsgroup</th>\n",
              "      <th>regex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>None</td>\n",
              "      <td>[alien, alien, alien, alien, alien, alien, alien]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>None</td>\n",
              "      <td>[dimensional, dimension, dimensional, dimension]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>None</td>\n",
              "      <td>[cosmic, cosmic, cosmic]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>None</td>\n",
              "      <td>[dimensional, alien, dimensional]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>None</td>\n",
              "      <td>[quantum, quantum, cosmic]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  newsgroup                                              regex\n",
              "0      None  [alien, alien, alien, alien, alien, alien, alien]\n",
              "1      None   [dimensional, dimension, dimensional, dimension]\n",
              "2      None                           [cosmic, cosmic, cosmic]\n",
              "3      None                  [dimensional, alien, dimensional]\n",
              "4      None                         [quantum, quantum, cosmic]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYWyJznOhJKq",
        "colab_type": "text"
      },
      "source": [
        "There are a few ways in which these can be turned into features. You can create binary features—in other words, the value is 1 if any of the regexes match. You can also use the number of matches as a feature.\n",
        "\n",
        "Now that we have introduced two of the most common classic NLP features, let's talk about how we reduce our dimensions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RY6MxPaMhJRF",
        "colab_type": "text"
      },
      "source": [
        "## Feature Selection\n",
        "  Once you have determined a set of features, often a mix of bag-of-words and regular expressions, you may find that you have a very high dimensional feature space. This will depend very much on the sort of language used in the corpus. In highly technical corpora, it is not uncommon to have more features than examples. If you look at the distribution, you will see that they are distributed by a power law.\n",
        "\n",
        "We can use the Spark `StopWordsRemover` to remove words like \"the\" and \"of,\" like we discussed in \"Information Retrieval\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-qhQ6fYiKVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import StopWordsRemover\n",
        "\n",
        "sw_remover = StopWordsRemover() \\\n",
        "    .setInputCol(\"normalized\") \\\n",
        "    .setOutputCol(\"filtered\") \\\n",
        "    .setStopWords(StopWordsRemover.loadDefaultStopWords(\"english\"))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyTJDv7zhJYX",
        "colab_type": "text"
      },
      "source": [
        "Finally, we turn this into a pipeline. It is important to include your text processing steps in your pipeline. This will let you explore hyperparameters of your machine learning model alongside NLP parameters. This gets more important the more complex your NLP preprocessing becomes. We will also include our bag-of-words stages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ac8IPgjiOP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_vectorizer = CountVectorizer(inputCol='filtered', \n",
        "    outputCol='tf', minDF=10)\n",
        "idf = IDF(inputCol='tf', outputCol='tfidf', minDocFreq=10)\n",
        "\n",
        "pipeline = Pipeline() \\\n",
        "    .setStages([\n",
        "        assembler, \n",
        "        sentence, \n",
        "        tokenizer, \n",
        "        lemmatizer, \n",
        "        normalizer, \n",
        "        finisher, \n",
        "        sw_remover,\n",
        "        count_vectorizer,\n",
        "        idf\n",
        "    ]) \\\n",
        "    .fit(texts)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPfqDbb9hJi7",
        "colab_type": "text"
      },
      "source": [
        "Now that we have our pipeline constructed, we transform our texts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WF4jMVqwiQop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = pipeline.transform(texts).persist()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRJCypvViRyc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "e990f411-b97a-4de7-fdb8-cf2d28d2c08c"
      },
      "source": [
        "features.printSchema()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- path: string (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            " |-- newsgroup: string (nullable = true)\n",
            " |-- normalized: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- filtered: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- tf: vector (nullable = true)\n",
            " |-- tfidf: vector (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJboKG4qhJft",
        "colab_type": "text"
      },
      "source": [
        "In Spark MLlib, the features are stored in a single vector-valued column. This is much more efficient than creating a column for each of the features, but it does make interacting with the data more complicated. To deal with this, we will be pulling the data into a pandas DataFrame. We can do this because our data is small and can fit in memory. This would not work on a larger data set.\n",
        "\n",
        "Now that we have a fitted `CountVectorizerModel`, we can look at the vocabulary it found. The words are sorted by document frequency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sa0J0KOeiXRT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "f9f809a2-eecf-4e63-9a3d-65adb5c8cbce"
      },
      "source": [
        "pipeline.stages"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[DocumentAssembler_13e26bdc1088,\n",
              " SentenceDetector_c4c7a603f2f8,\n",
              " REGEX_TOKENIZER_a6cf775762ec,\n",
              " LEMMATIZER_c62ad8f355f9,\n",
              " NORMALIZER_f52a4d9c95a5,\n",
              " Finisher_2bb2afd5d7bf,\n",
              " StopWordsRemover_9f668759275c,\n",
              " CountVectorizer_d85757be7a2f,\n",
              " IDF_3dd8820dcd44]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqIs6dUIiZDx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv_model = pipeline.stages[-2]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4C_iztyiaKi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "37be1e3c-4281-4519-ef1a-c4d25cf53c7b"
      },
      "source": [
        "len(cv_model.vocabulary)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3033"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cyOa2jahJUm",
        "colab_type": "text"
      },
      "source": [
        "This is a modest vocabulary size. We will see larger sizes when we get to \"Applications\" part of this book.\n",
        "\n",
        "Let's look at our top 10 words by document frequency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSSR9gqZiiOo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8e95651f-c95b-4818-cb62-f6e030a4d460"
      },
      "source": [
        "cv_model.vocabulary[:10]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['write', 'one', 'use', 'get', 'article', 'say', 'know', 'x', 'make', 'dont']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8SGkw35hJN1",
        "colab_type": "text"
      },
      "source": [
        "Let's look at the distribution of mean term frequency. We will create a histogram of mean term frequency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnF68CUMimXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf = features.select('tf').toPandas()\n",
        "tf = tf['tf'].apply(lambda sv: sv.toArray())\n",
        "mean_tf = pd.Series(tf.mean(), index=cv_model.vocabulary)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZU-WPA_inWy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "outputId": "f80d58ca-5b91-4e7e-f7d1-dbb0c3c34f2a"
      },
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "mean_tf.hist(bins=10)\n",
        "plt.title('Histogram of mean term frequency per word over the corpus')\n",
        "plt.show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAswAAAHiCAYAAAD8n5rBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dfbhkV10n+u+PNERIeAkEe/IGjdxmxkTmAvZAHJzxIAIh6gSuIyTDSxoj8QVUNKNEriMIMhOvgqN3HCRIhjchRBTpIXFyY+SQQQgmaAQSYNKSxs4LiZAEaKJohnX/2PuEyrHOOpXu03VOuj+f56mna6+9aq+1d62u861da1dVay0AAMB091nvDgAAwEYmMAMAQIfADAAAHQIzAAB0CMwAANAhMAMAQIfADB1VdXVVLax3P9ZTVT27qnZX1Z6qevx69+fepKp+uaq+UFWfX+++sHeqaqGqrl/vfsyiqt5SVb+83v2AA5HAzEGrqnZV1fcsK9teVR9aWm6tndBaW1xlO1uqqlXVpv3U1fX2a0le2lo7vLX2F+vdmVlNe37n3P4jkpyV5PjW2j9Zr35wYFr+WgXsXwIzbHAbIIg/MsnV69yHuarBvr4+PiLJF1trt6zQxno/r/ca8zpWG/U52aj9Ws29td8wjcAMHZNnKavqiVV1ZVV9uapurqrXj9UuG/+9fZy28B1VdZ+q+oWq+lxV3VJVb6uqB09s94Xjui9W1X9Y1s6rquo9VfWOqvpyku1j2x+pqtur6qaq+i9Vdb+J7bWq+vGquraqvlJVr6mqR1fVh8f+XjBZf9k+Tu1rVR1aVXuSHJLkL6vqr1Z4/D1qu6q+r6quGvflw1X1zyfWnV1VfzVu55qqevbEuu1V9aGq+rWquq2qrquqZ67Qp7dnCKz/fXxOfm4sP3Fs8/aq+svJ6TZVtVhVr62qP01yR5Jv2dvjOj6XlyQ5emz/LROfRJxRVX+d5E/Guj9UVZ8a9+niqnrkxHaeVlWfrqovjc/5B6vqhyfGyTsm6t7tk47xOXzzOF5uqGF6yCGzHMuqemhV/bequnFc/4dj+Ser6vsn6t23hikn/2iqTo1TGarqFWOdXVX1vIn1h47t/3UN/59+u6ruv+yxL69hOst/m7L9z1XVt4/3nzfu+wnj8hkTfT60qv7zuC83jvcPXamdqrr/+HzdVlXXJPkXU4bYZD/+ZVVdMT5HV1TVvxzLn1tVVy6r+9NVtWNf97+qvjXJbyf5jnF83T6x+oiqunAcrx+tqkdPPO6fVdUlVXVrVX2mqp7T2a+pY2Bc9+Kq2jluZ0dVHT2xrlXVS6rq2iTXTpT9ZFV9dhwLv1rjG9IZxvH28XFfGcfpXWMI5qq15uZ2UN6S7EryPcvKtif50LQ6ST6S5AXj/cOTnDje35KkJdk08bgfSrIzybeMdf8gydvHdccn2ZPkO5PcL8OUh3+YaOdV4/KzMrypvX+Sb09yYpJNY3ufSvKyifZakvcleVCSE5J8LcmlY/sPTnJNktNXOA4r9nVi2/9H5zjO3HaSxye5JcmTMgTx08djfOi4/geTHD3u93OTfDXJURPPzT8kefH42B9LcmOSmuX5TXJMki8mOXnc/tPG5YeP6xeT/PW4D5uS3Hcfj+tCkusnlpfGyduSHDY+r6eMx/5bxzZ/IcmHx/pHJvlKkn879uWnk9yZ5Icnxsk7pmx/07j83iRvHNv65iR/luRHZjmWSS5M8u4kR4xtf9dY/nNJ3j3R5ilJPtHZ/zuTvD7JoUm+a3w+/+m4/teT7Ejy0CQPTPLfk/ynZY/9lfGx95+y/bclOWu8f26Sv0ryYxPrfnq8/+okl4/H4OFJPpzkNSu1k+ScJP9z7NdxST45+Twu68NDk9yW5AXj83fauPywJA8Yn7+tE/WvSHLqGu3/9ky8Vo1lb8kwpp849ud3k5w/rjssye4kLxrXPT7JFzJMGZq2byuNge8eH/eEsW//b5LLlr0eXDLu1/0nyj4wlj0iyf/KDON47POX840xc1SSE/bn3wU3t5Vu694BN7f1umUIVHuS3D5xuyMrB+bLkvxSkiOXbeeuF/iJskuT/PjE8j/NEFA2JfnFJO+aWPeAJH+fuwfmy1bp+8uSvHdiuSV58sTyx5K8fGL5dUn+8wrbWrGvE9teLTDP1HaSN2QMKxPrP7P0x3jKtq9Kcsp4f3uSncuOW0vyTzrP72Rgfnkm3giMZRfnG2F+Mcmr93bfprS/kOmB+Vsmyv4oyRkTy/cZx+Ajk7wwyeUT6yrJ9ZktaGzOEO7vP7H+tCQfWO1YZgglX09yxJR9OjpDCHzQuPyeJD/X2f87kxw2UXZBkv8w7stXkzx6Yt13JLlu4rF/n+SbOuPujCQ7xvufSvLD+UY4/FySJ4z3/yrJyROPe0aSXSu1k+SzSU6aWD4zKwfmFyT5s2VlH0myfbz/jiS/ON7fOh67B6zR/m/P9MD8OxPLJyf59Hj/uUn+57L6b0zyyinb7o2BNyf5fyaWD8/werFl4v/Md0/5fzR5TH88yaUzjOPDMrwu/0CmvGlwc5vnzZQMDnbPaq09ZOmW4YV8JWckeUyST48fvX5fp+7RGf5oL/lcvhFkjs5wpidJ0lq7I8NZoUm7Jxeq6jFV9f6q+nwN0zT+Y4YzkJNunrj/t1OWD9+Lvs5q1rYfmeSsGqZE3D5+lHzc2IelqSpXTaz7ttx9P+/6tonxuKWzX8s9MskPLmv7OzOEgyW7pzxub4/rSibbeGSS35joz60ZwtQx+cfjpK3Qv2kemeGs4E0T235jhrOsS1Y6lsclubW1dtvyjbbWbkzyp0l+oKoekuSZGc5iruS21tpXJ5Y/N+7XwzMEx49N9O9/jOVL/qa19nedbX8wyb+qqqMynCW/IMmTq2pLhrP/V431po3voyeWl7dzt+O+7LHLLd/2Uv1jxvvvzPBGJUn+XZI/HI/1Wuz/Sia/keWO3P3/3pOWjf/nZXiTtNyKYyDL9rm1tifD69cxE3WmjdPlx/ToKXXuZhw7z03yoxnG8oVV9c9WexzsDwIzzKi1dm1r7bQMoeNXkrynqg7LcDZkuRsz/IFa8ogMZ9tuTnJTkmOXVozzFh+2vLlly29I8ukMH+8+KMkrMgSrtdDr61rbneS1k29SWmsPaK29q4a5u29K8tIkDxvfwHwye7+fy4/h7gxnmCfbPqy1dk7nMfvDZBu7M0yTmOzT/VtrH84wTo5bqlhVNbmc4QzlAyaWJ4PP7gxnmI+c2O6DWmsnzNC/3UkeOgbiad6a5PkZps98pLV2Q2dbR4z/R5Y8IsN4+0KGNxsnTPTvwa21yTcf3eeitbYzQyD8iQyfyHw5Q1g8M8OZ16+PVaeN7xs77dztuI/1V7J820v1l47JJUkeXlWPyxCc3zmW7/P+z7B+ud1JPrhsrB3eWvuxFequNAbuts/j8/uwfGOfV+rb8mO69Bz0xnFaaxe31p6W4Y3tpzO8RsDcCcwwo6p6flU9fPxDvHSRzdeT/M3477dMVH9Xkp+uqkdV1eEZzgi/u7V2Z4aPsb9/vFjofhk+klwtFD4ww1y+PeMZlml/5PZWr69r7U1JfrSqnlSDw6rqe6vqgRk+fm0Zjmeq6kUZzjDvrZtz9+fkHRmO+zOq6pCq+qbx4qpjV3j8PPx2kp+vb1ys9uCq+sFx3YVJTqiq/2u8AOonc/cwcVWSf11Vj6jhgtKfX1rRWrspyf+X5HVV9aAaLux8dFV912odGh/7R0n+a1UdUcOFff96osofZpi/+lMZ5gqv5peq6n5V9a+SfF+S3xv/D70pya9X1TeP+35MVT1jhu1N+mCGN1gfHJcXly0nw/j+hap6eFUdmWFK1DuysgsyPCdHjGPjJzp1L0rymKr6d1W1qaqem+EahfcnSWvtH5L8XpJfzTB/95KxfC32/+Ykx9YKF/NO8f6xry8Yn9P7VtW/qOECwrtZZQy8K8mLqupxNVw8+R+TfLS1tmuV9n923NZxGcbOu8fyFcdxVW2uqlPGUP61DFPovr58wzAPAjPM7qQkV9fwzRG/keHinb8dP2J9bZI/HT/qPDHJeUnenmHe83VJ/i7jH97W2tXj/fMznM3ak+FCuK912v73GT7S/UqGP7Tv7tS9p1bs61prrV2Z4UKz/5Lh4qidGeZiprV2TYY5wR/JEAYem+Hj/731nzIEpdur6t+31nZnuEjtFRlC+e4kP5t1fB1srb03w6cV549TbT6ZYZpDWmtfyHAW95wMH3lvzcTxaK1dkmEcfDzD3Or3L9v8CzNcVHpNhmP9ntx9+knPCzLMS/10hrH5sol2/zbJ7yd5VIYLRHs+P7Z9Y4apGz/aWvv0uO7lGZ7/y8d9/+MM8+fviQ9meDN52QrLSfLLSa7McJw+keTPx7KV/FKGKQPXZXjT8faVKrbWvpjhTcBZGZ6jn0vyfeNzt+SdSb4nwxuFyTeh+7r/f5Lh6x4/X1VfWK1ya+0rSZ6e5NQMz8fn842LCqeZOgZaa3+cYR7672d4/Xr0uM3VvC/DOL0qw5vBN4/b643j+yT5mbG/t2a4cHQtTxbAzJauiAbWyXhW9/YM0y2uW+/+sHFV1WKGC6R+Z5378YtJHtNae36nzkKGvq7nGXw2gKpqGV7fdq53X2BvOcMM66Cqvr+qHjB+1PhrGc587VrfXsHqquqhGS6APXe9+wIwLwIzrI9TMnzMeGOGj9pPbT7uYYOrqhdnmMryR621y1arD3CgMCUDAAA6nGEGAIAOgRkAADo2rXcHeo488si2ZcuWubX31a9+NYcddtjqFTloGBNMY1wwjXHBNMbFvcfHPvaxL7TWHj5t3YYOzFu2bMmVV145t/YWFxezsLAwt/bY+IwJpjEumMa4YBrj4t6jqpb/1P1dTMkAAIAOgRkAADoEZgAA6BCYAQCgQ2AGAIAOgRkAADoEZgAA6BCYAQCgQ2AGAIAOgRkAADoEZgAA6BCYAQCgQ2AGAIAOgRkAADoEZgAA6BCYAQCgQ2AGAIAOgRkAADoEZgAA6Ni03h3YqLacfeF6d2Hudp3zvevdBQCADccZZgAA6BCYAQCgQ2AGAIAOgRkAADoEZgAA6BCYAQCgQ2AGAIAOgRkAADoEZgAA6BCYAQCgQ2AGAIAOgRkAADoEZgAA6BCYAQCgQ2AGAIAOgRkAADoEZgAA6BCYAQCgQ2AGAIAOgRkAADoEZgAA6BCYAQCgQ2AGAIAOgRkAADoEZgAA6BCYAQCgQ2AGAIAOgRkAADoEZgAA6BCYAQCgQ2AGAIAOgRkAADoEZgAA6BCYAQCgQ2AGAIAOgRkAADoEZgAA6BCYAQCgQ2AGAIAOgRkAADoEZgAA6BCYAQCgY9XAXFXHVdUHquqaqrq6qn5qLH9VVd1QVVeNt5MnHvPzVbWzqj5TVc+YKD9pLNtZVWfvn10CAIC1s2mGOncmOau19udV9cAkH6uqS8Z1v95a+7XJylV1fJJTk5yQ5Ogkf1xVjxlX/1aSpyW5PskVVbWjtXbNWuwIAADsD6sG5tbaTUluGu9/pao+leSYzkNOSXJ+a+1rSa6rqp1Jnjiu29la+2ySVNX5Y12BGQCADWuWM8x3qaotSR6f5KNJnpzkpVX1wiRXZjgLfVuGMH35xMOuzzcC9u5l5U+a0saZSc5Mks2bN2dxcfGedHGf7Nmz5672znrsnXNrd6OY57G+t5gcE7DEuGAa44JpjIsDw8yBuaoOT/L7SV7WWvtyVb0hyWuStPHf1yX5oX3tUGvt3CTnJsm2bdvawsLCvm5yZouLi1lqb/vZF86t3Y1i1/MW1rsLG87kmIAlxgXTGBdMY1wcGGYKzFV13wxh+Xdba3+QJK21myfWvynJ+8fFG5IcN/HwY8eydMoBAGBDmuVbMirJm5N8qrX2+onyoyaqPTvJJ8f7O5KcWlWHVtWjkmxN8mdJrkiytaoeVVX3y3Bh4I612Q0AANg/ZjnD/OQkL0jyiaq6aix7RZLTqupxGaZk7EryI0nSWru6qi7IcDHfnUle0lr730lSVS9NcnGSQ5Kc11q7eg33BQAA1tws35LxoSQ1ZdVFnce8Nslrp5Rf1HscAABsNH7pDwAAOgRmAADoEJgBAKBDYAYAgA6BGQAAOgRmAADoEJgBAKBDYAYAgA6BGQAAOgRmAADoEJgBAKBDYAYAgA6BGQAAOgRmAADoEJgBAKBDYAYAgA6BGQAAOgRmAADoEJgBAKBDYAYAgA6BGQAAOgRmAADoEJgBAKBDYAYAgA6BGQAAOgRmAADoEJgBAKBDYAYAgA6BGQAAOgRmAADoEJgBAKBDYAYAgA6BGQAAOgRmAADoEJgBAKBDYAYAgA6BGQAAOgRmAADoEJgBAKBDYAYAgA6BGQAAOgRmAADoEJgBAKBDYAYAgA6BGQAAOgRmAADoEJgBAKBDYAYAgA6BGQAAOgRmAADoEJgBAKBDYAYAgA6BGQAAOgRmAADoEJgBAKBDYAYAgA6BGQAAOgRmAADoEJgBAKBDYAYAgA6BGQAAOgRmAADoEJgBAKBDYAYAgI5VA3NVHVdVH6iqa6rq6qr6qbH8oVV1SVVdO/57xFheVfWbVbWzqj5eVU+Y2NbpY/1rq+r0/bdbAACwNmY5w3xnkrNaa8cnOTHJS6rq+CRnJ7m0tbY1yaXjcpI8M8nW8XZmkjckQ8BO8sokT0ryxCSvXArZAACwUa0amFtrN7XW/ny8/5Ukn0pyTJJTkrx1rPbWJM8a75+S5G1tcHmSh1TVUUmekeSS1tqtrbXbklyS5KQ13RsAAFhj92gOc1VtSfL4JB9Nsrm1dtO46vNJNo/3j0mye+Jh149lK5UDAMCGtWnWilV1eJLfT/Ky1tqXq+quda21VlVtLTpUVWdmmMqRzZs3Z3FxcS02O5M9e/bc1d5Zj71zbu1uFPM81vcWk2MClhgXTGNcMI1xcWCYKTBX1X0zhOXfba39wVh8c1Ud1Vq7aZxycctYfkOS4yYefuxYdkOShWXli8vbaq2dm+TcJNm2bVtbWFhYXmW/WVxczFJ728++cG7tbhS7nrew3l3YcCbHBCwxLpjGuGAa4+LAMMu3ZFSSNyf5VGvt9ROrdiRZ+qaL05O8b6L8heO3ZZyY5Evj1I2Lkzy9qo4YL/Z7+lgGAAAb1ixnmJ+c5AVJPlFVV41lr0hyTpILquqMJJ9L8pxx3UVJTk6yM8kdSV6UJK21W6vqNUmuGOu9urV265rsBQAA7CerBubW2oeS1AqrnzqlfkvykhW2dV6S8+5JBwEAYD35pT8AAOgQmAEAoENgBgCADoEZAAA6BGYAAOgQmAEAoENgBgCADoEZAAA6BGYAAOgQmAEAoENgBgCADoEZAAA6BGYAAOgQmAEAoENgBgCADoEZAAA6BGYAAOgQmAEAoENgBgCADoEZAAA6BGYAAOgQmAEAoENgBgCADoEZAAA6BGYAAOgQmAEAoENgBgCADoEZAAA6BGYAAOgQmAEAoENgBgCADoEZAAA6BGYAAOgQmAEAoENgBgCADoEZAAA6BGYAAOgQmAEAoENgBgCADoEZAAA6BGYAAOgQmAEAoENgBgCADoEZAAA6BGYAAOgQmAEAoENgBgCADoEZAAA6BGYAAOgQmAEAoENgBgCADoEZAAA6BGYAAOgQmAEAoENgBgCADoEZAAA6BGYAAOgQmAEAoENgBgCADoEZAAA6BGYAAOgQmAEAoENgBgCADoEZAAA6BGYAAOhYNTBX1XlVdUtVfXKi7FVVdUNVXTXeTp5Y9/NVtbOqPlNVz5goP2ks21lVZ6/9rgAAwNqb5QzzW5KcNKX811trjxtvFyVJVR2f5NQkJ4yP+a9VdUhVHZLkt5I8M8nxSU4b6wIAwIa2abUKrbXLqmrLjNs7Jcn5rbWvJbmuqnYmeeK4bmdr7bNJUlXnj3Wvucc9BgCAOVo1MHe8tKpemOTKJGe11m5LckySyyfqXD+WJcnuZeVPmrbRqjozyZlJsnnz5iwuLu5DF++ZPXv23NXeWY+9c27tbhTzPNb3FpNjApYYF0xjXDCNcXFg2NvA/IYkr0nSxn9fl+SH1qJDrbVzk5ybJNu2bWsLCwtrsdmZLC4uZqm97WdfOLd2N4pdz1tY7y5sOJNjApYYF0xjXDCNcXFg2KvA3Fq7eel+Vb0pyfvHxRuSHDdR9dixLJ1yAADYsPbqa+Wq6qiJxWcnWfoGjR1JTq2qQ6vqUUm2JvmzJFck2VpVj6qq+2W4MHDH3ncbAADmY9UzzFX1riQLSY6squuTvDLJQlU9LsOUjF1JfiRJWmtXV9UFGS7muzPJS1pr/3vczkuTXJzkkCTntdauXvO9AQCANTbLt2ScNqX4zZ36r03y2inlFyW56B71DgAA1plf+gMAgA6BGQAAOgRmAADoEJgBAKBDYAYAgA6BGQAAOgRmAADoEJgBAKBDYAYAgA6BGQAAOgRmAADoEJgBAKBDYAYAgA6BGQAAOgRmAADoEJgBAKBDYAYAgA6BGQAAOgRmAADoEJgBAKBDYAYAgA6BGQAAOgRmAADoEJgBAKBDYAYAgA6BGQAAOgRmAADoEJgBAKBDYAYAgA6BGQAAOgRmAADoEJgBAKBDYAYAgA6BGQAAOgRmAADoEJgBAKBDYAYAgA6BGQAAOgRmAADoEJgBAKBDYAYAgA6BGQAAOgRmAADoEJgBAKBDYAYAgA6BGQAAOgRmAADoEJgBAKBDYAYAgA6BGQAAOgRmAADoEJgBAKBDYAYAgA6BGQAAOgRmAADoEJgBAKBDYAYAgA6BGQAAOgRmAADoEJgBAKBDYAYAgA6BGQAAOgRmAADoEJgBAKBj1cBcVedV1S1V9cmJsodW1SVVde347xFjeVXVb1bVzqr6eFU9YeIxp4/1r62q0/fP7gAAwNqa5QzzW5KctKzs7CSXtta2Jrl0XE6SZybZOt7OTPKGZAjYSV6Z5ElJnpjklUshGwAANrJVA3Nr7bIkty4rPiXJW8f7b03yrInyt7XB5UkeUlVHJXlGkktaa7e21m5Lckn+cQgHAIANZ2/nMG9urd003v98ks3j/WOS7J6od/1YtlI5AABsaJv2dQOttVZVbS06kyRVdWaG6RzZvHlzFhcX12rTq9qzZ89d7Z312Dvn1u5GMc9jfW8xOSZgiXHBNMYF0xgXB4a9Dcw3V9VRrbWbxikXt4zlNyQ5bqLesWPZDUkWlpUvTttwa+3cJOcmybZt29rCwsK0avvF4uJiltrbfvaFc2t3o9j1vIX17sKGMzkmYIlxwTTGBdMYFweGvZ2SsSPJ0jddnJ7kfRPlLxy/LePEJF8ap25cnOTpVXXEeLHf08cyAADY0FY9w1xV78pwdvjIqro+w7ddnJPkgqo6I8nnkjxnrH5RkpOT7ExyR5IXJUlr7daqek2SK8Z6r26tLb+QEAAANpxVA3Nr7bQVVj11St2W5CUrbOe8JOfdo94BAMA680t/AADQITADAECHwAwAAB0CMwAAdAjMAADQITADAECHwAwAAB0CMwAAdAjMAADQITADAECHwAwAAB0CMwAAdAjMAADQITADAECHwAwAAB0CMwAAdAjMAADQITADAECHwAwAAB0CMwAAdAjMAADQITADAECHwAwAAB0CMwAAdAjMAADQITADAECHwAwAAB0CMwAAdAjMAADQITADAECHwAwAAB0CMwAAdAjMAADQITADAECHwAwAAB0CMwAAdAjMAADQITADAECHwAwAAB0CMwAAdAjMAADQITADAECHwAwAAB0CMwAAdAjMAADQITADAECHwAwAAB0CMwAAdAjMAADQITADAECHwAwAAB0CMwAAdAjMAADQITADAECHwAwAAB0CMwAAdAjMAADQITADAECHwAwAAB0CMwAAdAjMAADQITADAECHwAwAAB0CMwAAdAjMAADQsU+Buap2VdUnquqqqrpyLHtoVV1SVdeO/x4xlldV/WZV7ayqj1fVE9ZiBwAAYH9aizPMT2mtPa61tm1cPjvJpa21rUkuHZeT5JlJto63M5O8YQ3aBgCA/Wp/TMk4Jclbx/tvTfKsifK3tcHlSR5SVUfth/YBAGDNVGtt7x9cdV2S25K0JG9srZ1bVbe31h4yrq8kt7XWHlJV709yTmvtQ+O6S5O8vLV25bJtnpnhDHQ2b9787eeff/5e9++e2rNnTw4//PAkySdu+NLc2t0oHnvMg9e7CxvO5JiAJcYF0xgXTGNc3Hs85SlP+djEjIm72bSP2/7O1toNVfXNSS6pqk9Prmyttaq6R4m8tXZuknOTZNu2bW1hYWEfuzi7xcXFLLW3/ewL59buRrHreQvr3YUNZ3JMwBLjgmmMC6YxLg4M+zQlo7V2w/jvLUnem+SJSW5emmox/nvLWP2GJMdNPPzYsQwAADasvQ7MVXVYVT1w6X6Spyf5ZJIdSU4fq52e5H3j/R1JXjh+W8aJSb7UWrtpr3sOAABzsC9TMjYnee8wTTmbkryztfY/quqKJBdU1RlJPpfkOWP9i5KcnGRnkjuSvGgf2gYAgLnY68DcWvtskv9zSvkXkzx1SnlL8pK9bQ8AANaDX/oDAIAOgRkAADoEZgAA6BCYAQCgQ2AGAIAOgRkAADoEZgAA6BCYAQCgQ2AGAIAOgRkAADoEZgAA6BCYAQCgQ2AGAIAOgRkAADoEZgAA6BCYAQCgQ2AGAIAOgRkAADoEZgAA6BCYAQCgQ2AGAIAOgRkAADoEZgAA6BCYAQCgQ2AGAIAOgRkAADoEZgAA6BCYAQCgQ2AGAIAOgRkAADoEZgAA6BCYAQCgQ2AGAIAOgRkAADoEZgAA6BCYAQCgQ2AGAIAOgRkAADoEZgAA6BCYAQCgQ2AGAIAOgRkAADoEZgAA6BCYAQCgQ2AGAICOTevdATaOLWdfuN5dmLtd53zvencBANjgnGEGAIAOgRkAADoEZgAA6BCYAQCgQ2AGAIAOgRkAADoEZgAA6BCYAQCgQ2AGAIAOgRkAADoEZgAA6BCYAQCgQ2AGAIAOgRkAADoEZgAA6BCYAQCgQ2AGAIAOgRkAADo2zbvBqjopyW8kOSTJ77TWzpl3H2DJlrMv7K4/67F3Zvsqde5tdp3zvevdBQC4V5nrGeaqOmdCEcUAAASCSURBVCTJbyV5ZpLjk5xWVcfPsw8AAHBPzPsM8xOT7GytfTZJqur8JKckuWbO/YCD1mpn1Q80zqgDsK/mHZiPSbJ7Yvn6JE+acx+Ag8j+eINwIE7VYd/Ne1x4MwjzM/c5zKupqjOTnDku7qmqz8yx+SOTfGGO7bHB/aQxwRTGBdPMe1zUr8yrJfaR14t7j0eutGLegfmGJMdNLB87lt2ltXZuknPn2aklVXVla23berTNxmRMMI1xwTTGBdMYFweGeX+t3BVJtlbVo6rqfklOTbJjzn0AAICZzfUMc2vtzqp6aZKLM3yt3Hmttavn2QcAALgn5j6HubV2UZKL5t3ujNZlKggbmjHBNMYF0xgXTGNcHACqtbbefQAAgA3LT2MDAEDHQReYq+qkqvpMVe2sqrOnrD+0qt49rv9oVW2Zfy+ZtxnGxc9U1TVV9fGqurSqVvzqGQ4cq42LiXo/UFWtqlwJfxCYZVxU1XPG14yrq+qd8+4j8zXD35BHVNUHquovxr8jJ69HP9l7B9WUjPGnuf9Xkqdl+NGUK5Kc1lq7ZqLOjyf55621H62qU5M8u7X23HXpMHMx47h4SpKPttbuqKofS7JgXBzYZhkXY70HJrkwyf2SvLS1duW8+8r8zPh6sTXJBUm+u7V2W1V9c2vtlnXpMPvdjGPi3CR/0Vp7Q1Udn+Si1tqW9egve+dgO8N8109zt9b+PsnST3NPOiXJW8f770ny1KqqOfaR+Vt1XLTWPtBau2NcvDzDd4hzYJvl9SJJXpPkV5L83Tw7x7qZZVy8OMlvtdZuSxJh+YA3y5hoSR403n9wkhvn2D/WwMEWmKf9NPcxK9Vprd2Z5EtJHjaX3rFeZhkXk85I8kf7tUdsBKuOi6p6QpLjWmt+J/vgMcvrxWOSPKaq/rSqLq+qk+bWO9bDLGPiVUmeX1XXZ/imsJ+YT9dYKxvup7FhI6uq5yfZluS71rsvrK+quk+S1yfZvs5dYePZlGRrkoUMn0ZdVlWPba3dvq69Yj2dluQtrbXXVdV3JHl7VX1ba+3r690xZnOwnWFe9ae5J+tU1aYMH518cS69Y73MMi5SVd+T5P9O8m9aa1+bU99YP6uNiwcm+bYki1W1K8mJSXa48O+AN8vrxfVJdrTW/qG1dl2G+a1b59Q/5m+WMXFGhnntaa19JMk3JTlyLr1jTRxsgXmWn+bekeT08f6/TfIn7WC6MvLgtOq4qKrHJ3ljhrBsPuLBoTsuWmtfaq0d2VrbMl68c3mG8eGivwPbLH9H/jDD2eVU1ZEZpmh8dp6dZK5mGRN/neSpSVJV35ohMP/NXHvJPjmoAvM4J3npp7k/leSC1trVVfXqqvo3Y7U3J3lYVe1M8jNJVvwqKQ4MM46LX01yeJLfq6qrqmr5iyEHmBnHBQeZGcfFxUm+WFXXJPlAkp9trfmk8gA145g4K8mLq+ovk7wryXYn4+5dDqqvlQMAgHvqoDrDDAAA95TADAAAHQIzAAB0CMwAANAhMAMAQIfADAAAHQIzAAB0CMwAANDx/wNqjgjatC/LIgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jq9PnbUshJGn",
        "colab_type": "text"
      },
      "source": [
        "We can see that this looks like a power law distribution. Let's plot the log of the ranks versus the log of the mean term frequency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIMWSvQoirv4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "outputId": "9644d0a5-d6ff-4d2a-c982-00c6ecc795f5"
      },
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "ranks = np.arange(len(mean_tf)) + 1\n",
        "plt.plot(np.log10(ranks), np.log10(mean_tf.values))\n",
        "plt.title('Plot of the log of rank (by mean term frequency) versus the log of mean term frequency')\n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1AHV5u5hI-7",
        "colab_type": "text"
      },
      "source": [
        "This is normally what you see with a vocabulary distribution. Notice, that even though we removed the most common words, and dropped very rare words, by setting `minDF` to 10, we still have the expected distribution.\n",
        "\n",
        "Now that we have our features and have assured ourselves that we have not disturbed the expected distribution of words, how can we reduce the number of features? We could try and add more words to our stop-word list, or we could increase our `minDF` to remove more rare words. But let's think about a more principled way to approach this. Many of the more well-known techniques for reducing the number of features, for example looking at the univariate predictive power of each feature, will not work well with text. The strength of bag-of-words features is their interactions. So we may throw away features that are not powerful on their own but could be very powerful in combination. The high dimensionality means that we can't explore all the possible interactions. So what can we do?\n",
        "\n",
        "We can use a dictionary of words or phrases that domain experts have selected as important to the problem. We can also build a tree-based model, for example, random forest, and use the feature importances to select a subset of features. This can work because the random forest model is nonlinear and can discover interactions—so, a word that is important only in combination.\n",
        "\n",
        "We will look at other techniques for reducing dimensionality in the \"Topic Modeling\" and \"Word Embeddings\".  Now, let's discuss the modeling of text using TF.IDF features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQZuDRlmhIwW",
        "colab_type": "text"
      },
      "source": [
        "## Modeling\n",
        "\n",
        "Once you have converted your text into a feature vector, things start to look more like a regular machine learning problem, with some exceptions. The following are the most important things to keep in mind:\n",
        "\n",
        "There are many sparse features.\n",
        "These features are not independent of each other.\n",
        "We have lost a massive part of language by losing the ordering of words.\n",
        "Fortunately, none of these are showstoppers. Even if an algorithm makes assumptions that are violated by these facts, it can still be effective. We will discuss some popular algorithms here, and we will try out these algorithms in the exercises in this chapter.\n",
        "\n",
        "### Naïve Bayes\n",
        "  Naïve Bayes gets its name from its naïve assumption that all the features are mutually independent. It then estimates the probability of a class conditioned on the feature values. We know, from linguistics and common sense, that words are not independent of each other. But naïve Bayes is actually a popular baseline for text classification. The reason naïve Bayes is so popular is that the probability that it produces is similar to TF.IDF:\n",
        "\n",
        "\\begin{equation}\n",
        "P(class | \\text{term}_1, \\text{term}_2, ..., \\text{term}_N) = \\frac{P(class)\\prod^N_{i=1}{P(\\text{term}_i|class)}}{\\sum^K_{k=1}{P(class_k)\\prod^N_{i=1}{P(\\text{term}_i|class_k)}}}\n",
        "\\end{equation}\n",
        "\n",
        "If a term is common in all classes, it will not contribute much to this value. However, if a term is unique to the documents in a particular class it will be an important feature for naïve Bayes. This is similar to how IDF reduces the importance of words that are common to many documents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TU-MgDIhIeK",
        "colab_type": "text"
      },
      "source": [
        "### Linear Models\n",
        "\n",
        "Linear models like linear regression and logistic regression assume that their predictors are independent of each other. One way we could get around this is to look at interactions. However, that will not work in our case because we have a very high dimensional space. If you plan on using a linear model, you will likely want to put more effort in your featurization. Specifically, you will want to be more aggressive in reducing the number of features.\n",
        "\n",
        "### Decision/Regression Trees\n",
        "\n",
        "Decision and regression trees can learn nonlinear relationships, and they don't have any assumptions of independence. They can be adversely affected by the sparse features. Variables with less inherent entropy, like words that are relatively uncommon, are less likely to be picked for splitting by splitting criteria like information gain. This means that any nonsparse features will be favored over sparse features. Also, words with higher variance, often meaning higher document frequency, can be favored over words with lower document frequency. This can be mitigated, for example, by being more aggressive with stop-word removal. If you are using random forest or gradient boosted trees, you can mitigate some of the difficulties mentioned previously.\n",
        "\n",
        "Another great aspect of tree-based models is the ability to easily interpret the output of the model. Because you can see which features are being selected, you can easily check if the learning algorithm is making a sensible model.\n",
        "\n",
        "### Deep Learning Algorithms\n",
        "\n",
        "Neural networks are great at learning complex functions, but they do require quite a bit of data. The data needed goes up quickly with the number of parameters. If you are using the bag-of-words approach, the number of parameters for the first layer will be the size of your vocabulary times the size of the first hidden layer. This is already quite large. This means that you are spending a lot of time learning intermediate representations for words—which can also lead to overfitting. It is often a good idea to use word embeddings, which we will discuss in #word_embeddings, so that your classification or regression model has far fewer parameters to learn.\n",
        "\n",
        "Always keep in mind what you want from your data when doing NLP, or machine learning in general. Training and deploying deep learning models is often more complicated than with classical machine learning models. Always try the simplest thing first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPcX6vRXhH3X",
        "colab_type": "text"
      },
      "source": [
        "## Iteration\n",
        "\n",
        "The most important part of any classification or regression project is your iteration cycle.\n",
        "\n",
        "![How to iterate on NLP classification and regression problems](https://i.imgur.com/7prHD6w.png)  \n",
        "_How to iterate on NLP classification and regression problems_\n",
        "\n",
        "If you have done machine learning in the past, most of this will look familiar. There are some differences when working with text data that we should keep in mind, so let's go over the following steps.\n",
        "\n",
        "1. Get data.\n",
        "\n",
        "This is often the most time-consuming part of such a project. Hopefully, the data you work with is well-maintained and well-documented. Whether it is or not, you must validate the data.\n",
        "\n",
        "2. Look at the data.\n",
        "\n",
        "Whether working with structured or unstructured data, we generally need to do some work to prepare our data for modeling. With structured data, this often means removing invalid values or normalizing a field. With text data this is a little more murky. There may be business logic that dictates a minimum or maximum length. Or perhaps there are certain documents you want to remove based on metadata. Outside of business logic, you should check the encodings of your documents and convert them to a common encoding (e.g., UTF-8).\n",
        "\n",
        "You also want to create a hold-out set. Even if you are using a form of cross-validation instead of a train-test split, it's important to keep a completely untouched hold-out. It is easy to overfit to text data.\n",
        "\n",
        "3. Process the data.\n",
        "\n",
        "Whether working with structured or unstructured data, we generally need to do some work to prepare our data for modeling. In structured data, this often means removing invalid values or normalizing a field. With text data this is a little more murky. There may be business logic that dictates a minimum or maximum length. Or perhaps there are certain documents you want to remove based on metadata. Outside of business logic, you should check the encodings of your documents and convert them to a common encoding (e.g., UTF-8).\n",
        "\n",
        "You also want to create a hold-out set. Even if you are using a form of cross-validation instead of a train-test split, it's important to keep a completely untouched hold-out. It is often easy to overfit to text data.\n",
        "\n",
        "4. Featurize.\n",
        "\n",
        "Now that you have your data processed and ready, you can create feature vectors. After creating features, you should do some basic exploratory analysis of the features. You look at the vocabulary distribution like we did previously. You can also use topic models for this, which we will cover in #topic_modeling. Topic models can give you insights for deciding how to create your model and, as a side benefit, will help you catch errors.\n",
        "\n",
        "Because NLP featurization is often more complicated than featurization with structured data, you will want to have your featurization stages in the same pipeline as your modeling. This will help optimize model hyperparameters alongside featurization parameters.\n",
        "\n",
        "5. Model.\n",
        "\n",
        "You need to decide on which algorithm you want to use. As with general machine learning tasks, you will want to set a baseline. Popular models for setting baselines for text-based classification and regression problems are logistic regression, naïve Bayes, and decision trees. Once you have your features, and you have decided on an algorithm, you can train your model.\n",
        "\n",
        "6. Evaluate.\n",
        "\n",
        "Looking at the data is important to understanding what is happening with your model, but looking at metrics is just as important. You should iterate using cross-validation or on a dedicated validation set. Your hold-out set must be saved until you think you are ready to go to production.\n",
        "\n",
        "7. Review.\n",
        "\n",
        "It's important to get fresh eyes on as much of your pipeline as possible.\n",
        "\n",
        "  * Review your code: data processing code can be difficult to review if someone does not have familiarity with the data. If you can't find someone who has context to review your code, having thorough documentation becomes important.\n",
        "  * Review your data: you can review your data with a subject-matter expert. Also, consider reviewing with someone who is fully unfamiliar with the data.\n",
        "  * Review your features: the features you've created should make sense. If this is the case, you should review these features with a domain expert. If the features are too abstract to easily tie back to the domain, it might be worthwhile to review the theory behind your features with someone who has experience building similar models.\n",
        "  * Review your model: when working on a modeling project, it's easy to get lost in the details. It's important to review your rationale for the chosen algorithm, as well as the output.\n",
        "  * Review your metrics: as with any machine learning project, you should be able to give clear interpretation of your metrics—especially the metric you make business decisions on. If you have a hard time finding a good metric, you may not have the best approach to the problem. Sometimes, a classification problem is better framed as ranking problem.\n",
        "  * Review your documentation: you should make sure that your whole pipeline is well documented. This is necessary if you want to have reproducibility.\n",
        "\n",
        "Now that you have validated your baseline model, it's time to make a decision. Is the baseline good enough for production? If so, ship it. Otherwise, it's time to look at the data again. Now you have your cycle set up, and you can start to improve your metrics.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWkFZ0A1lBK1",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2omjkVwdlB7J",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lAw5agQlCNW",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMqSUH2RlCg3",
        "colab_type": "text"
      },
      "source": [
        "Now we have a framework for building text-based classifiers and regressors. There is no singular technique that makes working with the sparse, high dimensional text easier. You should rely on domain experts to help inform your choices. This chapter covered generic ideas and rules; we will look at more concrete applications in part_application of this book. One issue with the bag-of-words approach is that we lose an important part of language—syntax. We can capture some of that with N-grams, but what happens if we want to classify pieces in the text? In the next chapter, we explore how to build sequence models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-FV_xIWlCXB",
        "colab_type": "text"
      },
      "source": [
        "## Exercises\n",
        "\n",
        "Let's build a classifier to predict the newsgroup that a document belongs to. We will start out with the pipeline we built previously in this chapter, and we will use a naïve Bayes classifier.\n",
        "\n",
        "Use the [Spark MLlib Guide](https://spark.apache.org/docs/latest/ml-guide.html) as a reference to try new things."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXQuIdNnlOqv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test = texts.randomSplit([0.8, 0.2], seed=123)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvvfMpxtlPo1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stopwords = set(StopWordsRemover.loadDefaultStopWords(\"english\"))"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzgYCLDylQju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sw_remover = StopWordsRemover() \\\n",
        "    .setInputCol(\"normalized\") \\\n",
        "    .setOutputCol(\"filtered\") \\\n",
        "    .setStopWords(list(stopwords))\n",
        "\n",
        "count_vectorizer = CountVectorizer(inputCol='filtered', \n",
        "    outputCol='tf', minDF=10)\n",
        "idf = IDF(inputCol='tf', outputCol='tfidf', minDocFreq=10)\n",
        "\n",
        "text_processing_pipeline = Pipeline(stages=[\n",
        "        assembler, \n",
        "        sentence, \n",
        "        tokenizer, \n",
        "        lemmatizer, \n",
        "        normalizer, \n",
        "        finisher, \n",
        "        sw_remover,\n",
        "        count_vectorizer,\n",
        "        idf\n",
        "    ])"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMughi1xlSUg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import IndexToString, StringIndexer\n",
        "from pyspark.ml.classification import *\n",
        "from pyspark.ml.tuning import *\n",
        "from pyspark.ml.evaluation import *"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tXK6RK1lT0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_indexer = StringIndexer(inputCol='newsgroup', outputCol='label').fit(texts)\n",
        "naive_bayes = NaiveBayes(featuresCol='tfidf')\n",
        "prediction_deindexer = IndexToString(inputCol='prediction', outputCol='pred_newsgroup', \n",
        "                                     labels=label_indexer.labels)\n",
        "\n",
        "pipeline = Pipeline(stages=[\n",
        "    text_processing_pipeline, label_indexer, naive_bayes, prediction_deindexer\n",
        "])"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CGssWbKlVTY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = pipeline.fit(train)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foy_wZ4nlWWY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_predicted = model.transform(train)\n",
        "test_predicted = model.transform(test)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoaAeJH3lCEl",
        "colab_type": "text"
      },
      "source": [
        "We are using F1-score, which is the harmonic mean of precision and recall."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lastrboTlYoX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluator = MulticlassClassificationEvaluator(metricName='f1')"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9en316GlcxY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "92431356-23d6-4040-f2a8-313af1ed31d8"
      },
      "source": [
        "print('f1', evaluator.evaluate(train_predicted))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1 0.940955827768335\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wB8kB4VtleNX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cacd5c03-bb8d-4b71-eea7-2344347a97e6"
      },
      "source": [
        "print('f1', evaluator.evaluate(test_predicted))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1 0.6338363272292974\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnf4C-JqlBjm",
        "colab_type": "text"
      },
      "source": [
        "It looks like we are doing much better on the training data than on the testing data—perhaps we are overfitting. Experiment, and see how well you can do on the test set."
      ]
    }
  ]
}