{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3.16_Object_Character_Recognition.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPw4ZQbFvZdiKqJ+3m3HpYE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexander-n-thomas/spark-nlp-book-prod/blob/master/3_16_Object_Character_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSfFLZjiNdRI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fd7ed0ca-cc1d-42c0-e4bf-4106cdb94aff"
      },
      "source": [
        "! apt install tesseract-ocr\n",
        "! apt install libtesseract-dev"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 4,795 kB of archives.\n",
            "After this operation, 15.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-eng all 4.00~git24-0e00fe6-1.2 [1,588 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-osd all 4.00~git24-0e00fe6-1.2 [2,989 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr amd64 4.00~git2288-10f4998a-2 [218 kB]\n",
            "Fetched 4,795 kB in 3s (1,724 kB/s)\n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 144465 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.00~git2288-10f4998a-2_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Setting up tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libleptonica-dev\n",
            "The following NEW packages will be installed:\n",
            "  libleptonica-dev libtesseract-dev\n",
            "0 upgraded, 2 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 2,755 kB of archives.\n",
            "After this operation, 13.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libleptonica-dev amd64 1.75.3-3 [1,308 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libtesseract-dev amd64 4.00~git2288-10f4998a-2 [1,447 kB]\n",
            "Fetched 2,755 kB in 3s (1,091 kB/s)\n",
            "Selecting previously unselected package libleptonica-dev.\n",
            "(Reading database ... 144512 files and directories currently installed.)\n",
            "Preparing to unpack .../libleptonica-dev_1.75.3-3_amd64.deb ...\n",
            "Unpacking libleptonica-dev (1.75.3-3) ...\n",
            "Selecting previously unselected package libtesseract-dev.\n",
            "Preparing to unpack .../libtesseract-dev_4.00~git2288-10f4998a-2_amd64.deb ...\n",
            "Unpacking libtesseract-dev (4.00~git2288-10f4998a-2) ...\n",
            "Setting up libleptonica-dev (1.75.3-3) ...\n",
            "Setting up libtesseract-dev (4.00~git2288-10f4998a-2) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdhtKP0xNpk_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "b6b07fc1-68a5-478c-dce5-2164e68963cc"
      },
      "source": [
        "import os\n",
        "\n",
        "# Install java\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "! java -version\n",
        "\n",
        "# Install pyspark\n",
        "! pip install --ignore-installed pyspark==2.4.4\n",
        "\n",
        "# Install Spark NLP\n",
        "! pip install --ignore-installed spark-nlp==2.5.1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"1.8.0_252\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_252-8u252-b09-1~18.04-b09)\n",
            "OpenJDK 64-Bit Server VM (build 25.252-b09, mixed mode)\n",
            "Collecting pyspark==2.4.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/21/f05c186f4ddb01d15d0ddc36ef4b7e3cedbeb6412274a41f26b55a650ee5/pyspark-2.4.4.tar.gz (215.7MB)\n",
            "\u001b[K     |████████████████████████████████| 215.7MB 61kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 45.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.4-py2.py3-none-any.whl size=216130388 sha256=16494c6421bd36615a4f8b37444a6fcb044638a0a9385457d8feb02003d26777\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.4\n",
            "Collecting spark-nlp==2.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/b4/db653f8080a446de8ce981b262d85c85c61de7e920930726da0d1c6b4c65/spark_nlp-2.5.1-py2.py3-none-any.whl (121kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: spark-nlp\n",
            "Successfully installed spark-nlp-2.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHiheTwtRxwi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "48612aa9-27cc-4cf8-bc78-909f6cc79e20"
      },
      "source": [
        "! curl https://i.imgur.com/WicCekw.png -o 'EHR example.PNG'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 14625  100 14625    0     0  21350      0 --:--:-- --:--:-- --:--:-- 21350\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1ZTQdEfPPSA",
        "colab_type": "text"
      },
      "source": [
        "# Object Character Recognition\n",
        " So far, we've dealt with writing stored as text data. However, a large portion of written data is stored as images. To use this data we need to convert it to text. This is different than our other NLP problems. In this problem, our knowledge of linguistics won't be as useful. This isn't the same as reading; it's merely character recognition. It is a much less intentional activity than speaking or listening to speech. Fortunately, writing systems tend to be easily distinguishable characters, especially in print. This means that image recognition techniques should work well on images of print text.\n",
        "\n",
        "Object character recognition (OCR) is the task of taking an image of written language (with characters) and converting it into text data. Modern solutions are neural-network based, and are essentially classifying sections of an image as containing a character. These classifications are then mapped into a character or string of characters in the text data.\n",
        "\n",
        "Let's talk about some of the possible inputs.\n",
        "\n",
        "## Kinds of OCR Tasks\n",
        " There are several kinds of OCR tasks. The tasks differ in what kind of image is the input, what kind of writing is in the image, and what is the target of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vd9-V33APPO9",
        "colab_type": "text"
      },
      "source": [
        "### Images of Printed Text and PDFs to Text\n",
        "  Unfortunately, there are many systems that export their documents as images. Some will export as PDFs, but since there is such a wide variety of ways in which a document can be coded into a PDF, PDFs may not be better than images. The good news is that in a PDF the characters are represented very consistently (except for font and size differences) with a high-contrast background. Converting documents like this to text data is the easiest OCR task.\n",
        "\n",
        "This can be complicated if the images are actually scans of documents, which can introduce the following errors:\n",
        "\n",
        "* Print errors  \n",
        "The printer had a dirty head and produced blotches, or left lines in the text.\n",
        "* Paper problems   \n",
        "The paper is old, stained, or has creases. This can reduce the contrast and smudge or distort some parts of the image.\n",
        "* Scanning problems  \n",
        "The paper is skewed, which means that text is not in lines.\n",
        "\n",
        "### Images of Handwritten Text to Text\n",
        "  This situation still has the high-contrast background, but the consistency of characters is much worse. Additionally, the issue of text not being in lines can be much harder if a document has marginal notes. The well-worn data set of handwritten digits from the MNIST database is an example of this task.\n",
        "\n",
        "You will need some way to constrain this problem. For example, the MNIST data set is restricted to just 10 characters. Some electronic pen software constrains the problem by learning one person's handwriting. Trying to solve this problem for everyone's handwriting would be significantly more difficult. There is so much variety in writing styles that it is not uncommon for humans to be unable to read a stranger's handwriting. What the model learns in recognizing writing in letters from the American Civil War will be useless in recognizing doctors' notes or parsing signatures.\n",
        "\n",
        "### Images of Text in Environment to Text\n",
        " An example of images of text in an environment would be identifying what a sign says in a picture of a street. Generally, such text is printed, but the font and size can vary widely. There can also be distortions similar to the problems in our scanning example. The problem of skewed text in this type of image is more difficult than when scanned. When scanning, one dimension is fixed, so the paper can be assumed to be flat on the scanning bed. In the environment, text can be rotated in any way. For example, if you are building an OCR model for a self-driving car, some of the text will be to the right of the car, and some will be elevated above the car. There will also be text on the road. This means that the shapes of the letters will not be consistent.\n",
        "\n",
        "This problem is also often constrained. In most jurisdictions, there are some regulations on signage. For example, important instructions are limited and are published. This means that instead of needing to convert images to text, you can recognize particular signs. This changes the problem from OCR to object recognition. Even if you want to recognize location signs—for example, addresses and town names—there are usually specific colors that the signs are printed in. This means that your model can learn in stages.\n",
        "\n",
        "```\n",
        "Is this part of an image...\n",
        "\n",
        "- a sign\n",
        "- if so, is it a) instructions, or b) a place of interest\n",
        "- if a) classify it\n",
        "- if b) convert to text\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5FOny6EPPMX",
        "colab_type": "text"
      },
      "source": [
        "## Images of Text to Target\n",
        " In some situations, we may want to skip the text altogether. If we are classifying scanned documents, we can do this in two ways. First, we can convert to text and then use our text classification techniques. Second, we can simply do the classification directly on the images. There are couple of trade-offs.\n",
        "\n",
        "* Image to text to target\n",
        "\n",
        "  * Pro: we can examine the intermediate text to identify problems\n",
        "  * Pro: we can reuse the image-to-text and text-to-target models separately (especially valuable if some inputs are text and some are images)\n",
        "  * Cons: when converting to text, we may lose features in the image that could have helped us classify—for example, if there is an image in the letterhead that could give us a great signal\n",
        "\n",
        "* Image to target\n",
        "\n",
        "  * Pro: this is simpler—no need to develop and combine two separate models\n",
        "  * Pro: additional features, as mentioned previously\n",
        "  * Con: harder to debug problems, as mentioned previously\n",
        "  * Con: can only be reused on similar image-to-target problems\n",
        "\n",
        "It is better to start with the two-part approach because this will let you explore your data. Most image-to-text models today are neural nets, so adding some layers and retraining later in the project should not be too difficult."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5xahJdePPJt",
        "colab_type": "text"
      },
      "source": [
        "## Note on Different Writing Systems\n",
        " The difficulty of the task is very much related to the writing system used. If you recall, in #natural_language_basics we defined the different families of writing systems.  Logographic systems are difficult because there are a much larger number of possible characters. This is difficult for two reasons. First, the obvious reason is that there are more classes to predict and therefore more parameters. Second, logographic systems will have many similar-looking characters, since all characters are dots, lines, and curves in a small box. There are also other complications that make a writing system difficult. In printed English, each character has a single form, but in cursive English, characters can have up to four forms—isolated, initial, medial, and final. Some writing systems have multiple forms even in printed text—for example, Arabic. Also, if a writing system makes much use of diacritics it can exacerbate problems like smudging and skewing (see amharic_tuesday). You will want to be wary of this with most abugidas—for example, Devanagari and some alphabets, like Polish and Vietnamese. \n",
        "\n",
        "![\"Maksannyo\" [Tuesday] in Amharic written in Ge'ez](https://i.imgur.com/0OXF8xL.png)  \n",
        "_\"Maksannyo\" [Tuesday] in Amharic written in Ge'ez_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAYr4G20PPHC",
        "colab_type": "text"
      },
      "source": [
        "## Problem Statement and Constraints\n",
        " In our example, we will be implementing an ETL pipeline for converting images to text. This tools is quite general in its purpose. One common use for a tool like this is to convert images of text from legacy systems into text data. Our example will be using a (fake) electronic medical record. We will be using Tesseract from Google. We will use Spark to spread the workload out so we can parallelize the processing. We will also use a pretrained pipeline to process the text before storing it.\n",
        "\n",
        "1. What is the problem we are trying to solve?\n",
        "\n",
        "We will build a script that will convert the images to text, process the text, and finally store it. We will separate the functionality so that we can potentially augment or improve these steps in the future.\n",
        "\n",
        "2. What constraints are there?\n",
        "\n",
        "We will be working only with images of printed English text. The documents will have only one column of text. In our fictitious scenario, we also know the content will be medically related, but that will not affect this implementation\n",
        "\n",
        "3. How do we solve the problem with the constraints?\n",
        "\n",
        "We want a repeatable way to convert images to text, process the text, and store it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVvQdaFTPPEO",
        "colab_type": "text"
      },
      "source": [
        "## Plan the Project\n",
        " The solution is relatively straightforward. First, we will write a script that will allow us to pass data to Tesseract, instead of just to a file. Then we will write a Python script that will use the first script to get the text, and then use Spark NLP to process the text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Reg6Z1eaPPBZ",
        "colab_type": "text"
      },
      "source": [
        "## Implement the Solution\n",
        "  Let's start by looking at an example of using Tesseract. Let's look at the usage output for the program."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4G6kQufURNCa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "b69c5d30-77a8-4011-b3af-b4f26a3601d8"
      },
      "source": [
        "! tesseract -h"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Usage:\n",
            "  tesseract --help | --help-extra | --version\n",
            "  tesseract --list-langs\n",
            "  tesseract imagename outputbase [options...] [configfile...]\n",
            "\n",
            "OCR options:\n",
            "  -l LANG[+LANG]        Specify language(s) used for OCR.\n",
            "NOTE: These options must occur before any configfile.\n",
            "\n",
            "Single options:\n",
            "  --help                Show this help message.\n",
            "  --help-extra          Show extra help for advanced users.\n",
            "  --version             Show version information.\n",
            "  --list-langs          List available languages for tesseract engine.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jfgrfXKPO-l",
        "colab_type": "text"
      },
      "source": [
        "It looks like we simply need to pass it an image, `imagename`, and output name, `outputbase`. Let's look at the text that is in the image.\n",
        "\n",
        "```\n",
        "CHIEF COMPLAINT\n",
        "Ankle pain\n",
        "\n",
        "HISTORY OF PRESENT ILLNESS:\n",
        "\n",
        "The patient is 28 y/o man who tripped when hiking. He struggled back to his car, and immediately came in. Due to his severe ankle pain, he\n",
        "thought the right ankle may be broken.\n",
        "\n",
        "EXAMINATION:\n",
        "An x-ray of right ankle ruled out fracture.\n",
        "\n",
        "IMPRESSION:\n",
        "The right ankle is sprained.\n",
        "\n",
        "RECOMMENDATION:\n",
        "- Take ibuprofen as needed\n",
        "- Try to stay off right ankle for one week\n",
        "```\n",
        "\n",
        "Let's look at the image we will be experimenting with\n",
        "\n",
        "Now, let's try and pass the image through Tesseract"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8KEYNkLRZsl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "abf38900-0351-4aab-dffa-51cb8350e4f6"
      },
      "source": [
        "! tesseract EHR_example.PNG EHR_example"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLLL0KNoPO0g",
        "colab_type": "text"
      },
      "source": [
        "![EHR image of text](https://i.imgur.com/WicCekw.png)\n",
        "_EHR image of text_\n",
        "\n",
        "Now let's see what Tesseract extracted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTcSmHFTSFJG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "48b6d95f-9d5d-4a18-aa01-14fb63c3f046"
      },
      "source": [
        "! cat EHR_example.txt"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CHIEF COMPLAINT\n",
            "Ankle pain\n",
            "\n",
            "HISTORY OF PRESENT ILLNESS:\n",
            "\n",
            "The patient is 28 y/o man who tripped when hiking. He struggled back\n",
            "thought the right ankle may be broken.\n",
            "\n",
            "EXAMINATION:\n",
            "An x-ray of right ankle ruled out fracture.\n",
            "\n",
            "IMPRESSION:\n",
            "The right ankle is sprained.\n",
            "\n",
            "RECOMMENDATION:\n",
            "- Take ibuprofen when as needed\n",
            "- Try to stay off right ankle for one week\n",
            "\n",
            "to his car, and immediately came in. Due to his severe ankle pain, he\n",
            "\f"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVcFec3QPO0Y",
        "colab_type": "text"
      },
      "source": [
        "~This worked perfectly.~ *** This is producing different results than previously. *** Now, let's put together our conversion script. The input to the script will be the type of image, and then the actual image will be encoded as a base64 string. We create a temporary image file and extract the text with Tesseract. This will also create a temporary text file, which we will stream into the stdout. We need to replace new lines with a special character, \"~\", so that we can know which lines are from which input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tDaJA48VoXh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ae9f53b1-6d57-43c0-fa9b-e3d8df66368e"
      },
      "source": [
        "%%writefile img2txt.sh\n",
        "#!/bin/bash\n",
        "\n",
        "set -e\n",
        "\n",
        "# assumed input is lines of \"image-type base64-encoded-image-data\"\n",
        "\n",
        "type=$1\n",
        "data=$2\n",
        "file=\"img.$type\"\n",
        "echo $data | base64 -d > $file\n",
        "tesseract $file text\n",
        "cat text.txt | tr '\\n' '~'"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting img2txt.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2Ub6iTNPO0Q",
        "colab_type": "text"
      },
      "source": [
        "Let's try our script out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlS2wpgwbAH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! chmod a+x img2txt.sh"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0vDT1hVVq4y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "9f66de0b-d956-4a03-8629-aaa83e839a44"
      },
      "source": [
        "! ./img2txt.sh \"png\" $(base64 EHR_example.PNG |\\\n",
        "    tr -d '\\n') |\\\n",
        "    tr '~' '\\n'"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "CHIEF COMPLAINT\n",
            "Ankle pain\n",
            "\n",
            "HISTORY OF PRESENT ILLNESS:\n",
            "\n",
            "The patient is 28 y/o man who tripped when hiking. He struggled back\n",
            "thought the right ankle may be broken.\n",
            "\n",
            "EXAMINATION:\n",
            "An x-ray of right ankle ruled out fracture.\n",
            "\n",
            "IMPRESSION:\n",
            "The right ankle is sprained.\n",
            "\n",
            "RECOMMENDATION:\n",
            "- Take ibuprofen when as needed\n",
            "- Try to stay off right ankle for one week\n",
            "\n",
            "to his car, and immediately came in. Due to his severe ankle pain, he\n",
            "\f"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po4dNniJPOqt",
        "colab_type": "text"
      },
      "source": [
        "Now let's work on the full processing code. First, we will get a pretrained pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2lwB0ghV2-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import base64\n",
        "import os\n",
        "import subprocess as sub\n",
        "\n",
        "import sparknlp\n",
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "\n",
        "spark = sparknlp.start()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfmfDlt-V51d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "d7dafc08-db64-4eaf-c29c-6f9e37d1e439"
      },
      "source": [
        "pipeline = PretrainedPipeline('explain_document_ml')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "explain_document_ml download started this may take some time.\n",
            "Approx size to download 9.4 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YgOV98WPOmx",
        "colab_type": "text"
      },
      "source": [
        "Now let's create our test input data. We will copy our image a hundred times into the EHRs folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSDjE9SbV94S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "73bab559-af61-40dd-9b99-290f63902fb6"
      },
      "source": [
        "! mkdir EHRs\n",
        "for i in range(100):\n",
        "    ! cp EHR_example.PNG EHRs/EHR{i}.PNG"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘EHRs’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lv7h5OXwPNre",
        "colab_type": "text"
      },
      "source": [
        "Now, we will create a DataFrame that contains the filepath, image type, and image data as three string fields."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUr7Ble9WBhC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = []\n",
        "for file in os.listdir('EHRs') :\n",
        "    file = os.path.join('EHRs', file)\n",
        "    with open(file, 'rb') as image:\n",
        "        f = image.read()\n",
        "        b = bytearray(f)\n",
        "    image_b64 = base64.b64encode(b).decode('utf-8')\n",
        "    extension = os.path.splitext(file)[1][1:]\n",
        "    record = (file, extension, image_b64)\n",
        "    data.append(record)\n",
        "    \n",
        "data = spark.createDataFrame(data, ['file', 'type', 'image'])\\\n",
        "    .repartition(4)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pcw_et0AWDxZ",
        "colab_type": "text"
      },
      "source": [
        "Let's define a function that will take a partition of data, as an iterable, and return a generator of filepaths and text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN0nfvSJWGC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_partition(partition):\n",
        "    for file, extension, image_b64 in partition:\n",
        "        text = sub.check_output(['./img2txt.sh', extension, image_b64])\\\n",
        "            .decode('utf-8')\n",
        "        text.replace('~', '\\n')\n",
        "        yield (file, text)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_OMAHCbWHHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "post_ocr = data.rdd.mapPartitions(process_partition)\n",
        "post_ocr = spark.createDataFrame(post_ocr, ['file', 'text'])\n",
        "\n",
        "processed = pipeline.transform(post_ocr)\n",
        "processed.write.mode('overwrite').parquet('example_output.parquet/')"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLbT0d1VWEB7",
        "colab_type": "text"
      },
      "source": [
        "Now let's put this into a script."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osyqz6iKWPH3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0fb31f71-75ba-4823-faa5-5f3a023b4570"
      },
      "source": [
        "%%writefile process_image_dir.py\n",
        "#!/bin/python\n",
        "\n",
        "import base64\n",
        "import os\n",
        "import subprocess as sub\n",
        "import sys\n",
        "\n",
        "import sparknlp\n",
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "\n",
        "def process_partition(partition):\n",
        "    for file, extension, image_b64 in partition:\n",
        "        text = sub.check_output(['./img2txt.sh', extension, image_b64])\\\n",
        "            .decode('utf-8')\n",
        "        text.replace('~', '\\n')\n",
        "        yield (file, text)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    spark = sparknlp.start()\n",
        "\n",
        "    pipeline = PretrainedPipeline('explain_document_ml')\n",
        "    \n",
        "    data_dir = sys.argv[1]\n",
        "    output_file = sys.argv[2]\n",
        "    \n",
        "    data = []\n",
        "    for file in os.listdir(data_dir) :\n",
        "        file = os.path.join(data_dir, file)\n",
        "        with open(file, 'rb') as image:\n",
        "            f = image.read()\n",
        "            b = bytearray(f)\n",
        "        image_b64 = base64.b64encode(b).decode('utf-8')\n",
        "        extension = os.path.splitext(file)[1][1:]\n",
        "        record = (file, extension, image_b64)\n",
        "        data.append(record)\n",
        "\n",
        "    data = spark.createDataFrame(data, ['file', 'type', 'image'])\\\n",
        "        .repartition(4)\n",
        "    post_ocr = data.rdd.map(tuple).mapPartitions(process_partition)\n",
        "    post_ocr = spark.createDataFrame(post_ocr, ['file', 'text'])\n",
        "    processed = pipeline.transform(post_ocr)\n",
        "    processed.write.mode('overwrite').parquet(output_file)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing process_image_dir.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZesvSKqcWELU",
        "colab_type": "text"
      },
      "source": [
        "Now we have a script that will take a directory of images, and it will produce a directory of text files extracted from the images.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm71r4x8WSPi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7efdc1f7-6f88-48d3-a27b-15fdd2c8360f"
      },
      "source": [
        "! python process_image_dir.py EHRs ehr.parquet"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ivy Default Cache set to: /root/.ivy2/cache\n",
            "The jars for the packages stored in: /root/.ivy2/jars\n",
            ":: loading settings :: url = jar:file:/usr/local/lib/python3.6/dist-packages/pyspark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
            "com.johnsnowlabs.nlp#spark-nlp_2.11 added as a dependency\n",
            ":: resolving dependencies :: org.apache.spark#spark-submit-parent-2370ad7c-9285-4e71-a0fa-2c80a8bcf58c;1.0\n",
            "\tconfs: [default]\n",
            "\tfound com.johnsnowlabs.nlp#spark-nlp_2.11;2.5.1 in central\n",
            "\tfound com.typesafe#config;1.3.0 in central\n",
            "\tfound org.rocksdb#rocksdbjni;6.5.3 in central\n",
            "\tfound org.apache.hadoop#hadoop-aws;3.2.0 in central\n",
            "\tfound com.amazonaws#aws-java-sdk-core;1.11.603 in central\n",
            "\tfound commons-logging#commons-logging;1.1.3 in central\n",
            "\tfound org.apache.httpcomponents#httpclient;4.5.9 in central\n",
            "\tfound org.apache.httpcomponents#httpcore;4.4.11 in central\n",
            "\tfound commons-codec#commons-codec;1.11 in central\n",
            "\tfound software.amazon.ion#ion-java;1.0.2 in central\n",
            "\tfound com.fasterxml.jackson.dataformat#jackson-dataformat-cbor;2.6.7 in central\n",
            "\tfound joda-time#joda-time;2.8.1 in central\n",
            "\tfound com.amazonaws#aws-java-sdk-s3;1.11.603 in central\n",
            "\tfound com.amazonaws#aws-java-sdk-kms;1.11.603 in central\n",
            "\tfound com.amazonaws#jmespath-java;1.11.603 in central\n",
            "\tfound com.fasterxml.jackson.core#jackson-databind;2.6.7.2 in central\n",
            "\tfound com.fasterxml.jackson.core#jackson-annotations;2.6.0 in central\n",
            "\tfound com.fasterxml.jackson.core#jackson-core;2.6.7 in central\n",
            "\tfound com.github.universal-automata#liblevenshtein;3.0.0 in central\n",
            "\tfound com.google.code.findbugs#annotations;3.0.1 in central\n",
            "\tfound net.jcip#jcip-annotations;1.0 in central\n",
            "\tfound com.google.code.findbugs#jsr305;3.0.1 in central\n",
            "\tfound com.google.protobuf#protobuf-java-util;3.0.0-beta-3 in central\n",
            "\tfound com.google.protobuf#protobuf-java;3.0.0-beta-3 in central\n",
            "\tfound com.google.code.gson#gson;2.3 in central\n",
            "\tfound it.unimi.dsi#fastutil;7.0.12 in central\n",
            "\tfound org.projectlombok#lombok;1.16.8 in central\n",
            "\tfound org.slf4j#slf4j-api;1.7.21 in central\n",
            "\tfound com.navigamez#greex;1.0 in central\n",
            "\tfound dk.brics.automaton#automaton;1.11-8 in central\n",
            "\tfound org.json4s#json4s-ext_2.11;3.5.3 in central\n",
            "\tfound joda-time#joda-time;2.9.5 in central\n",
            "\tfound org.joda#joda-convert;1.8.1 in central\n",
            "\tfound org.tensorflow#tensorflow;1.15.0 in central\n",
            "\tfound org.tensorflow#libtensorflow;1.15.0 in central\n",
            "\tfound org.tensorflow#libtensorflow_jni;1.15.0 in central\n",
            "\tfound net.sf.trove4j#trove4j;3.0.3 in central\n",
            ":: resolution report :: resolve 1453ms :: artifacts dl 50ms\n",
            "\t:: modules in use:\n",
            "\tcom.amazonaws#aws-java-sdk-core;1.11.603 from central in [default]\n",
            "\tcom.amazonaws#aws-java-sdk-kms;1.11.603 from central in [default]\n",
            "\tcom.amazonaws#aws-java-sdk-s3;1.11.603 from central in [default]\n",
            "\tcom.amazonaws#jmespath-java;1.11.603 from central in [default]\n",
            "\tcom.fasterxml.jackson.core#jackson-annotations;2.6.0 from central in [default]\n",
            "\tcom.fasterxml.jackson.core#jackson-core;2.6.7 from central in [default]\n",
            "\tcom.fasterxml.jackson.core#jackson-databind;2.6.7.2 from central in [default]\n",
            "\tcom.fasterxml.jackson.dataformat#jackson-dataformat-cbor;2.6.7 from central in [default]\n",
            "\tcom.github.universal-automata#liblevenshtein;3.0.0 from central in [default]\n",
            "\tcom.google.code.findbugs#annotations;3.0.1 from central in [default]\n",
            "\tcom.google.code.findbugs#jsr305;3.0.1 from central in [default]\n",
            "\tcom.google.code.gson#gson;2.3 from central in [default]\n",
            "\tcom.google.protobuf#protobuf-java;3.0.0-beta-3 from central in [default]\n",
            "\tcom.google.protobuf#protobuf-java-util;3.0.0-beta-3 from central in [default]\n",
            "\tcom.johnsnowlabs.nlp#spark-nlp_2.11;2.5.1 from central in [default]\n",
            "\tcom.navigamez#greex;1.0 from central in [default]\n",
            "\tcom.typesafe#config;1.3.0 from central in [default]\n",
            "\tcommons-codec#commons-codec;1.11 from central in [default]\n",
            "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
            "\tdk.brics.automaton#automaton;1.11-8 from central in [default]\n",
            "\tit.unimi.dsi#fastutil;7.0.12 from central in [default]\n",
            "\tjoda-time#joda-time;2.9.5 from central in [default]\n",
            "\tnet.jcip#jcip-annotations;1.0 from central in [default]\n",
            "\tnet.sf.trove4j#trove4j;3.0.3 from central in [default]\n",
            "\torg.apache.hadoop#hadoop-aws;3.2.0 from central in [default]\n",
            "\torg.apache.httpcomponents#httpclient;4.5.9 from central in [default]\n",
            "\torg.apache.httpcomponents#httpcore;4.4.11 from central in [default]\n",
            "\torg.joda#joda-convert;1.8.1 from central in [default]\n",
            "\torg.json4s#json4s-ext_2.11;3.5.3 from central in [default]\n",
            "\torg.projectlombok#lombok;1.16.8 from central in [default]\n",
            "\torg.rocksdb#rocksdbjni;6.5.3 from central in [default]\n",
            "\torg.slf4j#slf4j-api;1.7.21 from central in [default]\n",
            "\torg.tensorflow#libtensorflow;1.15.0 from central in [default]\n",
            "\torg.tensorflow#libtensorflow_jni;1.15.0 from central in [default]\n",
            "\torg.tensorflow#tensorflow;1.15.0 from central in [default]\n",
            "\tsoftware.amazon.ion#ion-java;1.0.2 from central in [default]\n",
            "\t:: evicted modules:\n",
            "\tcommons-logging#commons-logging;1.2 by [commons-logging#commons-logging;1.1.3] in [default]\n",
            "\tjoda-time#joda-time;2.8.1 by [joda-time#joda-time;2.9.5] in [default]\n",
            "\t---------------------------------------------------------------------\n",
            "\t|                  |            modules            ||   artifacts   |\n",
            "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
            "\t---------------------------------------------------------------------\n",
            "\t|      default     |   38  |   0   |   0   |   2   ||   36  |   0   |\n",
            "\t---------------------------------------------------------------------\n",
            ":: retrieving :: org.apache.spark#spark-submit-parent-2370ad7c-9285-4e71-a0fa-2c80a8bcf58c\n",
            "\tconfs: [default]\n",
            "\t0 artifacts copied, 36 already retrieved (0kB/22ms)\n",
            "20/07/25 00:45:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
            "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
            "20/07/25 00:45:18 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
            "explain_document_ml download started this may take some time.\n",
            "20/07/25 00:45:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.\n",
            "20/07/25 00:45:21 WARN ApacheUtils: NoSuchMethodError was thrown when disabling normalizeUri. This indicates you are using an old version (< 4.5.8) of Apache http client. It is recommended to use http client version >= 4.5.9 to avoid the breaking change introduced in apache client 4.5.7 and the latency in exception handling. See https://github.com/aws/aws-sdk-java/issues/1919 for more information\n",
            "20/07/25 00:45:21 WARN ApacheUtils: NoSuchMethodError was thrown when disabling normalizeUri. This indicates you are using an old version (< 4.5.8) of Apache http client. It is recommended to use http client version >= 4.5.9 to avoid the breaking change introduced in apache client 4.5.7 and the latency in exception handling. See https://github.com/aws/aws-sdk-java/issues/1919 for more information\n",
            "20/07/25 00:45:23 WARN ApacheUtils: NoSuchMethodError was thrown when disabling normalizeUri. This indicates you are using an old version (< 4.5.8) of Apache http client. It is recommended to use http client version >= 4.5.9 to avoid the breaking change introduced in apache client 4.5.7 and the latency in exception handling. See https://github.com/aws/aws-sdk-java/issues/1919 for more information\n",
            "20/07/25 00:45:23 WARN ApacheUtils: NoSuchMethodError was thrown when disabling normalizeUri. This indicates you are using an old version (< 4.5.8) of Apache http client. It is recommended to use http client version >= 4.5.9 to avoid the breaking change introduced in apache client 4.5.7 and the latency in exception handling. See https://github.com/aws/aws-sdk-java/issues/1919 for more information\n",
            "Approx size to download 9.4 MB\n",
            "[ | ]explain_document_ml download started this may take some time.\n",
            "20/07/25 00:45:23 WARN ApacheUtils: NoSuchMethodError was thrown when disabling normalizeUri. This indicates you are using an old version (< 4.5.8) of Apache http client. It is recommended to use http client version >= 4.5.9 to avoid the breaking change introduced in apache client 4.5.7 and the latency in exception handling. See https://github.com/aws/aws-sdk-java/issues/1919 for more information\n",
            "20/07/25 00:45:23 WARN ApacheUtils: NoSuchMethodError was thrown when disabling normalizeUri. This indicates you are using an old version (< 4.5.8) of Apache http client. It is recommended to use http client version >= 4.5.9 to avoid the breaking change introduced in apache client 4.5.7 and the latency in exception handling. See https://github.com/aws/aws-sdk-java/issues/1919 for more information\n",
            "20/07/25 00:45:23 WARN ApacheUtils: NoSuchMethodError was thrown when disabling normalizeUri. This indicates you are using an old version (< 4.5.8) of Apache http client. It is recommended to use http client version >= 4.5.9 to avoid the breaking change introduced in apache client 4.5.7 and the latency in exception handling. See https://github.com/aws/aws-sdk-java/issues/1919 for more information\n",
            "20/07/25 00:45:23 WARN ApacheUtils: NoSuchMethodError was thrown when disabling normalizeUri. This indicates you are using an old version (< 4.5.8) of Apache http client. It is recommended to use http client version >= 4.5.9 to avoid the breaking change introduced in apache client 4.5.7 and the latency in exception handling. See https://github.com/aws/aws-sdk-java/issues/1919 for more information\n",
            "20/07/25 00:45:24 WARN ApacheUtils: NoSuchMethodError was thrown when disabling normalizeUri. This indicates you are using an old version (< 4.5.8) of Apache http client. It is recommended to use http client version >= 4.5.9 to avoid the breaking change introduced in apache client 4.5.7 and the latency in exception handling. See https://github.com/aws/aws-sdk-java/issues/1919 for more information\n",
            "20/07/25 00:45:24 WARN ApacheUtils: NoSuchMethodError was thrown when disabling normalizeUri. This indicates you are using an old version (< 4.5.8) of Apache http client. It is recommended to use http client version >= 4.5.9 to avoid the breaking change introduced in apache client 4.5.7 and the latency in exception handling. See https://github.com/aws/aws-sdk-java/issues/1919 for more information\n",
            "Approximate size to download 9.4 MB\n",
            "20/07/25 00:45:24 WARN ApacheUtils: NoSuchMethodError was thrown when disabling normalizeUri. This indicates you are using an old version (< 4.5.8) of Apache http client. It is recommended to use http client version >= 4.5.9 to avoid the breaking change introduced in apache client 4.5.7 and the latency in exception handling. See https://github.com/aws/aws-sdk-java/issues/1919 for more information\n",
            "20/07/25 00:45:24 WARN ApacheUtils: NoSuchMethodError was thrown when disabling normalizeUri. This indicates you are using an old version (< 4.5.8) of Apache http client. It is recommended to use http client version >= 4.5.9 to avoid the breaking change introduced in apache client 4.5.7 and the latency in exception handling. See https://github.com/aws/aws-sdk-java/issues/1919 for more information\n",
            "Download done! Loading the resource.\n",
            "[OK!]\n",
            "20/07/25 00:45:48 WARN TaskSetManager: Stage 21 contains a task of very large size (966 KB). The maximum recommended task size is 100 KB.\n",
            "[Stage 21:==========================================================(2 + 0) / 2]Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "[Stage 24:>                                                         (0 + 2) / 4]Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Estimating resolution as 132\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Estimating resolution as 132\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Estimating resolution as 132\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "[Stage 24:==============>                                           (1 + 2) / 4]Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "[Stage 24:=============================>                            (2 + 2) / 4]Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Estimating resolution as 132\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Estimating resolution as 132\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n",
            "[Stage 24:===========================================>              (3 + 1) / 4]Tesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\n",
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 132\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d5INQMTWEGK",
        "colab_type": "text"
      },
      "source": [
        "## Test and Measure the Solution\n",
        " For an application that is fully internal, there are no actual business metrics; instead, monitoring the quality is the sole focus. We must make sure that this internal application is not unnecessarily increasing the error of the application.\n",
        "\n",
        "### Model-Centric Metrics\n",
        " We can measure the accuracy of an OCR model by character and word accuracy. You can measure this character error rate by calculating the Levenshtein distance between the expected and observed text then dividing by the size of the text.\n",
        "\n",
        "In addition to monitoring the actual model error rates, you can capture statistics about output. For example, monitoring the distribution of words can potentially diagnose a problem.\n",
        "\n",
        "## Review\n",
        " When you build an internal service, like an OCR tool may very well be, you will want to review the work with the teams that will need it. Ultimately, the success of your application requires that your users be satisfied with both the technical correctness and the support available. In some organizations, especially larger ones, there can be significant pressure to use in-house tools. If these tools are poorly engineered, under-documented, or unsupported, other teams will rightfully try and avoid them. This can potentially create hard feelings and lead to duplicated work and the siloing of teams. This is why it is a good idea to review the internal products and seek and accept feedback early and often.\n",
        "\n",
        "## Conclusion\n",
        "In this chapter we looked at an NLP application that is not focused on extracting structured data from unstructured data but is instead focused on converting from one type of data to another. Although this is only tangentially related to linguistics, it is immensely important practically. If you are building an application that uses data from long-established industries, it is very likely you will have to convert images to text.\n",
        "\n",
        "In this part of the book, we talked about building simple applications that apply some of the techniques we learned in part_ii. We also discussed specific and general development practices that can help you succeed in building your NLP application. To revisit a point made previously about Spark NLP, a central philosophical tenet of this library is that there is no one-size-fits-all. You will need to know your data, and know how to build your NLP application. In the next part we will discuss some more general tips and strategies for deploying applications. "
      ]
    }
  ]
}