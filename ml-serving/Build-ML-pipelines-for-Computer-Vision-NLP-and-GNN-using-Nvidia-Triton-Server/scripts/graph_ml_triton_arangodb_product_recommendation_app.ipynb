{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triton Meets ArangoDB: Amazon Product Recommendation Application using GraphSage Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will build an Amazon Product Recommendation application by leveraging three technologies at a time i.e. Graph Machine Learning, Nvidia's Triton inference server and ArangoDB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.data import NeighborSampler\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "from pandas.core.common import flatten\n",
    "# importing obg datatset\n",
    "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator\n",
    "from pandas.core.common import flatten\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import collections\n",
    "from scipy.special import softmax\n",
    "\n",
    "from arango import ArangoClient\n",
    "import pprint\n",
    "import tritongrpcclient\n",
    "import tritongrpcclient.model_config_pb2 as mc\n",
    "import tritonhttpclient\n",
    "from tritonclientutils import triton_to_np_dtype\n",
    "from tritonclientutils import InferenceServerException\n",
    "from scipy.special import softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"./create_triton_acceptable_models/datasets\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PygNodePropPredDataset('ogbn-products', root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting train val test split idx based on sales ranking\n",
    "split_idx = dataset.get_idx_split()\n",
    "evaluator = Evaluator(name='ogbn-products')\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing train, validation and test node indices\n",
    "train_idx = split_idx['train']\n",
    "valid_idx = split_idx['valid']\n",
    "test_idx = split_idx['test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test node indexes\n",
    "test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neighborhood sampling of test nodes\n",
    "test_loader = NeighborSampler(data.edge_index, node_idx=test_idx,\n",
    "                              sizes=[15, 10, 5], batch_size=1,\n",
    "                              shuffle=False, num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node feature matrix\n",
    "x = data.x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels\n",
    "y = data.y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating adjs for performing a trace on the GraphSage model\n",
    "# will contain only edge_idx and size attributes\n",
    "\n",
    "max_nodes = 1000\n",
    "def create_triton_input(dummy_n_ids, dummy_adjs):\n",
    "    edge_list_0 = []\n",
    "    edge_list_1 = []\n",
    "    edge_list_2 = []\n",
    "    edge_adjs = []\n",
    "    for idx, e_idx in enumerate(dummy_adjs[0]):\n",
    "        if idx == 0:\n",
    "            edge_list_0.append(e_idx[0])\n",
    "            #edge_list_0.append(e_idx[1])\n",
    "            edge_list_0.append(torch.tensor(np.asarray(e_idx[2])))\n",
    "        elif idx == 1:\n",
    "            edge_list_1.append(e_idx[0])\n",
    "            #edge_list_1.append(e_idx[1])\n",
    "            edge_list_1.append(torch.tensor(np.asarray(e_idx[2])))\n",
    "        else:\n",
    "            edge_list_2.append(e_idx[0])\n",
    "            #edge_list_2.append(e_idx[1])\n",
    "            edge_list_2.append(torch.tensor(np.asarray(e_idx[2])))\n",
    "    \n",
    "    # creating edge indexes\n",
    "    edge_index_0 = edge_list_0[0]\n",
    "    edge_index_0 = edge_index_0.to(device)\n",
    "    edge_size_0 = edge_list_0[1]\n",
    "    edge_size_0 = edge_size_0.to(device)\n",
    "\n",
    "    edge_index_1 = edge_list_1[0]\n",
    "    edge_index_1 = edge_index_1.to(device)\n",
    "    edge_size_1 = edge_list_1[1]\n",
    "    edge_size_1 = edge_size_1.to(device)\n",
    "\n",
    "    edge_index_2 = edge_list_2[0]\n",
    "    edge_index_2 = edge_index_2.to(device)\n",
    "    edge_size_2 = edge_list_2[1]\n",
    "    edge_size_2 = edge_size_2.to(device)\n",
    "    \n",
    "    \n",
    "    # add padding to node feature matrix\n",
    "    dummy_x = x[dummy_n_ids[0]]\n",
    "    total_nodes = dummy_x.size(0)\n",
    "    nodes_padded = max_nodes - total_nodes\n",
    "    dummy_x_pad = F.pad(input=dummy_x, pad=(0, 0, 0, nodes_padded), mode='constant', value=0)\n",
    "    dummy_x_pad = dummy_x_pad.to(device)\n",
    "    \n",
    "    return dummy_x_pad, edge_index_0, edge_size_0, edge_index_1, edge_size_1, edge_index_2, edge_size_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting inputs and output names as same in config file\n",
    "input_name = ['input__0', 'input__1', 'input__2', 'input__3', 'input__4', 'input__5', 'input__6']\n",
    "output_name = ['output__0', 'output__1', 'output__2']\n",
    "VERBOSE = False\n",
    "from tritonclient.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client-Side Script to Interact with Triton Inference Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The run_inference function computes the node embeddings of a given node at three different layers of trained GraphSage model and returns the same. This function requires 7 inputs:\n",
    "\n",
    "{ node_matrix: Padded node feature matrix consiting of nodes involved in the computation      graph\n",
    "\n",
    "  edge_index_0: adjacency list for all the edges involved at the Hop-3 (layer-3)\n",
    "  \n",
    "  edge_size_0 : shape of the bipartite graph at Hop-3\n",
    "\n",
    "  edge_index_1: adjacency list for all the edges involved at the Hop-2 (layer-2)\n",
    "  \n",
    "  edge_size_1 : shape of the bipartite graph at Hop-2\n",
    "  \n",
    "  edge_index_2: adjacency list for all the edges involved at the Hop-1 (layer-1)\n",
    "  \n",
    "  edge_size_2 : shape of the bipartite graph at Hop-1\n",
    "}\n",
    "\n",
    "Note: Neighborhood sampler returns ajacency list in reversed order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(node_matrix, edge_index_0, edge_size_0, edge_index_1, edge_size_1, edge_index_2, edge_size_2, model_name='graph_embeddings', url='127.0.0.1:8000', model_version='1'):\n",
    "    triton_client = tritonhttpclient.InferenceServerClient(\n",
    "        url=url, verbose=VERBOSE)\n",
    "    model_metadata = triton_client.get_model_metadata(\n",
    "        model_name=model_name, model_version=model_version)\n",
    "    model_config = triton_client.get_model_config(\n",
    "        model_name=model_name, model_version=model_version)\n",
    "    # I have restricted the input sequence length to 256\n",
    "\n",
    "    input_node_matrix = node_matrix\n",
    "    input_node_matrix  = np.array(input_node_matrix.cpu(), dtype=np.float32)\n",
    "    \n",
    "    # edges_indexes and sizes\n",
    "    ed_index_0 = np.array(edge_index_0.cpu(), dtype=np.int64)\n",
    "    ed_index_1 = np.array(edge_index_1.cpu(), dtype=np.int64)\n",
    "    ed_index_2 = np.array(edge_index_2.cpu(), dtype=np.int64)\n",
    "    \n",
    "    ed_size_0 = np.array(edge_size_0.cpu(), dtype=np.int64)\n",
    "    ed_size_1 = np.array(edge_size_1.cpu(), dtype=np.int64)\n",
    "    ed_size_2 = np.array(edge_size_2.cpu(), dtype=np.int64)\n",
    "    \n",
    "\n",
    "\n",
    "    input0 = tritonhttpclient.InferInput(input_name[0], (1000,  100), 'FP32')\n",
    "    input0.set_data_from_numpy(input_node_matrix, binary_data=False)\n",
    "    \n",
    "    #layer-1\n",
    "    input1 = tritonhttpclient.InferInput(input_name[1], ed_index_0.shape, 'INT64')\n",
    "    input1.set_data_from_numpy(ed_index_0, binary_data=False)\n",
    "    #size\n",
    "    input2 = tritonhttpclient.InferInput(input_name[2], (2,), 'INT64')\n",
    "    input2.set_data_from_numpy(ed_size_0, binary_data=False)\n",
    "    \n",
    "    #layer-2\n",
    "    input3 = tritonhttpclient.InferInput(input_name[3], ed_index_1.shape, 'INT64')\n",
    "    input3.set_data_from_numpy(ed_index_1, binary_data=False)\n",
    "    #size\n",
    "    input4 = tritonhttpclient.InferInput(input_name[4], (2,), 'INT64')\n",
    "    input4.set_data_from_numpy(ed_size_1, binary_data=False)\n",
    "    \n",
    "    #layer-3\n",
    "    input5 = tritonhttpclient.InferInput(input_name[5], ed_index_2.shape, 'INT64')\n",
    "    input5.set_data_from_numpy(ed_index_2, binary_data=False)\n",
    "    #size\n",
    "    input6 = tritonhttpclient.InferInput(input_name[6], (2,), 'INT64')\n",
    "    input6.set_data_from_numpy(ed_size_2, binary_data=False)\n",
    "    \n",
    "    output0 = tritonhttpclient.InferRequestedOutput(output_name[0],  binary_data=False)\n",
    "    output1 = tritonhttpclient.InferRequestedOutput(output_name[1],  binary_data=False)\n",
    "    output2 = tritonhttpclient.InferRequestedOutput(output_name[2],  binary_data=False)\n",
    "    \n",
    "    response = triton_client.infer(model_name, model_version=model_version, inputs=[input0, input1, input2, input3, input4, input5, input6], outputs=[output0, output1, output2])\n",
    "    # layer-1 embeddings\n",
    "    embeddings_layer_1 = response.as_numpy('output__0')\n",
    "    # layer-2 embeddings\n",
    "    embeddings_layer_2 = response.as_numpy('output__1')\n",
    "    # # layer-3 embeddings\n",
    "    embeddings_layer_3 = response.as_numpy('output__2')\n",
    "    return embeddings_layer_1, embeddings_layer_2, embeddings_layer_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load integer to real product category label mapping\n",
    "df = pd.read_csv('./create_triton_acceptable_models/datasets/ogbn_products/mapping/labelidx2productcategory.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_idx, prod_cat = df.iloc[: ,0].values, df.iloc[: ,1].values\n",
    "label_mapping = dict(zip(label_idx, prod_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the demonstration purpose we will use first 5000 test nodes for the Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting test nodes and its adjacency matrix\n",
    "\n",
    "layer_3_embs = []\n",
    "layer_2_embs = []\n",
    "for idx, (batch_size, n_id, adjs) in enumerate(test_loader):\n",
    "        print(\"idx:\", idx)\n",
    "        dummy_n_ids = []\n",
    "        dummy_adjs = []\n",
    "        dummy_n_ids.append(n_id)\n",
    "        dummy_adjs.append(adjs)\n",
    "        \n",
    "        if len(dummy_n_ids[0]) == 1:\n",
    "            print(\"Found Disconnected Node in the graph at index:\", idx)\n",
    "            layer_3_embs.append(\"Disconnected Node\")\n",
    "        elif idx == 5000:\n",
    "            break\n",
    "        else:\n",
    "            # creating triton input\n",
    "            dummy_x_pad, edge_index_0, edge_size_0, edge_index_1, edge_size_1, edge_index_2, edge_size_2 = create_triton_input(dummy_n_ids, dummy_adjs)\n",
    "            # generating node embeddings for test node from Triton Server\n",
    "            emb1, emb2, emb3 = run_inference(dummy_x_pad, edge_index_0, edge_size_0, edge_index_1, edge_size_1, edge_index_2, edge_size_2)\n",
    "            layer_3_embs.append(emb3[0])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connectiong to arangodb\n",
    "# Initialize the ArangoDB client.\n",
    "client = ArangoClient(\"http://127.0.0.1:8529\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Connect to the database\n",
    "#amazon_db = oasis.connect_python_arango(login)\n",
    "amazon_db = client.db('_system', username='root', password='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx_lb = 235938\n",
    "test_idx_mb = test_idx_lb + len(layer_3_embs)\n",
    "test_idx_ub = 2449028"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "#! ./arangorestore -c none --create-collection true --server.endpoint \"tcp://127.0.0.1:8529\" --server.username \"root\" --server.database \"_system\" --server.password \"amritsar\" --default-replication-factor 3  --input-directory \"./ogbn-product_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = []\n",
    "BATCH_SIZE = 250\n",
    "batch_idx = 1\n",
    "index = 0\n",
    "# collection in which we will store are inference results\n",
    "product_collection = amazon_db[\"Products\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below cell we will update the amazon product recommendation graph (obgn-products) dataset stored inside the ArangoDB with the node embeddings and their corresponding product category predictions for the 5000 test nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(test_idx_lb, test_idx_mb):\n",
    "    update_doc = {}\n",
    "    product_id = \"Products/\" + str(idx)\n",
    "    update_doc[\"_id\"] = product_id\n",
    "    if layer_3_embs[index] == \"Disconnected Node\":\n",
    "        update_doc[\"predicted_node_embeddings\"] = layer_3_embs[index]\n",
    "        update_doc[\"predicted_product\"] = str(-1)\n",
    "    else:\n",
    "        update_doc[\"predicted_node_embeddings\"] = layer_3_embs[index].tolist()\n",
    "        update_doc[\"predicted_product\"] = str(label_mapping[np.argmax(layer_3_embs[index], axis=-1)])\n",
    "    batch.append(update_doc)\n",
    "    last_record = (idx == (test_idx_mb - 1))\n",
    "    index +=1\n",
    "    \n",
    "    if index % BATCH_SIZE == 0:\n",
    "        print(\"Inserting batch %d\" % (batch_idx))\n",
    "        batch_idx += 1\n",
    "        product_collection.update_many(batch)\n",
    "        batch = []   \n",
    "    if last_record and len(batch) > 0:\n",
    "        print(\"Inserting batch the last batch!\")\n",
    "        product_collection.update_many(batch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Product Recommendation with AQL \n",
    "Products which can be bought together with a query product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product ids for demo 235940, 240930\n",
    "cursor = amazon_db.aql.execute(\n",
    "\"\"\"\n",
    "  FOR p in Products\n",
    "    FILTER p._id == \"Products/236435\"\n",
    "    RETURN { \"predicted_node_embeddings\": p.predicted_node_embeddings, \"product_cat\": p.product_cat }\n",
    "\"\"\")\n",
    "\n",
    "# Iterate through the result cursor\n",
    "for doc in cursor:\n",
    "  print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = amazon_db.aql.execute(\n",
    "\"\"\"\n",
    "LET descr_emb = (\n",
    "  FOR p in Products\n",
    "    FILTER p._id == \"Products/236435\"\n",
    "    FOR j in RANGE(0, 46)\n",
    "      RETURN TO_NUMBER(NTH(p.predicted_node_embeddings,j))\n",
    ")\n",
    "\n",
    "LET descr_mag = (\n",
    "  SQRT(SUM(\n",
    "    FOR i IN RANGE(0, 47)\n",
    "      RETURN POW(TO_NUMBER(NTH(descr_emb, i)), 2)\n",
    "  ))\n",
    ")\n",
    "\n",
    "LET dau = (\n",
    "\n",
    "    FOR v in Products\n",
    "    FILTER HAS(v, \"predicted_node_embeddings\")\n",
    "\n",
    "    LET v_mag = (SQRT(SUM(\n",
    "      FOR k IN RANGE(0, 47)\n",
    "        RETURN POW(TO_NUMBER(NTH(v.predicted_node_embeddings, k)), 2)\n",
    "    )))\n",
    "\n",
    "    LET numerator = (SUM(\n",
    "      FOR i in RANGE(0,46)\n",
    "          RETURN TO_NUMBER(NTH(descr_emb, i)) * TO_NUMBER(NTH(v.predicted_node_embeddings, i))\n",
    "    ))\n",
    "\n",
    "    LET cos_sim = (numerator)/(descr_mag * v_mag)\n",
    "\n",
    "    RETURN {\"product\": v._id, \"product_cat\": v.product_cat, \"cos_sim\": cos_sim}\n",
    "\n",
    "    )\n",
    "\n",
    "FOR du in dau\n",
    "    SORT du.cos_sim DESC\n",
    "    LIMIT 5000\n",
    "    RETURN {\"product_cat\": du.product_cat, \"cos_sim\": du.cos_sim} \n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the result cursor\n",
    "for doc in cursor:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we're using the cosine similarity to retrieve the product which can be bought together with a query product. The cosine similarity is calculated between the node embeddings of a query product and all the other 4999 products:\n",
    "$$\n",
    " \\frac{\n",
    "  \\sum\\limits_{i=1}^{n}{a_i b_i}\n",
    "  }{\n",
    "      \\sqrt{\\sum\\limits_{j=1}^{n}{a_j^2}}\n",
    "      \\sqrt{\\sum\\limits_{k=1}^{n}{b_k^2}}\n",
    "  }\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "Once we calculate the cosine similarities, we can then SORT the products and return the highly likely bought together product with a query product!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: \n",
    "1)For the demo purpose I am using 5000 test nodes but definitely if we go for more nodes results can be improved.\n",
    "\n",
    "2) Also there is a lot of room for the improvement of the accuracy of model which can be achieved using hyperparameter tuning for e.g setting different number of search depths or playing with size of hidden layers like we have used 256 in our experiment. Another interesting thing to experiment would be using different neighborhood sampling techniques like random walk. \n",
    "\n",
    "Therefore, I can left this as a HomeWork for you !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
