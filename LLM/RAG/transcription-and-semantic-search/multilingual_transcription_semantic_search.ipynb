{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from encoder.encoder import Encoder\n",
    "from transcriptor.whisperx import WhisperX\n",
    "from langchain.vectorstores.pgvector import PGVector\n",
    "from langchain.docstore.document import Document\n",
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
    "import utils\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"env/connection.env\")\n",
    "\n",
    "COLLECTION_NAME = \"pt\"  # or 'en'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Video into Audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.convert_to_wav(f\"data/{COLLECTION_NAME}.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcribe audio using WhiperX and create documents to be stored in Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whisperX in cpu is too slow, we used large whisper\n",
    "whisperx = WhisperX(model_name=\"whisper\")\n",
    "transcription = whisperx.transcribe(f\"data/{COLLECTION_NAME}.wav\")\n",
    "\n",
    "# create documents to store in Postgres\n",
    "docs = [\n",
    "    Document(page_content=f'start {item[\"start\"]} - end {item[\"end\"]}: {item[\"text\"]}')\n",
    "    for item in transcription[\"segments\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create connection settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONNECTION_STRING = PGVector.connection_string_from_db_params(\n",
    "    driver=os.getenv(\"DRIVER\"),\n",
    "    host=os.getenv(\"HOST\"),\n",
    "    port=os.getenv(\"PORT\"),\n",
    "    database=os.getenv(\"DATABASE\"),\n",
    "    user=os.getenv(\"USERNAME\"),\n",
    "    password=os.getenv(\"PASSWORD\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert embeddings into Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collection not found\n"
     ]
    }
   ],
   "source": [
    "db = PGVector.from_documents(\n",
    "    embedding=Encoder().encoder,\n",
    "    documents=docs,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    connection_string=CONNECTION_STRING,\n",
    "    pre_delete_collection=True,  # deletes previous records, useful for testing\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Huub use case with portuguese audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query PT: 'marcas e investimentos' | Top 4 results:\n",
      "start 81.401 - end 85.26:  uma marca baseada em Berlim, portanto ao invés de esperarmos que esse investimento chegasse,\n",
      "start 111.902 - end 117.26:  para maturar o produto, para investir em tecnologia e para investir no business development.\n",
      "start 88.58 - end 93.039:  Estas duas rondas de investimento que nós já fizemos com uma capacidade também diferente\n",
      "start 28.6 - end 32.64:  Portanto, damos toda a componente de infraestrutura logística que uma marca precisa.\n",
      "Query EN: 'brands and investments' | Top 4 results:\n",
      "start 81.401 - end 85.26:  uma marca baseada em Berlim, portanto ao invés de esperarmos que esse investimento chegasse,\n",
      "start 105.26 - end 111.24:  Portanto esta ronda de investimento para nós significou um incremento daquilo que é a nossa capacidade\n",
      "start 111.902 - end 117.26:  para maturar o produto, para investir em tecnologia e para investir no business development.\n",
      "start 88.58 - end 93.039:  Estas duas rondas de investimento que nós já fizemos com uma capacidade também diferente\n"
     ]
    }
   ],
   "source": [
    "similar_docs_pt = db.similarity_search(\"marcas e investimentos\", k=4)\n",
    "similar_docs_en = db.similarity_search(\"brands and investments\", k=4)\n",
    "\n",
    "print(\"Query PT: 'marcas e investimentos' | Top 4 results:\")\n",
    "print(\"\\n\".join([x.page_content for x in similar_docs_pt]))\n",
    "print(\"Query EN: 'brands and investments' | Top 4 results:\")\n",
    "print(\"\\n\".join([x.page_content for x in similar_docs_en]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probabilistic Deep Learning use case with english audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query PT: 'modelos de aprendizagem profunda' | Top 8 result:\n",
      "start 45.28 - end 51.9:  when we are using deep learning models, usually we are relying on maximum likelihood estimation\n",
      "Query EN: 'deep learning models' | Top 1 result:\n",
      "start 45.28 - end 51.9:  when we are using deep learning models, usually we are relying on maximum likelihood estimation\n"
     ]
    }
   ],
   "source": [
    "similar_docs_pt = db.similarity_search(\"modelos de aprendizagem profunda\", k=8)\n",
    "similar_docs_en = db.similarity_search(\"deep learning models\", k=8)\n",
    "\n",
    "print(\"Query PT: 'modelos de aprendizagem profunda' | Top 8 result:\")\n",
    "print(similar_docs_pt[-1].page_content)\n",
    "print(\"Query EN: 'deep learning models' | Top 1 result:\")\n",
    "print(similar_docs_en[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query PT: 'distribuição normal' | Top 4 results:\n",
      "start 61.102 - end 64.598: Well, when we calculated from a normal standard, normal distribution,\n",
      "start 19.601 - end 24.739:  normal distribution that is exactly as we we've built it before, univariate normal distribution.\n",
      "start 0.201 - end 2.228:  the mean of this normal distribution.\n",
      "start 73.421 - end 74.545:  this normal distribution.\n",
      "Query EN: 'normal distribution' | Top 4 results:\n",
      "start 61.102 - end 64.598: Well, when we calculated from a normal standard, normal distribution,\n",
      "start 0.201 - end 2.228:  the mean of this normal distribution.\n",
      "start 73.421 - end 74.545:  this normal distribution.\n",
      "start 19.601 - end 24.739:  normal distribution that is exactly as we we've built it before, univariate normal distribution.\n"
     ]
    }
   ],
   "source": [
    "similar_docs_pt = db.similarity_search(\"distribuição normal\", k=4)\n",
    "similar_docs_en = db.similarity_search(\"normal distribution\", k=4)\n",
    "\n",
    "print(\"Query PT: 'distribuição normal' | Top 4 results:\")\n",
    "print(\"\\n\".join([x.page_content for x in similar_docs_pt]))\n",
    "print(\"Query EN: 'normal distribution' | Top 4 results:\")\n",
    "print(\"\\n\".join([x.page_content for x in similar_docs_en]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zaai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
