{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "489809b2",
      "metadata": {
        "id": "489809b2",
        "outputId": "9bf6cb26-5e00-45be-be71-9ba79e2fb099"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /opt/homebrew/lib/python3.11/site-packages (0.0.157)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.3 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (1.4.47)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (3.8.4)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (0.5.7)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (1.24.3)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (1.2.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (1.10.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (2.28.2)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: tqdm>=4.48.0 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (4.65.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /opt/homebrew/lib/python3.11/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /opt/homebrew/lib/python3.11/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /opt/homebrew/lib/python3.11/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/homebrew/lib/python3.11/site-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2->langchain) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
            "Requirement already satisfied: packaging>=17.0 in /Users/prakul.agarwal/Library/Python/3.11/lib/python/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/homebrew/lib/python3.11/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: llama-index==0.6.0 in /opt/homebrew/lib/python3.11/site-packages (0.6.0)\n",
            "Requirement already satisfied: dataclasses-json in /opt/homebrew/lib/python3.11/site-packages (from llama-index==0.6.0) (0.5.7)\n",
            "Requirement already satisfied: langchain>=0.0.152 in /opt/homebrew/lib/python3.11/site-packages (from llama-index==0.6.0) (0.0.157)\n",
            "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.11/site-packages (from llama-index==0.6.0) (1.24.3)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /opt/homebrew/lib/python3.11/site-packages (from llama-index==0.6.0) (8.2.2)\n",
            "Requirement already satisfied: openai>=0.26.4 in /opt/homebrew/lib/python3.11/site-packages (from llama-index==0.6.0) (0.27.4)\n",
            "Requirement already satisfied: pandas in /opt/homebrew/lib/python3.11/site-packages (from llama-index==0.6.0) (2.0.1)\n",
            "Requirement already satisfied: tiktoken in /opt/homebrew/lib/python3.11/site-packages (from llama-index==0.6.0) (0.3.3)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /opt/homebrew/lib/python3.11/site-packages (from langchain>=0.0.152->llama-index==0.6.0) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.3 in /opt/homebrew/lib/python3.11/site-packages (from langchain>=0.0.152->llama-index==0.6.0) (1.4.47)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/homebrew/lib/python3.11/site-packages (from langchain>=0.0.152->llama-index==0.6.0) (3.8.4)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /opt/homebrew/lib/python3.11/site-packages (from langchain>=0.0.152->llama-index==0.6.0) (2.8.4)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /opt/homebrew/lib/python3.11/site-packages (from langchain>=0.0.152->llama-index==0.6.0) (1.2.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /opt/homebrew/lib/python3.11/site-packages (from langchain>=0.0.152->llama-index==0.6.0) (1.10.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /opt/homebrew/lib/python3.11/site-packages (from langchain>=0.0.152->llama-index==0.6.0) (2.28.2)\n",
            "Requirement already satisfied: tqdm>=4.48.0 in /opt/homebrew/lib/python3.11/site-packages (from langchain>=0.0.152->llama-index==0.6.0) (4.65.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /opt/homebrew/lib/python3.11/site-packages (from dataclasses-json->llama-index==0.6.0) (3.19.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /opt/homebrew/lib/python3.11/site-packages (from dataclasses-json->llama-index==0.6.0) (1.5.1)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /opt/homebrew/lib/python3.11/site-packages (from dataclasses-json->llama-index==0.6.0) (0.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/prakul.agarwal/Library/Python/3.11/lib/python/site-packages (from pandas->llama-index==0.6.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas->llama-index==0.6.0) (2023.3)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas->llama-index==0.6.0) (2023.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /opt/homebrew/lib/python3.11/site-packages (from tiktoken->llama-index==0.6.0) (2023.3.23)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.152->llama-index==0.6.0) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.152->llama-index==0.6.0) (3.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.152->llama-index==0.6.0) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.152->llama-index==0.6.0) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.152->llama-index==0.6.0) (1.9.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.152->llama-index==0.6.0) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.152->llama-index==0.6.0) (1.3.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /Users/prakul.agarwal/Library/Python/3.11/lib/python/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json->llama-index==0.6.0) (23.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/homebrew/lib/python3.11/site-packages (from pydantic<2,>=1->langchain>=0.0.152->llama-index==0.6.0) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /Users/prakul.agarwal/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.8.2->pandas->llama-index==0.6.0) (1.16.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2->langchain>=0.0.152->llama-index==0.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2->langchain>=0.0.152->llama-index==0.6.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2->langchain>=0.0.152->llama-index==0.6.0) (2022.12.7)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/homebrew/lib/python3.11/site-packages (from typing-inspect>=0.4.0->dataclasses-json->llama-index==0.6.0) (1.0.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: pymongo in /opt/homebrew/lib/python3.11/site-packages (4.3.3)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /opt/homebrew/lib/python3.11/site-packages (from pymongo) (2.3.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: nltk in /opt/homebrew/lib/python3.11/site-packages (3.8.1)\n",
            "Requirement already satisfied: click in /opt/homebrew/lib/python3.11/site-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /opt/homebrew/lib/python3.11/site-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /opt/homebrew/lib/python3.11/site-packages (from nltk) (2023.3.23)\n",
            "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.11/site-packages (from nltk) (4.65.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: Pillow in /opt/homebrew/lib/python3.11/site-packages (9.5.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip3 install langchain\n",
        "!pip3 install llama-index==0.6.0\n",
        "!pip3 install pymongo\n",
        "!pip3 install nltk\n",
        "!pip3 install Pillow\n",
        "!pip3 install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a54d1c43-4b7f-4917-939f-a964f6f3dafc",
      "metadata": {
        "id": "a54d1c43-4b7f-4917-939f-a964f6f3dafc",
        "scrolled": true,
        "tags": []
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa67fa07-1395-4aab-a356-72bdb302f6b2",
      "metadata": {
        "id": "fa67fa07-1395-4aab-a356-72bdb302f6b2",
        "scrolled": true,
        "tags": []
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import sys\n",
        "\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d12d766-3ca8-4012-9da2-248be80bb6ab",
      "metadata": {
        "id": "1d12d766-3ca8-4012-9da2-248be80bb6ab",
        "scrolled": true,
        "tags": [],
        "outputId": "d7424f6b-9a86-4164-f660-8f4708a6bb69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:numexpr.utils:Note: NumExpr detected 10 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "Note: NumExpr detected 10 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n",
            "NumExpr defaulting to 8 threads.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from llama_index import (\n",
        "    LLMPredictor,\n",
        "    GPTVectorStoreIndex,\n",
        "    GPTListIndex,\n",
        "    GPTSimpleKeywordTableIndex,\n",
        "    download_loader\n",
        ")\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from llama_index.response.notebook_utils import display_response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tinxuHz_05Vu",
      "metadata": {
        "id": "tinxuHz_05Vu"
      },
      "source": [
        "### INTRO\n",
        "\n",
        "At a basic level, LlamaIndex takes your documents and breaks them into chunks called nodes.\n",
        "\n",
        "Workflow:\n",
        "1) Connect the private knowledge sources using LlamaIndex connectors.\n",
        "2) Load in the Documents. A ‘LlamaIndex Document’ represents a lightweight container around the data source.\n",
        "3) Parse the ‘LlamaIndex Documents’ objects into ‘LlamaIndex Nodes’ objects. Nodes represent “chunks” of source ‘LlamaIndex Documents’ (ex., a text chunk). These node objects can be persisted in a MongoDB collection.\n",
        "4) Construct ‘LlamaIndex Index’ from ‘LlamaIndex Nodes’. There are various kinds of indexes in LlamaIndex, like “List Index” (which stores Nodes as a Sequential chain) and “Vector Store Index” (this stores each node and a corresponding embedding in a vector store). Depending on the type of Index, these indexes can be persisted into a MongoDB collection or a Vector Database.\n",
        "5) Finally, query the Index. The query is parsed at this step; relevant Nodes are retrieved through indexes and provided as input to the “Large Language Model” (LLM). Different types of queries can use different indexes.\n",
        "\n",
        "\n",
        "Use of Indexes:\n",
        "For summarization, you have two options: GPTListIndex or GPTVectorStoreIndex with response_mode=\"tree_summarize\". The distinction lies in the approach taken to generate the summary. A list index utilizes every node in the index to create the summary, while a vector index utilizes only the top k nodes to generate a summary.\n",
        "\n",
        "For Q&A, GPTVectorStoreIndex can be used. During the query, the system fetches the top k most relevant nodes based on your query text. These nodes are then used as context to synthesize an answer using the LLM."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "977352b8",
      "metadata": {
        "id": "977352b8"
      },
      "source": [
        "### Initialize OpenAI and MongoDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8758826e",
      "metadata": {
        "id": "8758826e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6dd9d5f-a601-4097-894e-fe98a0c35a5b",
      "metadata": {
        "id": "f6dd9d5f-a601-4097-894e-fe98a0c35a5b"
      },
      "source": [
        "#### Load Documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d4c9479-8bfd-4f2b-b4d3-bd4d4af0cbff",
      "metadata": {
        "id": "0d4c9479-8bfd-4f2b-b4d3-bd4d4af0cbff",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# In this example we load in GPT-4 paper\n",
        "import requests\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "PDFReader = download_loader(\"PDFReader\")\n",
        "loader = PDFReader()\n",
        "\n",
        "out_dir = Path(\"data\")\n",
        "if not out_dir.exists():\n",
        "    os.makedirs(out_dir)\n",
        "out_path = out_dir / \"paper.pdf\"\n",
        "\n",
        "if not out_path.exists():\n",
        "    url = 'https://arxiv.org/pdf/2303.08774.pdf'\n",
        "    r = requests.get(url)\n",
        "    with open(out_path, 'wb') as f:\n",
        "        f.write(r.content)\n",
        "\n",
        "doc = loader.load_data(file=Path(out_path))[0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bae82b55-5c9f-432a-9e06-1fccb6f9fc7f",
      "metadata": {
        "id": "bae82b55-5c9f-432a-9e06-1fccb6f9fc7f"
      },
      "source": [
        "#### Parse into Nodes\n",
        "Document stores contain ingested document chunks, which LlamaIndex calls 'Node' objects.\n",
        "\n",
        "\n",
        "By default, the SimpleDocumentStore stores Node objects in-memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f97e558a-c29f-44ec-ab33-1f481da1a6ef",
      "metadata": {
        "id": "f97e558a-c29f-44ec-ab33-1f481da1a6ef",
        "scrolled": true,
        "tags": []
      },
      "outputs": [],
      "source": [
        "from llama_index.node_parser import SimpleNodeParser\n",
        "nodes = SimpleNodeParser().get_nodes_from_documents([doc])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b81e70f",
      "metadata": {
        "id": "7b81e70f"
      },
      "source": [
        "## Persisting nodes and indexes to MongoDB\n",
        "There is an option to persist the nodes as an actual collection in mongoDB using MongoDocumentStore. Here we would persist the data in mongoDB.\n",
        "Storing the ‘LlamaIndex documents’ and indexes in a database becomes necessary in a couple of scenarios:\n",
        "(a) Use cases where large datasets require more than in-memory storage.\n",
        "(b) Ingesting and processing data from various sources (for example, PDFs, google docs, Slack).\n",
        "(c) The requirement to continuously maintain updates from the underlying data sources.\n",
        "\n",
        "Being able to persist this data enables processing the data once and then being able to query it for various downstream applications. You can easily reconnect to your MongoDB collection and reload the index by re-initializing a MongoIndexStore with an existing db_name and collection_name.\n",
        "\n",
        "MongoDB offers a free forever Atlas cluster in the public cloud service of your choice. Quickly create a free forever Atlas cluster by following this [tutorial](https://www.mongodb.com/developer/products/atlas/free-atlas-cluster/). Or you can get started directly [here](https://www.mongodb.com/cloud/atlas/register).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a6071d9",
      "metadata": {
        "id": "3a6071d9"
      },
      "outputs": [],
      "source": [
        "MONGO_URI = os.environ[\"MONGO_URI\"]\n",
        "MONGODB_DATABASE = \"gpt4_paper\"\n",
        "# Note: You can configure the db_name and namespace when instantiating MongoDocumentStore & MongoIndexStore,\n",
        "# otherwise they default to db_name=\"db_docstore\" and namespace=\"docstore\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aff4c8e1-b2ba-4ea6-a8df-978c2788fedc",
      "metadata": {
        "id": "aff4c8e1-b2ba-4ea6-a8df-978c2788fedc"
      },
      "source": [
        "#### Add Nodes to MongoDB backed Docstore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d46adf9a",
      "metadata": {
        "id": "d46adf9a"
      },
      "outputs": [],
      "source": [
        "from llama_index.storage.docstore import MongoDocumentStore\n",
        "docstore = MongoDocumentStore.from_uri(uri=MONGO_URI)\n",
        "\n",
        "docstore.add_documents(nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b262e0ce",
      "metadata": {
        "id": "b262e0ce"
      },
      "source": [
        "This would result in a new collection called `docstore/data` and `docstore/metadata` being created in mongoDB"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69ec9c02",
      "metadata": {
        "id": "69ec9c02"
      },
      "source": [
        "![MongoDocumentStore](https://drive.google.com/uc?export=view&id=1PrMet1I8bWfd-6pf4YK8RtQmRYFpLdVu)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5f85f6d",
      "metadata": {
        "id": "a5f85f6d"
      },
      "source": [
        "### Define Indexes & Store them in MongoDB\n",
        "\n",
        "\n",
        "Each index uses the same underlying Docstore."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b61db18",
      "metadata": {
        "id": "1b61db18"
      },
      "outputs": [],
      "source": [
        "from llama_index.storage.docstore import MongoDocumentStore\n",
        "from llama_index.storage.index_store import MongoIndexStore\n",
        "from llama_index.storage.storage_context import StorageContext\n",
        "\n",
        "storage_context = StorageContext.from_defaults(\n",
        "    docstore=MongoDocumentStore.from_uri(uri=MONGO_URI, db_name=MONGODB_DATABASE),\n",
        "    index_store=MongoIndexStore.from_uri(uri=MONGO_URI, db_name=MONGODB_DATABASE),\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "409d5d13",
      "metadata": {
        "id": "409d5d13",
        "outputId": "5657caba-dcf8-4e74-e6ee-b26b4d4c752c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
            "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
            "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 0 tokens\n",
            "> [build_index_from_nodes] Total embedding token usage: 0 tokens\n"
          ]
        }
      ],
      "source": [
        "list_index = GPTListIndex(nodes, storage_context=storage_context)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2f4c6be",
      "metadata": {
        "id": "c2f4c6be",
        "outputId": "7d4109c5-1114-4a41-f589-5e7b5716060f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
            "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
            "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 97155 tokens\n",
            "> [build_index_from_nodes] Total embedding token usage: 97155 tokens\n"
          ]
        }
      ],
      "source": [
        "vector_index = GPTVectorStoreIndex(nodes, storage_context=storage_context)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4d8ef30",
      "metadata": {
        "id": "c4d8ef30",
        "outputId": "667c7fd8-3d27-429c-be81-fe2aa930ad50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
            "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
            "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 0 tokens\n",
            "> [build_index_from_nodes] Total embedding token usage: 0 tokens\n"
          ]
        }
      ],
      "source": [
        "keyword_table_index = GPTSimpleKeywordTableIndex(nodes, storage_context=storage_context)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dgqVlJrd-ajJ",
      "metadata": {
        "id": "dgqVlJrd-ajJ"
      },
      "source": [
        "This would result in a new collection called `index_store/data` being created in mongoDB"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1b2293a",
      "metadata": {
        "id": "c1b2293a"
      },
      "source": [
        "![MongoIndexStore](https://drive.google.com/uc?export=view&id=1JkpyWyJjXLLC-0i1Q2NCflDG5RyDUQbk)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "948a5b10",
      "metadata": {
        "id": "948a5b10"
      },
      "source": [
        "### Retrieve Nodes from MongoDB Docstore\n",
        "\n",
        "(This is an OPTIONAL step. If you have been following along till now, the documents are already loaded in-memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ba8b0da-67a8-4653-8cdb-09e39583a2d8",
      "metadata": {
        "id": "1ba8b0da-67a8-4653-8cdb-09e39583a2d8",
        "scrolled": true,
        "tags": []
      },
      "outputs": [],
      "source": [
        "from llama_index.storage.docstore import MongoDocumentStore\n",
        "docstore = MongoDocumentStore.from_uri(uri=MONGO_URI, db_name=MONGODB_DATABASE)\n",
        "nodes = list(docstore.docs.values())\n",
        "\n",
        "# NOTE: Verify that the docstore still has the same nodes\n",
        "len(docstore.docs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3bf6aaf-3375-4212-8323-777969a918f7",
      "metadata": {
        "id": "d3bf6aaf-3375-4212-8323-777969a918f7"
      },
      "source": [
        "## Test out some Queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "036077b7-108e-4026-9628-44c694343460",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "036077b7-108e-4026-9628-44c694343460",
        "outputId": "f29f60c0-da63-46ee-d5cd-9a8a74c0fcc8",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
            "> [retrieve] Total LLM token usage: 0 tokens\n",
            "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 11 tokens\n",
            "> [retrieve] Total embedding token usage: 11 tokens\n",
            "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 1996 tokens\n",
            "> [get_response] Total LLM token usage: 1996 tokens\n",
            "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
            "> [get_response] Total embedding token usage: 0 tokens\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "**`Final Response:`** GPT-4 performs well on the Uniform Bar Exam, achieving a score in the top 10% of test takers (Table 1, Figure 4)."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "---"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "**`Source Node 1/2`**"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "**Document ID:** 4ecd6a4d-b2f3-423a-bff8-28971258a752<br>**Similarity:** 0.8548833172733542<br>**Text:** knowledge) 86 % 86 % 58 %\n",
              "Advanced Sommelier (theory knowledge) 77 % 77 % 46 %\n",
              "Leetcode (easy) 31...<br>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "---"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "**`Source Node 2/2`**"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "**Document ID:** cb9d2c43-2f71-4047-a7ce-d53115827dd2<br>**Similarity:** 0.8320178432122729<br>**Text:** 213 / 400 (~10th)\n",
              "LSAT 163 (~88th) 161 (~83rd) 149 (~40th)\n",
              "SAT Evidence-Based Reading & Writing 7...<br>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'4ecd6a4d-b2f3-423a-bff8-28971258a752': None,\n",
              " 'cb9d2c43-2f71-4047-a7ce-d53115827dd2': None}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "vector_response = vector_index.as_query_engine().query(\"How does GPT4 do on the bar exam?\")\n",
        "display_response(vector_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff58018c-3117-4d50-abff-16a1873eda9c",
      "metadata": {
        "id": "ff58018c-3117-4d50-abff-16a1873eda9c",
        "scrolled": true,
        "outputId": "13fc8143-78f3-412f-815f-ad6c5c11b728"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
            "> [retrieve] Total LLM token usage: 0 tokens\n",
            "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 17 tokens\n",
            "> [retrieve] Total embedding token usage: 17 tokens\n",
            "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 1890 tokens\n",
            "> [get_response] Total LLM token usage: 1890 tokens\n",
            "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
            "> [get_response] Total embedding token usage: 0 tokens\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "**`Final Response:`** After RLHF fine-tuning, GPT-4 was observed to be overly cautious in certain ways, refusing innocuous requests and excessively hedging or \"overrefusing\". Additionally, the post-training process was observed to reduce the calibration of the model."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "---"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "**`Source Node 1/2`**"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "**Document ID:** a438be10-f028-4b53-aa7c-280b48e10716<br>**Similarity:** 0.842341961779629<br>**Text:** 5-shot RLHF0%10%20%30%40%50%60%70%\n",
              "ModelAccuracyAccuracy on adversarial questions (TruthfulQA mc1...<br>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "---"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "**`Source Node 2/2`**"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "**Document ID:** e17b25d7-070f-449b-8235-830ae763f0a6<br>**Similarity:** 0.8396913346010052<br>**Text:** and\n",
              "improve how users experience the model (e.g., to reduce risk of overreliance).27\n",
              "3.1 Model Mi...<br>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'a438be10-f028-4b53-aa7c-280b48e10716': None,\n",
              " 'e17b25d7-070f-449b-8235-830ae763f0a6': None}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "vector_response = vector_index.as_query_engine().query(\"What issues were observed after fine-tuning GPT-4 with RLHF?\")\n",
        "display_response(vector_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aeb8e427",
      "metadata": {
        "id": "aeb8e427"
      },
      "outputs": [],
      "source": [
        "vector_response = vector_index.as_query_engine().query(\"What is RBRM?\")\n",
        "display_response(vector_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f2f8fc0",
      "metadata": {
        "id": "3f2f8fc0"
      },
      "outputs": [],
      "source": [
        "vector_response = vector_index.as_query_engine().query(\"How much better is GPT-4 in reducing hallucinations over GPT-3.5?\")\n",
        "display_response(vector_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "544c0565-72a0-434b-98e5-83138ebdaa2b",
      "metadata": {
        "id": "544c0565-72a0-434b-98e5-83138ebdaa2b",
        "scrolled": true,
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Note: This will take a while to execute\n",
        "# You set use_async=True and response_mode=\"tree_summarize\"\n",
        "query_engine = list_index.as_query_engine()\n",
        "\n",
        "list_response = query_engine.query(\n",
        "    \"What is a summary of this document?\"\n",
        ")\n",
        "\n",
        "display_response(list_response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "aff4c8e1-b2ba-4ea6-a8df-978c2788fedc"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}