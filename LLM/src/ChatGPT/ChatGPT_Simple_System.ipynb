{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyPBUp1lRJH6z/lOkxj4Q8Ed"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Language Models, the Chat Format and Tokens\n","\n","## Setup"],"metadata":{"id":"wm07KhCAVXga"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iMH4cIE86FRi","executionInfo":{"status":"ok","timestamp":1686053543431,"user_tz":-540,"elapsed":23433,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"add9b127-48bd-4bc5-945f-fdd40082e48e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive/')"]},{"cell_type":"code","source":["import os\n","os.chdir(\"drive/\")\n","os.chdir('My Drive')\n","os.chdir('Experiment')\n","os.chdir('ChatGPT')"],"metadata":{"id":"D613nlta7wzS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["OUTPUT_DIR = './outputs/'\n","if not os.path.exists(OUTPUT_DIR):\n","    os.makedirs(OUTPUT_DIR)"],"metadata":{"id":"GaCLZWGL7zzs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install openai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RXFg0muqg1oS","executionInfo":{"status":"ok","timestamp":1686053554424,"user_tz":-540,"elapsed":10379,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"0377a412-742e-44ed-c82c-5e16c7f77700"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting openai\n","  Downloading openai-0.27.7-py3-none-any.whl (71 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n","Collecting aiohttp (from openai)\n","  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n","Collecting multidict<7.0,>=4.5 (from aiohttp->openai)\n","  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n","  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->openai)\n","  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->openai)\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.7 yarl-1.9.2\n"]}]},{"cell_type":"code","source":["import openai\n","import os\n","\n","from dotenv import load_dotenv, find_dotenv\n","_ = load_dotenv(find_dotenv())\n","\n","openai.api_key  = os.getenv('OPENAI_API_KEY')"],"metadata":{"id":"FjkVvEzwVeLp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### helper function\n","\n","Throughout this course, we will use OpenAI's `gpt-3.5-turbo` model and the [chat completions endpoint](https://platform.openai.com/docs/guides/chat). \n","\n","This helper function will make it easier to use prompts and look at the generated outputs:"],"metadata":{"id":"LSrlOMpwVlR1"}},{"cell_type":"code","source":["def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n","    messages = [{\"role\": \"user\", \"content\": prompt}]\n","    response = openai.ChatCompletion.create(\n","        model=model,\n","        messages=messages,\n","        temperature=0, # this is the degree of randomness of the model's output\n","    )\n","    return response.choices[0].message[\"content\"]"],"metadata":{"id":"8Y0jVc7FVeJB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_completion_from_messages(messages, model=\"gpt-3.5-turbo\", temperature=0, max_tokens=500):\n","    response = openai.ChatCompletion.create(\n","        model=model,\n","        messages=messages,\n","        temperature=temperature, # this is the degree of randomness of the model's output\n","        max_tokens=max_tokens, # the maximum number of tokens the model can ouptut \n","    )\n","    return response.choices[0].message[\"content\"]"],"metadata":{"id":"iP5Rp9yINpDW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_completion_and_token_count(messages, model=\"gpt-3.5-turbo\", temperature=0, max_tokens=500):\n","    \n","    response = openai.ChatCompletion.create(\n","        model=model,\n","        messages=messages,\n","        temperature=temperature, \n","        max_tokens=max_tokens,\n","    )\n","    \n","    content = response.choices[0].message[\"content\"]\n","    \n","    token_dict = {\n","      'prompt_tokens':response['usage']['prompt_tokens'],\n","      'completion_tokens':response['usage']['completion_tokens'],\n","      'total_tokens':response['usage']['total_tokens'],\n","    }\n","\n","    return content, token_dict"],"metadata":{"id":"ipV7RoQLmDZe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Prompt the model and get a completion"],"metadata":{"id":"ZahPUuuelPZk"}},{"cell_type":"code","source":["response = get_completion(\"What is the capital of France?\")\n","print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rRWFFNkzlQHQ","executionInfo":{"status":"ok","timestamp":1686053557200,"user_tz":-540,"elapsed":2780,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"2a48d820-2813-43c6-c96f-8b6b4e16dba0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The capital of France is Paris.\n"]}]},{"cell_type":"markdown","source":["## Tokens"],"metadata":{"id":"BOGcd2_tlT_t"}},{"cell_type":"code","source":["response = get_completion(\"Take the letters in lollipop and reverse them\")\n","print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_SHqGHyYlQEd","executionInfo":{"status":"ok","timestamp":1686053557921,"user_tz":-540,"elapsed":723,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"60503a9b-d129-4695-e05d-daa1d71f781c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ppilolol\n"]}]},{"cell_type":"markdown","source":["\"lollipop\" in reverse should be \"popillol\""],"metadata":{"id":"ou4zx9ChlXnY"}},{"cell_type":"code","source":["response = get_completion(\"\"\"Take the letters in l-o-l-l-i-p-o-p and reverse them\"\"\")\n","print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dEFtc4TulP_r","executionInfo":{"status":"ok","timestamp":1686053601882,"user_tz":-540,"elapsed":43964,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"774fe9e3-a197-466d-e8b0-2285021d2ed6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["p-o-p-i-l-l-o-l\n"]}]},{"cell_type":"markdown","source":["## With formatted messages"],"metadata":{"id":"d5SKTnswlwaL"}},{"cell_type":"code","source":["messages =  [  \n","  {'role':'system', \n","  'content':\"\"\"You are an assistant who responds in the style of Dr Seuss.\"\"\"},    \n","  {'role':'user', \n","  'content':\"\"\"write me a very short poem about a happy carrot\"\"\"},  \n","] \n","response = get_completion_from_messages(messages, temperature=1)\n","print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7w2gFaSalP84","executionInfo":{"status":"ok","timestamp":1686053605507,"user_tz":-540,"elapsed":3629,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"ecb2e0dd-918d-44ac-a918-f7009d8b0ca7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Oh, the happy orange carrot,\n","With a smile as big as a parrot,\n","Growing in the garden so green,\n","Oh, how happy it has been!\n"]}]},{"cell_type":"code","source":["# length\n","messages =  [  \n","  {'role':'system',\n","  'content':'All your responses must be \\\n","  one sentence long.'},    \n","  {'role':'user',\n","  'content':'write me a story about a happy carrot'},  \n","]\n","response = get_completion_from_messages(messages, temperature =1)\n","print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_LJwuduXlP4q","executionInfo":{"status":"ok","timestamp":1686053609059,"user_tz":-540,"elapsed":3556,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"bd1391af-2316-412c-a4ab-6b80693b51a8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Once upon a time, there lived a happy carrot named Carl who lived in a beautiful garden and loved nothing more than basking in the warm sun and soaking up the fresh rainwater.\n"]}]},{"cell_type":"code","source":["# length\n","messages =  [  \n","{'role':'system',\n"," 'content':'All your responses must be \\\n","one sentence long.'},    \n","{'role':'user',\n"," 'content':'write me a story about a happy carrot'},  \n","]\n","response = get_completion_from_messages(messages, temperature =1)\n","print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZiwxDSwflP2H","executionInfo":{"status":"ok","timestamp":1686053613957,"user_tz":-540,"elapsed":4917,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"6612cc46-874f-45ca-9f54-0e42ad226b41"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Once there was a carrot named Carl who grew to be plump and bright, always gleeful in his patch and when he was harvested, he became the starring ingredient in a delicious bowl of soup that brought smiles to everyone who tasted it.\n"]}]},{"cell_type":"code","source":["# combined\n","messages =  [  \n","{'role':'system',\n"," 'content':\"\"\"You are an assistant who \\\n","responds in the style of Dr Seuss. \\\n","All your responses must be one sentence long.\"\"\"},    \n","{'role':'user',\n"," 'content':\"\"\"write me a story about a happy carrot\"\"\"},\n","] \n","response = get_completion_from_messages(messages, \n","                                        temperature =1)\n","print(response)"],"metadata":{"id":"4iPcOJYCk06k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686053617464,"user_tz":-540,"elapsed":3526,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"8ee0fac2-fed5-42eb-b404-6dec35b23c66"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["In a garden so bright, lived a carrot so cheery and light; he loved chatting with the bees and the birds, and every morning he smiled at the rising sun without any words.\n"]}]},{"cell_type":"code","source":["messages = [\n","  {'role':'system', \n","  'content':\"\"\"You are an assistant who responds\\\n","  in the style of Dr Seuss.\"\"\"},    \n","  {'role':'user',\n","  'content':\"\"\"write me a very short poem \\ \n","  about a happy carrot\"\"\"},  \n","]\n","\n","\n","response, token_dict = get_completion_and_token_count(messages)"],"metadata":{"id":"Rqwc3F3zmAq-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VGqbLFUZmAoY","executionInfo":{"status":"ok","timestamp":1686053622459,"user_tz":-540,"elapsed":14,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"ce06f5d3-c240-41b2-ff07-914312547c3a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Oh, the happy carrot, so bright and so bold,\n","With a smile on its face, and a story untold.\n","It grew in the garden, with love and with care,\n","And now it's so happy, it's beyond compare!\n"]}]},{"cell_type":"code","source":["print(token_dict)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W2XfvsK2mAkM","executionInfo":{"status":"ok","timestamp":1686053622459,"user_tz":-540,"elapsed":10,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"d0c34bae-01d4-4913-840e-fd3b4a30b823"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'prompt_tokens': 41, 'completion_tokens': 49, 'total_tokens': 90}\n"]}]},{"cell_type":"markdown","source":["#### A note about the backslash\n","\n","- In the notebook, we are using a backslash `\\` to make the text fit on the screen without inserting newline '\\n' characters.\n","- GPT-3 isn't really affected whether you insert newline characters or not.  But when working with LLMs in general, you may consider whether newline characters in your prompt may affect the model's performance."],"metadata":{"id":"t_vlPvXlmSv2"}},{"cell_type":"code","source":[],"metadata":{"id":"gfzyWfKqmAd5"},"execution_count":null,"outputs":[]}]}