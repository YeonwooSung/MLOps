{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "821ad079",
   "metadata": {},
   "source": [
    "# Topic Modeling With Language Models\n",
    "\n",
    "*View this code on [Github](https://github.com/gkamradt/langchain-tutorials/blob/main/data_generation/Topic%20Modeling%20With%20Language%20Models.ipynb)*\n",
    "\n",
    "\n",
    "Topic Modeling is the practice of pulling out categorized groups of information from a piece of longer text.\n",
    "\n",
    "Example: Inferring chapters from a book or segments of a movie. This is a classic data science topic that has been studied for years. Check out examples from previous research like [scikit-learn](https://towardsdatascience.com/introduction-to-topic-modeling-using-scikit-learn-4c3f3290f5b9) and [BERTopic](https://www.youtube.com/watch?v=uZxQz87lb84) if you want to see these techniques.\n",
    "\n",
    "However today we are going to take a pass at this problem using language models. Why? Language models are extremely good at processing text and pulling out big picture ideas from a document.\n",
    "\n",
    "There are many methods to do this and my goal for today's tutorial is to show you a few different approaches so you can apply it to your own scenario.\n",
    "\n",
    "In this lesson we are prioritizing comprehensiveness and robustness of information over API costs so please be mindful of your expense comfortability.\n",
    "\n",
    "I'll be taking a 2-pass approach today:\n",
    "* **1st Pass:** Run through the entire document via map reduce and pull out topics as bullet points\n",
    "* **2nd Pass:** Iterate through your topic bullet points and expand on them with a subset of context that was selected via retrieval\n",
    "\n",
    "\n",
    "Today we are going to be looking at a [My First Million](https://www.mfmpod.com/) podcast because it's rich with segments, ideas, sayings, and stories. Great for topic parsing!\n",
    "\n",
    "**Bonus**: As a bonus we are also going to be looking at how to auto generate timestamps for each topic as well. The most common use case of this is YouTube Chapters\n",
    "\n",
    "**My Assumptions**\n",
    "* You don't have a table of contents. That would definitely help out (since a human likely generated them) but I want to make this method as general as possible so you can apply it\n",
    "* You want to *learn* the nuts and bolts how to do this. If you wanted a 3rd party tool to do this for you I suggest something like [AssemblyAI](https://www.assemblyai.com/) or [PodcastNotes](https://podcastnotes.org/) \n",
    "\n",
    "### Use Cases:\n",
    "\n",
    "* **YouTube Videos** - Auto Chapter Generation\n",
    "* **Podcasts** - Extract structured information\n",
    "* **Meeting Notes** - Send topic summaries to participants\n",
    "* **Town Hall Meetings** - Structured information\n",
    "* **Earnings Report Calls** - Sell structured data to investment groups\n",
    "* **Legal Documents** - Quickly summarize by topic\n",
    "* **Movie Scripts** - Quick bullet points for production recaps\n",
    "* **Books** - Auto generate table of contents\n",
    "\n",
    "Finally, if you want to see the inspiration for this tutorial, [here's the tweet](https://twitter.com/GregKamradt/status/1651957952725807106) that started it all.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de3e5a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make the display a bit wider\n",
    "# from IPython.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "# LangChain basics\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.chains import create_extraction_chain\n",
    "\n",
    "# Vector Store and retrievals\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import Pinecone\n",
    "import pinecone\n",
    "\n",
    "# Chat Prompt templates for dynamic values\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "\n",
    "# Supporting libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67bf65b",
   "metadata": {},
   "source": [
    "### The Set Up - Create your LLMs and get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17ef4d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating two versions of the model so I can swap between gpt3.5 and gpt4\n",
    "llm3 = ChatOpenAI(temperature=0,\n",
    "                  openai_api_key=os.getenv('OPENAI_API_KEY', 'YourAPIKeyIfNotSet'),\n",
    "                  model_name=\"gpt-3.5-turbo-0613\",\n",
    "                  request_timeout = 180\n",
    "                )\n",
    "\n",
    "llm4 = ChatOpenAI(temperature=0,\n",
    "                  openai_api_key=os.getenv('OPENAI_API_KEY', 'YourAPIKeyIfNotSet'),\n",
    "                  model_name=\"gpt-4-0613\",\n",
    "                  request_timeout = 180\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97df506a",
   "metadata": {},
   "source": [
    "First we'll need to get transcripts. I put a few pre-processed transcripts in the data folder of this repo.\n",
    "\n",
    "If you need transcripts for your own audio I suggest a transcription tool like [AssemblyAI](https://www.assemblyai.com/). I also tried [Steno.ai](https://steno.ai/my-first-million) but the quality and speaker detection wasn't that high.\n",
    "\n",
    "Reach out if you want me to grab transcripts in bulk for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be6fb49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I put three prepared transcripts\n",
    "transcript_paths = [\n",
    "    '../data/Transcripts/MFMPod/mfm_pod_steph.txt',\n",
    "    '../data/Transcripts/MFMPod/mfm_pod_alex.txt',\n",
    "    '../data/Transcripts/MFMPod/mfm_pod_rob.txt'\n",
    "]\n",
    "\n",
    "with open('../data/Transcripts/MFMPod/mfm_pod_steph.txt') as file:\n",
    "    transcript = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fd28ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shaan Puri (0:00:00-0:00:03): D to see hearing AIDS. I think that's actually going to be a big deal. \n",
      "\n",
      "Sam Parr (0:00:03-0:00:05): And they're profitable. \n",
      "\n",
      "Shaan Puri (0:00:05-0:00:08): I mean, I'm just turning you on. Yeah, they were. \n",
      "\n",
      "Sam Parr (0:00:12-0:00:13): They Mormon. \n"
     ]
    }
   ],
   "source": [
    "print(transcript[:280])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c7b13f",
   "metadata": {},
   "source": [
    "Then we are going to split our text up into chunks. We do this so:\n",
    "\n",
    "1. The context size is smaller and the LLM can increase it's attention to context ratio\n",
    "2. In case the text is too long and it wouldn't fit in the prompt anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce687f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 3 docs. First doc is 2801 tokens\n"
     ]
    }
   ],
   "source": [
    "# Load up your text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\", \"\\n\", \" \"], chunk_size=10000, chunk_overlap=2200)\n",
    "\n",
    "# I'm only doing the first 23250 characters. This to save on costs. When you're doing your exercise you can remove this to let all the data through\n",
    "transcript_subsection_characters = 23250\n",
    "docs = text_splitter.create_documents([transcript[:transcript_subsection_characters]])\n",
    "print (f\"You have {len(docs)} docs. First doc is {llm3.get_num_tokens(docs[0].page_content)} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb048dd1",
   "metadata": {},
   "source": [
    "## Step 1: Extract Topic Titles & Short Description\n",
    "\n",
    "### The Custom Prompts - Customize your prompt to fit your use case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5e4b2a",
   "metadata": {},
   "source": [
    "Next up I'm going to use custom prompts to instruct the LLM on how to pull out the topics I want.\n",
    "\n",
    "This will be heavily dependent on your domain. You should adjust the prompt below to use descriptions and examples that are relevant to you.\n",
    "\n",
    "I built these descriptions over many iterations playing with prompts and checking the output. If you ever start a business this will be part of your IP!\n",
    "\n",
    "I will ask the LLM for a topic title and a short description. I found it was too much for the LLM to ask for a long description in the first pass. Results weren't great and high latency.\n",
    "\n",
    "Let's start with our map prompt which will iterate over the chunks we just made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9792cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"\"\"\n",
    "You are a helpful assistant that helps retrieve topics talked about in a podcast transcript\n",
    "- Your goal is to extract the topic names and brief 1-sentence description of the topic\n",
    "- Topics include:\n",
    "  - Themes\n",
    "  - Business Ideas\n",
    "  - Interesting Stories\n",
    "  - Money making businesses\n",
    "  - Quick stories about people\n",
    "  - Mental Frameworks\n",
    "  - Stories about an industry\n",
    "  - Analogies mentioned\n",
    "  - Advice or words of caution\n",
    "  - Pieces of news or current events\n",
    "- Provide a brief description of the topics after the topic name. Example: 'Topic: Brief Description'\n",
    "- Use the same words and terminology that is said in the podcast\n",
    "- Do not respond with anything outside of the podcast. If you don't see any topics, say, 'No Topics'\n",
    "- Do not respond with numbers, just bullet points\n",
    "- Do not include anything about 'Marketing Against the Grain'\n",
    "- Only pull topics from the transcript. Do not use the examples\n",
    "- Make your titles descriptive but concise. Example: 'Shaan's Experience at Twitch' should be 'Shaan's Interesting Projects At Twitch'\n",
    "- A topic should be substantial, more than just a one-off comment\n",
    "\n",
    "% START OF EXAMPLES\n",
    " - Sam’s Elisabeth Murdoch Story: Sam got a call from Elizabeth Murdoch when he had just launched The Hustle. She wanted to generate video content.\n",
    " - Shaan’s Rupert Murdoch Story: When Shaan was running Blab he was invited to an event organized by Rupert Murdoch during CES in Las Vegas.\n",
    " - Revenge Against The Spam Calls: A couple of businesses focused on protecting consumers: RoboCall, TrueCaller, DoNotPay, FitIt\n",
    " - Wildcard CEOs vs. Prudent CEOs: However, Munger likes to surround himself with prudent CEO’s and says he would never hire Musk.\n",
    " - Chess Business: Priyav, a college student, expressed his doubts on the MFM Facebook group about his Chess training business, mychesstutor.com, making $12.5K MRR with 90 enrolled.\n",
    " - Restaurant Refiller: An MFM Facebook group member commented on how they pay AirMark $1,000/month for toilet paper and toilet cover refills for their restaurant. Shaan sees an opportunity here for anyone wanting to compete against AirMark.\n",
    " - Collecting: Shaan shared an idea to build a mobile only marketplace for a collectors’ category; similar to what StockX does for premium sneakers.\n",
    "% END OF EXAMPLES\n",
    "\"\"\"\n",
    "system_message_prompt_map = SystemMessagePromptTemplate.from_template(template)\n",
    "\n",
    "human_template=\"Transcript: {text}\" # Simply just pass the text as a human message\n",
    "human_message_prompt_map = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt_map = ChatPromptTemplate.from_messages(messages=[system_message_prompt_map, human_message_prompt_map])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6825c1",
   "metadata": {},
   "source": [
    "Then we have our combine prompt which will run once over the results of the map prompt above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75d6fc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"\"\"\n",
    "You are a helpful assistant that helps retrieve topics talked about in a podcast transcript\n",
    "- You will be given a series of bullet topics of topics vound\n",
    "- Your goal is to exract the topic names and brief 1-sentence description of the topic\n",
    "- Deduplicate any bullet points you see\n",
    "- Only pull topics from the transcript. Do not use the examples\n",
    "\n",
    "% START OF EXAMPLES\n",
    " - Sam’s Elisabeth Murdoch Story: Sam got a call from Elizabeth Murdoch when he had just launched The Hustle. She wanted to generate video content.\n",
    " - Shaan’s Rupert Murdoch Story: When Shaan was running Blab he was invited to an event organized by Rupert Murdoch during CES in Las Vegas.\n",
    "% END OF EXAMPLES\n",
    "\"\"\"\n",
    "system_message_prompt_map = SystemMessagePromptTemplate.from_template(template)\n",
    "\n",
    "human_template=\"Transcript: {text}\" # Simply just pass the text as a human message\n",
    "human_message_prompt_map = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt_combine = ChatPromptTemplate.from_messages(messages=[system_message_prompt_map, human_message_prompt_map])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1e906a",
   "metadata": {},
   "source": [
    "### The First Pass - Run through your text and extract the topics per your custom prompts\n",
    "Then we get our chain ready. This is object that will do the actual processing for us when we call it. I'm using gpt4 because we need the increased reasoning ability to pull out topics. You could use gpt3.5 but results may vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0bb61ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_summarize_chain(llm4,\n",
    "                             chain_type=\"map_reduce\",\n",
    "                             map_prompt=chat_prompt_map,\n",
    "                             combine_prompt=chat_prompt_combine,\n",
    "#                              verbose=True\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b12aed",
   "metadata": {},
   "source": [
    "Then the `.run()` code below will do the actual API calls and work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98b9b205",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topics_found = chain.run({\"input_documents\": docs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f6bcb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Children's Play Space Business Idea: Shaan shared a concept about a membership-based children's play space, but clarified he doesn't endorse it.\n",
      "- Steph Smith's Career Journey: Sam Parr talked about discovering Steph Smith through her blog and inviting her to join The Hustle's Trends team, who now works at Andreessen Horowitz.\n",
      "- Working at Andreessen Horowitz: Steph Smith discussed her experience at Andreessen Horowitz, mentioning her remote work arrangement and occasional office visits.\n",
      "- Adam Bornstein's Health Book: Sam Parr mentioned Adam Bornstein's new book \"You Can't Screw This Up,\" which provides tips for healthier diet habits.\n",
      "- Importance of Consistency: Sam Parr and Steph Smith emphasized the role of consistency in achieving greatness, referencing a blog post by Steph.\n",
      "- Sam's Master Plan at Facebook: Sam advised his wife to be proactive at Facebook meetings to get noticed and potentially invited to dinner by the CEO.\n",
      "- Shaan's Strategy at Twitch: Shaan shared his strategy at Twitch of attending interesting meetings and interacting with interesting people.\n",
      "- Commercial Real Estate Crisis: The hosts discussed the crisis in commercial real estate, with high vacancy rates, particularly in cities like San Francisco.\n",
      "- Fractional Real Estate Opportunity: Steph Smith introduced fractional real estate as a potential solution to the commercial real estate crisis, using Temple Immersive as an example.\n",
      "- Temple Immersive: Discussed as an example of fractional real estate, a nightclub used as a yoga studio during the day.\n",
      "- Rage Rooms: Steph Smith discussed the trend of rage rooms, where people pay to smash objects for stress relief, as a potential use for unused commercial spaces.\n",
      "- Escape Room Business Success: The hosts discussed Raleigh Williams' success story of creating a mobile escape room business in an abandoned bus and selling it for $26 million.\n"
     ]
    }
   ],
   "source": [
    "print (topics_found)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99caca7c",
   "metadata": {},
   "source": [
    "### Structured Data - Turn your LLM output into structured data\n",
    "\n",
    "The LLM just returned a wall of text to us, I want to convert this into structured data I can more easily use elsewhere.\n",
    "\n",
    "We might have been able to do add structured output instructions to the pull above but I preferred to do it in two steps for clarity. Plus the cost us super low so we only have latency to worry about, but that isn't a priority for this tutorial.\n",
    "\n",
    "We will use OpenAI's [function calling](function Calling via ChatGPT API - First Look With LangChain - YouTube) to extract each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b1e14c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "    \"properties\": {\n",
    "        # The title of the topic\n",
    "        \"topic_name\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\" : \"The title of the topic listed\"\n",
    "        },\n",
    "        # The description\n",
    "        \"description\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\" : \"The description of the topic listed\"\n",
    "        },\n",
    "        \"tag\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\" : \"The type of content being described\",\n",
    "            \"enum\" : ['Business Models', 'Life Advice', 'Health & Wellness', 'Stories']\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"topic\", \"description\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32e3b595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using gpt3.5 here because this is an easy extraction task and no need to jump to gpt4\n",
    "chain = create_extraction_chain(schema, llm3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "767cfbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_structured = chain.run(topics_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28ccaa5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'topic_name': \"Children's Play Space Business Idea\",\n",
       "  'description': \"Shaan shared a concept about a membership-based children's play space, but clarified he doesn't endorse it.\",\n",
       "  'tag': 'Business Models'},\n",
       " {'topic_name': \"Steph Smith's Career Journey\",\n",
       "  'description': \"Sam Parr talked about discovering Steph Smith through her blog and inviting her to join The Hustle's Trends team, who now works at Andreessen Horowitz.\",\n",
       "  'tag': 'Business Models'},\n",
       " {'topic_name': 'Working at Andreessen Horowitz',\n",
       "  'description': 'Steph Smith discussed her experience at Andreessen Horowitz, mentioning her remote work arrangement and occasional office visits.',\n",
       "  'tag': 'Business Models'},\n",
       " {'topic_name': \"Adam Bornstein's Health Book\",\n",
       "  'description': 'Sam Parr mentioned Adam Bornstein\\'s new book \"You Can\\'t Screw This Up,\" which provides tips for healthier diet habits.',\n",
       "  'tag': 'Health & Wellness'},\n",
       " {'topic_name': 'Importance of Consistency',\n",
       "  'description': 'Sam Parr and Steph Smith emphasized the role of consistency in achieving greatness, referencing a blog post by Steph.',\n",
       "  'tag': 'Life Advice'},\n",
       " {'topic_name': \"Sam's Master Plan at Facebook\",\n",
       "  'description': 'Sam advised his wife to be proactive at Facebook meetings to get noticed and potentially invited to dinner by the CEO.',\n",
       "  'tag': 'Business Models'},\n",
       " {'topic_name': \"Shaan's Strategy at Twitch\",\n",
       "  'description': 'Shaan shared his strategy at Twitch of attending interesting meetings and interacting with interesting people.',\n",
       "  'tag': 'Business Models'},\n",
       " {'topic_name': 'Commercial Real Estate Crisis',\n",
       "  'description': 'The hosts discussed the crisis in commercial real estate, with high vacancy rates, particularly in cities like San Francisco.',\n",
       "  'tag': 'Business Models'},\n",
       " {'topic_name': 'Fractional Real Estate Opportunity',\n",
       "  'description': 'Steph Smith introduced fractional real estate as a potential solution to the commercial real estate crisis, using Temple Immersive as an example.',\n",
       "  'tag': 'Business Models'},\n",
       " {'topic_name': 'Temple Immersive',\n",
       "  'description': 'Discussed as an example of fractional real estate, a nightclub used as a yoga studio during the day.',\n",
       "  'tag': 'Business Models'},\n",
       " {'topic_name': 'Rage Rooms',\n",
       "  'description': 'Steph Smith discussed the trend of rage rooms, where people pay to smash objects for stress relief, as a potential use for unused commercial spaces.',\n",
       "  'tag': 'Business Models'},\n",
       " {'topic_name': 'Escape Room Business Success',\n",
       "  'description': \"The hosts discussed Raleigh Williams' success story of creating a mobile escape room business in an abandoned bus and selling it for $26 million.\",\n",
       "  'tag': 'Business Models'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_structured"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bea8d61",
   "metadata": {},
   "source": [
    "Great, now we have our structured topics. Let's move into the next step and *expand* on those topics even more.\n",
    "\n",
    "## Step 2: Expand on the topics you found\n",
    "\n",
    "In order to expand on the topics we found we are going to do the vectorstore dance. We'll chunk our podcast into *small* chunks and then modify the retrieval and qa chain to help us pull out more information.\n",
    "\n",
    "I want to split into small chunks to hopefully increase the signal to noise ratio. Here I'll only do 4K characters which is less than half of what we did above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0b6b833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 8 docs. First doc is 776 tokens\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=4000, chunk_overlap=800)\n",
    "\n",
    "docs = text_splitter.create_documents([transcript[:transcript_subsection_characters]])\n",
    "\n",
    "print (f\"You have {len(docs)} docs. First doc is {llm3.get_num_tokens(docs[0].page_content)} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80145b03",
   "metadata": {},
   "source": [
    "Because I want to do Question & Answer Retrieval, we need to get embeddings for our documents so we can pull out the docs which are similar for context later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "faa3a638",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key=os.getenv('OPENAI_API_KEY', 'YourAPIKeyIfNotSet'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdd1aeb",
   "metadata": {},
   "source": [
    "I tried getting Chroma and FAISS to work for a local solution but it was a huge pain in the butt and both had errors. You may have better luck. So swap out Pinecone if you'd like! Sign up at [Pinecone.io](https://www.pinecone.io/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88a021c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize pinecone\n",
    "pinecone.init(\n",
    "    api_key=os.getenv('PINECONE_API_KEY', 'YourAPIKeyIfNotSet'),  # find at app.pinecone.io\n",
    "    environment=os.getenv('PINECONE_ENV', 'YourAPIKeyIfNotSet'),  # next to api key in console\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31ce1b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"topic-modeling\"\n",
    "\n",
    "docsearch = Pinecone.from_documents(docs, embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f491256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If you want to delete your vectors in your index to start over, run the code below!\n",
    "# index = pinecone.Index(index_name)\n",
    "# index.delete(delete_all='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee90371",
   "metadata": {},
   "source": [
    "Then we are going to create a custom prompt for our Retriever. I'm doing this because the out of the [out-of-the-box](https://github.com/hwchase17/langchain/blob/7414e9d19603c962063dd337cdcf3c3168d4b8be/langchain/chains/question_answering/stuff_prompt.py#L20) prompt used here isn't bad, but a bit generic for my use case. Plus, I only really want to *answer a question* I want to generated a mini-summary based off of docs.\n",
    "\n",
    "Let's switch it up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6ee1f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The system instructions. Notice the 'context' placeholder down below. This is where our relevant docs will go.\n",
    "# The 'question' in the human message below won't be a question per se, but rather a topic we want to get relevant information on\n",
    "system_template = \"\"\"\n",
    "You will be given text from a podcast transcript which contains many topics.\n",
    "You goal is to write a summary (5 sentences or less) about a topic the user chooses\n",
    "Do not respond with information that isn't relevant to the topic that the user gives you\n",
    "----------------\n",
    "{context}\"\"\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessagePromptTemplate.from_template(system_template),\n",
    "    HumanMessagePromptTemplate.from_template(\"{question}\"),\n",
    "]\n",
    "\n",
    "# This will pull the two messages together and get them ready to be sent to the LLM through the retriever\n",
    "CHAT_PROMPT = ChatPromptTemplate.from_messages(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35eb54d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm using gpt4 for the increased reasoning power.\n",
    "# I'm also setting k=4 so the number of relevant docs we get back is 4. This parameter should be tuned to your use case\n",
    "qa = RetrievalQA.from_chain_type(llm=llm4,\n",
    "                                 chain_type=\"stuff\",\n",
    "                                 retriever=docsearch.as_retriever(k=4),\n",
    "                                 chain_type_kwargs = {\n",
    "#                                      'verbose': True,\n",
    "                                     'prompt': CHAT_PROMPT\n",
    "                                 })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdd1fe6",
   "metadata": {},
   "source": [
    "Then let's iterate through the topics that we found and run our QA query on them.\n",
    "\n",
    "This will print out our expanded topics. This is the final result you can use wherever you want!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "319bebc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hearing Aids Business: Shaan and Sam discuss the potential profitability of the hearing aids industry.\n",
      "Shaan Puri and Sam Parr discuss the potential of the hearing aids industry, noting that it could be a profitable venture. They believe that direct-to-consumer hearing aids could become a significant market.\n",
      "\n",
      "\n",
      "\n",
      "Children's Play Space Business: Shaan talks about a business idea he had discussed in a previous episode about a children's play space that operates on a membership basis.\n",
      "Shaan Puri discussed a business idea from a previous episode about a children's play space. The concept involves a location where children can play with various toys, funded by a membership fee. However, he clarified that he does not endorse this business idea, as his knowledge is based on a single experience and he has not thoroughly evaluated its potential profitability. He expressed concern about listeners potentially investing in such a franchise based on his casual discussion.\n",
      "\n",
      "\n",
      "\n",
      "Steph Smith's Career: Sam and Shaan discuss Steph Smith's career journey, from working with them at Trends to her current role at Andreessen Horowitz.\n",
      "Sam Parr humorously claims credit for Steph Smith's career, noting that he recruited her to join Trends after being impressed by her blog. After a couple of years with Trends, Smith moved on to Andreessen Horowitz, one of the world's largest venture capital firms. She currently works remotely for the firm, but the hosts encourage her to take advantage of the opportunity to network and learn from the smart people around her by spending more time in the office.\n",
      "\n",
      "\n",
      "\n",
      "Health and Diet Hacks: Sam mentions a book by Adam Bornstein, a health expert, that provides simple hacks for creating healthier diet habits.\n",
      "Adam Bornstein, a health expert who previously worked with Tim Ferriss, has released a book titled \"You Can't Screw This Up\". The book, which is written in a style similar to authors like Ryan Holiday, James Clear, and Tim Ferriss, provides simple hacks for creating healthier diet habits. The forward of the book was written by Arnold Schwarzenegger.\n",
      "\n",
      "\n",
      "\n",
      "Working at Andreessen Horowitz: Steph shares her experience working at Andreessen Horowitz, one of the biggest VC firms in the world.\n",
      "Steph Smith discusses her experience working at Andreessen Horowitz, a leading venture capital firm. She mentions that she works remotely but occasionally visits the office, which she finds novel due to her long history of remote work. She also talks about the podcast she's involved with at the firm, which she says is finally taking off and becoming enjoyable. Despite the day-to-day work being quite normal, she acknowledges the unique opportunities and experiences that come with working at such a prestigious firm.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Only doing the first 3 for conciseness \n",
    "for topic in topics_structured[:5]:\n",
    "    query = f\"\"\"\n",
    "        {topic['topic_name']}: {topic['description']}\n",
    "    \"\"\"\n",
    "\n",
    "    expanded_topic = qa.run(query)\n",
    "\n",
    "    print(f\"{topic['topic_name']}: {topic['description']}\")\n",
    "    print(expanded_topic)\n",
    "    print (\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af12d27",
   "metadata": {},
   "source": [
    "## Bonus: Chapters With Timestamps\n",
    "\n",
    "Because why not?\n",
    "\n",
    "We have the timestamps on the transcript so let's pull them out and get timestamp chapters. This is helpful so you can scrub to the topic when you're listening.\n",
    "\n",
    "I tried a few methods to do this, including function calling, but I found just a regular prompt worked great. It's not *that* hard of a task to pull out a timestamp. I did the Retrieval chain again to get relevant documents, then asked the LLM to pull out the earliest timestamp it saw a topic was talked about.\n",
    "\n",
    "**Hardcore**: Right now this will pull out the timestamp of the monologue. However the topic may or may not start at the beginning, maybe it's the middle? Timestamps could be off. If you wanted to go more hardcore accurate you could go down to the word level and make a guestimate as to when the topic actually started.\n",
    "\n",
    "Same as above, we'll make custom prompts for our QA chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fffe4acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"\"\"\n",
    "What is the first timestamp when the speakers started talking about a topic the user gives?\n",
    "Only respond with the timestamp, nothing else. Example: 0:18:24\n",
    "----------------\n",
    "{context}\"\"\"\n",
    "messages = [\n",
    "    SystemMessagePromptTemplate.from_template(system_template),\n",
    "    HumanMessagePromptTemplate.from_template(\"{question}\"),\n",
    "]\n",
    "CHAT_PROMPT = ChatPromptTemplate.from_messages(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53da58b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm=llm4,\n",
    "                                 chain_type=\"stuff\",\n",
    "                                 retriever=docsearch.as_retriever(k=4),\n",
    "                                 chain_type_kwargs = {\n",
    "#                                      'verbose': True,\n",
    "                                     'prompt': CHAT_PROMPT\n",
    "                                 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff8085a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holder for our topic timestamps\n",
    "topic_timestamps = []\n",
    "\n",
    "for topic in topics_structured:\n",
    "\n",
    "    query = f\"{topic['topic_name']} - {topic['description']}\"\n",
    "    timestamp = qa.run(query)\n",
    "    \n",
    "    topic_timestamps.append(f\"{timestamp} - {topic['topic_name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a0a1f1",
   "metadata": {},
   "source": [
    "They might be out of order so let's sort them and print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35f75f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00 - Hearing Aids Business\n",
      "0:00:40 - Children's Play Space Business\n",
      "0:02:11 - Health and Diet Hacks\n",
      "0:04:26 - Steph Smith's Career\n",
      "0:05:27 - Working at Andreessen Horowitz\n",
      "0:06:37 - Sam's Strategy for Networking\n",
      "0:09:21 - Shaan's Approach to Networking\n",
      "0:12:32 - Commercial Real Estate Crisis\n",
      "0:12:32 - Fractional Real Estate Opportunity\n",
      "0:13:29 - Temple Immersive\n",
      "0:14:56 - Rage Rooms\n",
      "0:16:43 - Escape Room Business Success\n"
     ]
    }
   ],
   "source": [
    "print (\"\\n\".join(sorted(topic_timestamps)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d053fb4c",
   "metadata": {},
   "source": [
    "Check out the audio for this episode [here](https://steno.ai/my-first-million/steph-smith-jobs-of-the-future-fractional-real-estate-mouth)\n",
    "\n",
    "Awesome! This is great, what domain are you going to parse topics from? Please let me know on [Twitter](https://twitter.com/GregKamradt) or contact me directly at contact@dataindependent.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc1da1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
