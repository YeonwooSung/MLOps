{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyMgnve7ZQAjrHFXRT1jXtZD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# LangChain: Memory\n","\n","## Outline\n","* ConversationBufferMemory\n","* ConversationBufferWindowMemory\n","* ConversationTokenBufferMemory\n","* ConversationSummaryMemory\n","\n","## Setup"],"metadata":{"id":"wm07KhCAVXga"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iMH4cIE86FRi","executionInfo":{"status":"ok","timestamp":1686058633098,"user_tz":-540,"elapsed":17147,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"0299fb71-48c1-41ae-90cc-3eacd43eb13c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive/')"]},{"cell_type":"code","source":["import os\n","os.chdir(\"drive/\")\n","os.chdir('My Drive')\n","os.chdir('Experiment')\n","os.chdir('LangChain')"],"metadata":{"id":"D613nlta7wzS","executionInfo":{"status":"ok","timestamp":1686058633946,"user_tz":-540,"elapsed":851,"user":{"displayName":"성연우","userId":"12015659827226767816"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["OUTPUT_DIR = './outputs/'\n","if not os.path.exists(OUTPUT_DIR):\n","    os.makedirs(OUTPUT_DIR)"],"metadata":{"id":"GaCLZWGL7zzs","executionInfo":{"status":"ok","timestamp":1686058633946,"user_tz":-540,"elapsed":3,"user":{"displayName":"성연우","userId":"12015659827226767816"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["!pip install python-dotenv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-jZlpzZo5pqB","executionInfo":{"status":"ok","timestamp":1686058637964,"user_tz":-540,"elapsed":4020,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"be154b2c-58a5-4c72-9e7b-f063a55972b4"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting python-dotenv\n","  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n","Installing collected packages: python-dotenv\n","Successfully installed python-dotenv-1.0.0\n"]}]},{"cell_type":"code","source":["!pip install openai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RXFg0muqg1oS","executionInfo":{"status":"ok","timestamp":1686058646171,"user_tz":-540,"elapsed":8210,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"af9c1b0a-af5f-4696-b644-70773ce957b3"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting openai\n","  Downloading openai-0.27.7-py3-none-any.whl (71 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n","Collecting aiohttp (from openai)\n","  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n","Collecting multidict<7.0,>=4.5 (from aiohttp->openai)\n","  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n","  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->openai)\n","  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->openai)\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.7 yarl-1.9.2\n"]}]},{"cell_type":"code","source":["!pip install --upgrade langchain"],"metadata":{"id":"2Y_rpi682Mdb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686058653578,"user_tz":-540,"elapsed":7419,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"83a703a2-0332-4194-b24e-aeb1d4d19264"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting langchain\n","  Downloading langchain-0.0.191-py3-none-any.whl (993 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.7/993.7 kB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.10)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.4)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n","Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n","  Downloading dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n","Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n","Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain)\n","  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.7)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.27.1)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Collecting marshmallow<4.0.0,>=3.3.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n","  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting marshmallow-enum<2.0.0,>=1.5.1 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n","  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n","Collecting typing-inspect>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Installing collected packages: mypy-extensions, marshmallow, typing-inspect, openapi-schema-pydantic, marshmallow-enum, dataclasses-json, langchain\n","Successfully installed dataclasses-json-0.5.7 langchain-0.0.191 marshmallow-3.19.0 marshmallow-enum-1.5.1 mypy-extensions-1.0.0 openapi-schema-pydantic-1.2.4 typing-inspect-0.9.0\n"]}]},{"cell_type":"code","source":["import openai\n","import os\n","\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"FjkVvEzwVeLp","executionInfo":{"status":"ok","timestamp":1686058654003,"user_tz":-540,"elapsed":434,"user":{"displayName":"성연우","userId":"12015659827226767816"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["from dotenv import load_dotenv, find_dotenv\n","_ = load_dotenv(find_dotenv())\n","\n","openai.api_key  = os.getenv('OPENAI_API_KEY')"],"metadata":{"id":"cWYdp7Uv6JaM","executionInfo":{"status":"ok","timestamp":1686058654003,"user_tz":-540,"elapsed":3,"user":{"displayName":"성연우","userId":"12015659827226767816"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["#### helper function\n","\n","Throughout this course, we will use OpenAI's `gpt-3.5-turbo` model and the [chat completions endpoint](https://platform.openai.com/docs/guides/chat). \n","\n","This helper function will make it easier to use prompts and look at the generated outputs:"],"metadata":{"id":"LSrlOMpwVlR1"}},{"cell_type":"code","source":["def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n","    messages = [{\"role\": \"user\", \"content\": prompt}]\n","    response = openai.ChatCompletion.create(\n","        model=model,\n","        messages=messages,\n","        temperature=0, # this is the degree of randomness of the model's output\n","    )\n","    return response.choices[0].message[\"content\"]"],"metadata":{"id":"8Y0jVc7FVeJB","executionInfo":{"status":"ok","timestamp":1686058654003,"user_tz":-540,"elapsed":2,"user":{"displayName":"성연우","userId":"12015659827226767816"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def get_completion_from_messages(messages, model=\"gpt-3.5-turbo\", temperature=0, max_tokens=500):\n","    response = openai.ChatCompletion.create(\n","        model=model,\n","        messages=messages,\n","        temperature=temperature, \n","        max_tokens=max_tokens,\n","    )\n","    return response.choices[0].message[\"content\"]"],"metadata":{"id":"iP5Rp9yINpDW","executionInfo":{"status":"ok","timestamp":1686058654003,"user_tz":-540,"elapsed":2,"user":{"displayName":"성연우","userId":"12015659827226767816"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["from langchain.chat_models import ChatOpenAI\n","from langchain.chains import ConversationChain\n","from langchain.memory import ConversationBufferMemory"],"metadata":{"id":"t41tCITr57zZ","executionInfo":{"status":"ok","timestamp":1686058656170,"user_tz":-540,"elapsed":2169,"user":{"displayName":"성연우","userId":"12015659827226767816"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["llm = ChatOpenAI(temperature=0.0)\n","memory = ConversationBufferMemory()\n","conversation = ConversationChain(\n","    llm=llm, \n","    memory = memory,\n","    verbose=True\n",")"],"metadata":{"id":"D20jU3E-2pij","executionInfo":{"status":"ok","timestamp":1686058656170,"user_tz":-540,"elapsed":2,"user":{"displayName":"성연우","userId":"12015659827226767816"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["conversation.predict(input=\"Hi, my name is Andrew\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":264},"id":"mFq-S_FS6PTt","executionInfo":{"status":"ok","timestamp":1686058659077,"user_tz":-540,"elapsed":2908,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"bce26b77-b8a2-406d-e4d6-84eb1e55e7d5"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","\n","Human: Hi, my name is Andrew\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["\"Hello Andrew, it's nice to meet you. My name is AI. How can I assist you today?\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["conversation.predict(input=\"What is 1+1?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281},"id":"PLAqi69G6PQt","executionInfo":{"status":"ok","timestamp":1686058660331,"user_tz":-540,"elapsed":1274,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"84a5c227-439d-4de6-8d3f-7d93e82347ce"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","Human: Hi, my name is Andrew\n","AI: Hello Andrew, it's nice to meet you. My name is AI. How can I assist you today?\n","Human: What is 1+1?\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["'The answer to 1+1 is 2.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["conversation.predict(input=\"What is my name?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":316},"id":"KF2Tfy-Q6RAq","executionInfo":{"status":"ok","timestamp":1686058661926,"user_tz":-540,"elapsed":1601,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"8fb19bfc-8cbb-4585-ee20-e90a06e690b1"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","Human: Hi, my name is Andrew\n","AI: Hello Andrew, it's nice to meet you. My name is AI. How can I assist you today?\n","Human: What is 1+1?\n","AI: The answer to 1+1 is 2.\n","Human: What is my name?\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["'Your name is Andrew, as you mentioned earlier.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["print(memory.buffer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AHsOwGNn6Q-C","executionInfo":{"status":"ok","timestamp":1686058661926,"user_tz":-540,"elapsed":9,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"9d96ee69-4277-4ec5-ddd9-0808eeea5336"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Human: Hi, my name is Andrew\n","AI: Hello Andrew, it's nice to meet you. My name is AI. How can I assist you today?\n","Human: What is 1+1?\n","AI: The answer to 1+1 is 2.\n","Human: What is my name?\n","AI: Your name is Andrew, as you mentioned earlier.\n"]}]},{"cell_type":"code","source":["memory.load_memory_variables({})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HniEJh5u6Q7G","executionInfo":{"status":"ok","timestamp":1686058661926,"user_tz":-540,"elapsed":8,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"ffa418ac-e591-434e-f84a-c98d8ad0c028"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': \"Human: Hi, my name is Andrew\\nAI: Hello Andrew, it's nice to meet you. My name is AI. How can I assist you today?\\nHuman: What is 1+1?\\nAI: The answer to 1+1 is 2.\\nHuman: What is my name?\\nAI: Your name is Andrew, as you mentioned earlier.\"}"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["memory = ConversationBufferMemory()"],"metadata":{"id":"zf3D0V5F6Lzz","executionInfo":{"status":"ok","timestamp":1686058661926,"user_tz":-540,"elapsed":7,"user":{"displayName":"성연우","userId":"12015659827226767816"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["memory.save_context({\"input\": \"Hi\"}, {\"output\": \"What's up\"})"],"metadata":{"id":"8qbi0KyJ6XVq","executionInfo":{"status":"ok","timestamp":1686058661927,"user_tz":-540,"elapsed":7,"user":{"displayName":"성연우","userId":"12015659827226767816"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["print(memory.buffer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nl2PRwCo6XRV","executionInfo":{"status":"ok","timestamp":1686058661927,"user_tz":-540,"elapsed":7,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"cf5bf310-1be4-454c-94ac-bc9fb5d43cd5"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Human: Hi\n","AI: What's up\n"]}]},{"cell_type":"code","source":["memory.load_memory_variables({})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iVDww-Wj6XOH","executionInfo":{"status":"ok","timestamp":1686058661927,"user_tz":-540,"elapsed":6,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"2ba56d02-b9d2-4fae-bd88-3a5f31870079"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': \"Human: Hi\\nAI: What's up\"}"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["memory.save_context({\"input\": \"Not much, just hanging\"}, {\"output\": \"Cool\"})"],"metadata":{"id":"87ZeiKWq6d-A","executionInfo":{"status":"ok","timestamp":1686058661927,"user_tz":-540,"elapsed":6,"user":{"displayName":"성연우","userId":"12015659827226767816"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["memory.load_memory_variables({})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6yvm44ie6d8Q","executionInfo":{"status":"ok","timestamp":1686058662357,"user_tz":-540,"elapsed":436,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"3b2ea7e5-37bc-45bc-a2ae-3821e3399c34"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': \"Human: Hi\\nAI: What's up\\nHuman: Not much, just hanging\\nAI: Cool\"}"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["## ConversationBufferWindowMemory"],"metadata":{"id":"8xrkfCVV6h_H"}},{"cell_type":"code","source":["from langchain.memory import ConversationBufferWindowMemory"],"metadata":{"id":"9koMi1GX6d5z","executionInfo":{"status":"ok","timestamp":1686058662358,"user_tz":-540,"elapsed":3,"user":{"displayName":"성연우","userId":"12015659827226767816"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["memory = ConversationBufferWindowMemory(k=1)\n","memory.save_context({\"input\": \"Hi\"},\n","                    {\"output\": \"What's up\"})\n","memory.save_context({\"input\": \"Not much, just hanging\"},\n","                    {\"output\": \"Cool\"})"],"metadata":{"id":"ij1DfKYT6d3h","executionInfo":{"status":"ok","timestamp":1686058662358,"user_tz":-540,"elapsed":3,"user":{"displayName":"성연우","userId":"12015659827226767816"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["memory.load_memory_variables({})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P2GQoZNj6XKm","executionInfo":{"status":"ok","timestamp":1686058662358,"user_tz":-540,"elapsed":3,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"c4dea706-3d14-4ac9-abe4-9d7aa7fa9963"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': 'Human: Not much, just hanging\\nAI: Cool'}"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["llm = ChatOpenAI(temperature=0.0)\n","memory = ConversationBufferWindowMemory(k=1)\n","conversation = ConversationChain(\n","    llm=llm, \n","    memory = memory,\n","    verbose=False\n",")"],"metadata":{"id":"HtjVZ18W6qNn","executionInfo":{"status":"ok","timestamp":1686058662358,"user_tz":-540,"elapsed":2,"user":{"displayName":"성연우","userId":"12015659827226767816"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["conversation.predict(input=\"Hi, my name is Andrew\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"K9JBfI0e6qLM","executionInfo":{"status":"ok","timestamp":1686058664250,"user_tz":-540,"elapsed":1894,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"c20097f3-b172-41fe-e9b9-1c481f9231d7"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"Hello Andrew, it's nice to meet you. My name is AI. How can I assist you today?\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["conversation.predict(input=\"What is 1+1?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"ULjXeCKo6qGQ","executionInfo":{"status":"ok","timestamp":1686058665818,"user_tz":-540,"elapsed":1577,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"08f885ad-1add-4ef4-ae08-500b4591b657"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'The answer to 1+1 is 2.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["conversation.predict(input=\"What is my name?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"HsxMVQlJ6qD8","executionInfo":{"status":"ok","timestamp":1686058667970,"user_tz":-540,"elapsed":2156,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"79ece852-b436-4751-f33b-9056ac26f2ad"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"I'm sorry, I don't have access to that information. Could you please tell me your name?\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":30}]},{"cell_type":"markdown","source":["## ConversationTokenBufferMemory"],"metadata":{"id":"pcHvw2Rj6wED"}},{"cell_type":"code","source":["!pip install tiktoken"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I30s32fH6qCH","executionInfo":{"status":"ok","timestamp":1686058672641,"user_tz":-540,"elapsed":4675,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"ad204deb-2aca-4f72-ec55-da0e5eadaf19"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tiktoken\n","  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2022.10.31)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.27.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n","Installing collected packages: tiktoken\n","Successfully installed tiktoken-0.4.0\n"]}]},{"cell_type":"code","source":["from langchain.memory import ConversationTokenBufferMemory\n","from langchain.llms import OpenAI\n","\n","\n","llm = ChatOpenAI(temperature=0.0)\n","\n","memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=30)\n","memory.save_context({\"input\": \"AI is what?!\"},\n","                    {\"output\": \"Amazing!\"})\n","memory.save_context({\"input\": \"Backpropagation is what?\"},\n","                    {\"output\": \"Beautiful!\"})\n","memory.save_context({\"input\": \"Chatbots are what?\"}, \n","                    {\"output\": \"Charming!\"})\n","\n","memory.load_memory_variables({})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"epNWbHKZ6vxR","executionInfo":{"status":"ok","timestamp":1686058673631,"user_tz":-540,"elapsed":994,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"b788ce6b-bc38-4381-aa36-79e06354198b"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': 'AI: Beautiful!\\nHuman: Chatbots are what?\\nAI: Charming!'}"]},"metadata":{},"execution_count":32}]},{"cell_type":"markdown","source":["## ConversationSummaryMemory"],"metadata":{"id":"OfBPsXUy68jg"}},{"cell_type":"code","source":["from langchain.memory import ConversationSummaryBufferMemory\n","\n","\n","# create a long string\n","schedule = \"There is a meeting at 8am with your product team. \\\n","You will need your powerpoint presentation prepared. \\\n","9am-12pm have time to work on your LangChain \\\n","project which will go quickly because Langchain is such a powerful tool. \\\n","At Noon, lunch at the italian resturant with a customer who is driving \\\n","from over an hour away to meet you to understand the latest in AI. \\\n","Be sure to bring your laptop to show the latest LLM demo.\"\n","\n","memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n","memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n","memory.save_context({\"input\": \"Not much, just hanging\"},\n","                    {\"output\": \"Cool\"})\n","memory.save_context({\"input\": \"What is on the schedule today?\"}, \n","                    {\"output\": f\"{schedule}\"})\n","\n","memory.load_memory_variables({})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1nD5j2DX6vvR","executionInfo":{"status":"ok","timestamp":1686058678519,"user_tz":-540,"elapsed":4890,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"1c233c23-6dc8-46bf-9a83-d2fbb5215234"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': \"System: The human and AI engage in small talk before discussing the day's schedule. The AI informs the human of a morning meeting with the product team, time to work on the LangChain project, and a lunch meeting with a customer interested in the latest AI developments.\"}"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["conversation = ConversationChain(\n","    llm=llm, \n","    memory = memory,\n","    verbose=True\n",")"],"metadata":{"id":"OhOVwiWk6vso","executionInfo":{"status":"ok","timestamp":1686058678519,"user_tz":-540,"elapsed":4,"user":{"displayName":"성연우","userId":"12015659827226767816"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["conversation.predict(input=\"What would be a good demo to show?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":298},"id":"jQWIJMdJ6vpu","executionInfo":{"status":"ok","timestamp":1686058693985,"user_tz":-540,"elapsed":15470,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"029a9c71-12e1-4ee6-848c-6f182aaed39a"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","System: The human and AI engage in small talk before discussing the day's schedule. The AI informs the human of a morning meeting with the product team, time to work on the LangChain project, and a lunch meeting with a customer interested in the latest AI developments.\n","Human: What would be a good demo to show?\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["\"Based on the customer's interest in AI developments, I would suggest showcasing our latest natural language processing capabilities. We could demonstrate how our AI can understand and respond to complex language queries, and even provide personalized recommendations based on the user's preferences. Additionally, we could highlight our machine learning algorithms and how they continuously improve the accuracy and efficiency of our AI. Would you like me to prepare a demo for the meeting?\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["memory.load_memory_variables({})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zHpDVWMY6vlz","executionInfo":{"status":"ok","timestamp":1686058693986,"user_tz":-540,"elapsed":6,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"2d380c01-b065-403a-ee4c-63ff2ccb00c4"},"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': \"System: The human and AI engage in small talk before discussing the day's schedule. The AI informs the human of a morning meeting with the product team, time to work on the LangChain project, and a lunch meeting with a customer interested in the latest AI developments. The human asks what would be a good demo to show.\\nAI: Based on the customer's interest in AI developments, I would suggest showcasing our latest natural language processing capabilities. We could demonstrate how our AI can understand and respond to complex language queries, and even provide personalized recommendations based on the user's preferences. Additionally, we could highlight our machine learning algorithms and how they continuously improve the accuracy and efficiency of our AI. Would you like me to prepare a demo for the meeting?\"}"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":[],"metadata":{"id":"brl6liQt6vhc","executionInfo":{"status":"ok","timestamp":1686058693986,"user_tz":-540,"elapsed":4,"user":{"displayName":"성연우","userId":"12015659827226767816"}}},"execution_count":36,"outputs":[]}]}