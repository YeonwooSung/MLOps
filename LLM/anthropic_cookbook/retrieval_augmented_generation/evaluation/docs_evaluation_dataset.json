[
    {
      "id": "efc09699",
      "question": "How can you create multiple test cases for an evaluation in the Anthropic Evaluation tool?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/test-and-evaluate/eval-tool#creating-test-cases",
        "https://docs.anthropic.com/en/docs/build-with-claude/develop-tests#building-evals-and-test-cases"
      ],
      "correct_answer": "To create multiple test cases in the Anthropic Evaluation tool, click the 'Add Test Case' button, fill in values for each variable in your prompt, and repeat the process to create additional test case scenarios."
    },
    {
      "id": "1305ea00",
      "question": "What embeddings provider does Anthropic recommend for customized domain-specific models, and what capabilities does this provider offer?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/build-with-claude/embeddings#before-implementing-embeddings",
        "https://docs.anthropic.com/en/docs/build-with-claude/embeddings#how-to-get-embeddings-with-anthropic"
      ],
      "correct_answer": "Anthropic recommends Voyage AI for embedding models. Voyage AI offers customized models for specific industry domains like finance and healthcare, as well as bespoke fine-tuned models for individual customers. They have a wide variety of options and capabilities."
    },
    {
      "id": "1811c10d",
      "question": "What are some key success metrics to consider when evaluating Claude's performance on a classification task, and how do they relate to choosing the right model to reduce latency?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/about-claude/use-cases/classification#evaluation-metrics",
        "https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/reduce-latency#1-choose-the-right-model"
      ],
      "correct_answer": "When evaluating Claude's performance on a classification task, some key success metrics to consider include accuracy, F1 score, consistency, structure, speed, bias and fairness. Choosing the right model that fits your specific requirements in terms of speed and output quality is a straightforward way to reduce latency and meet the acceptable response time for your use case."
    },
    {
      "id": "1d6210b8",
      "question": "What are two ways that Claude for Sheets can improve prompt engineering workflows compared to using chained prompts?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/build-with-claude/claude-for-sheets#why-use-claude-for-sheets",
        "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-prompts#how-to-chain-prompts"
      ],
      "correct_answer": "Claude for Sheets enables testing prompts across evaluation suites in parallel, which is faster than running chained prompts sequentially. It also excels at office tasks like survey analysis and online data processing that may be more cumbersome with chained prompts."
    },
    {
      "id": "97be1525",
      "question": "What happens if a prompt for the Text Completions API is missing the \"\\n\\nHuman:\" and \"\\n\\nAssistant:\" turns?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/api/migrating-from-text-completions-to-messages#system-prompt",
        "https://docs.anthropic.com/en/api/prompt-validation#examples"
      ],
      "correct_answer": "If a prompt for the Text Completions API is missing the required \"\\n\\nHuman:\" and \"\\n\\nAssistant:\" turns, it will result in an API error."
    },
    {
      "id": "838c732f",
      "question": "How do the additional tokens required for tool use in Claude API requests impact pricing compared to regular API requests?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/build-with-claude/tool-use#pricing",
        "https://docs.anthropic.com/en/docs/build-with-claude/tool-use#how-tool-use-works"
      ],
      "correct_answer": "Tool use requests in the Claude API are priced the same as regular API requests, based on the total input and output tokens. However, tool use requests have additional tokens beyond the regular input and output, including the tools parameter, tool use content blocks, tool result content blocks, and a special system prompt that enables tool use, which add to the total tokens and cost."
    },
    {
      "id": "1fc56a47",
      "question": "When will the new Anthropic Developer Console features that show API usage, billing details, and rate limits be available?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/release-notes/api#june-27th-2024"
      ],
      "correct_answer": "The new Usage, Cost, and Rate Limits tabs in the Anthropic Developer Console that show API usage, billing details, and current rate limits will be available on June 27th, 2024."
    },
    {
      "id": "5590f280",
      "question": "When deciding whether to use chain-of-thought (CoT) for a task, what are two key factors to consider in order to strike the right balance between performance and latency?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-of-thought#why-not-let-claude-think",
        "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-of-thought#before-implementing-cot"
      ],
      "correct_answer": "When deciding whether to use CoT, consider if the task requires in-depth thinking that a human would need to work through, and be aware that the increased output length from CoT may impact latency."
    },
    {
      "id": "eb7b1167",
      "question": "How can I use Claude to more easily digest the content of long PDF documents?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/build-with-claude/text-generation#anthropic-cookbook",
        "https://docs.anthropic.com/en/docs/build-with-claude/vision#before-you-upload"
      ],
      "correct_answer": "You can upload PDFs and have Claude summarize their content, making it easier to understand the key points of long documents without having to read through everything."
    },
    {
      "id": "48f497ca",
      "question": "According to the documentation, where can you view your organization's current API rate limits in the Anthropic Console?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/api/rate-limits#about-our-limits",
        "https://docs.anthropic.com/en/release-notes/api#june-27th-2024"
      ],
      "correct_answer": "You can view your organization's current API rate limits in the Rate Limits tab of the Developer Console."
    },
    {
      "id": "bc701a6a",
      "question": "How can we measure the performance of the ticket classification system implemented using Claude beyond just accuracy?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/about-claude/use-cases/ticket-routing#evaluation-methodology",
        "https://docs.anthropic.com/en/docs/about-claude/use-cases/ticket-routing#prompting-claude-for-ticket-routing"
      ],
      "correct_answer": "In addition to accuracy, we can measure the 95th percentile response time and average cost per classification to assess the ticket classification system's performance and production-readiness."
    },
    {
      "id": "7e78ad6c",
      "question": "How can you specify a system prompt using the Text Completions API versus the Messages API?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/api/prompt-validation#examples",
        "https://docs.anthropic.com/en/api/migrating-from-text-completions-to-messages#system-prompt"
      ],
      "correct_answer": "With the Text Completions API, the system prompt is added as text before the first \"\\n\\nHuman:\" turn. With the Messages API, the system prompt is specified using the separate \"system\" parameter when making the API request."
    },
    {
      "id": "67180f57",
      "question": "How can you combine XML tags with chain of thought reasoning to create high-performance prompts for Claude?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/use-xml-tags#tagging-best-practices",
        "https://docs.anthropic.com/en/docs/build-with-claude/tool-use#chain-of-thought"
      ],
      "correct_answer": "You can combine XML tags like <thinking> and <answer> with chain of thought reasoning, where Claude explains its step-by-step reasoning process, to create structured, high-performance prompts. For example, you can prompt Claude to show its reasoning by including \"Before answering, explain your reasoning step-by-step in <thinking> tags.\" in the user message or system prompt."
    },
    {
      "id": "cbde7951",
      "question": "When evaluating the Claude model's performance for ticket routing, what three key metrics are calculated and what are the results for the claude-3-haiku-20240307 model on the 91 test samples?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/about-claude/use-cases/ticket-routing#evaluation-methodology",
        "https://docs.anthropic.com/en/docs/about-claude/use-cases/ticket-routing#example-data"
      ],
      "correct_answer": "When evaluating the claude-3-haiku-20240307 model's performance on the 91 test samples, the three key metrics calculated are accuracy (89.01%), 95th percentile response time (1.61 seconds), and average cost per request routing ($0.0004)."
    },
    {
      "id": "bbeaa6b6",
      "question": "Before starting to engineer and improve a prompt in Claude, what key things does Anthropic recommend you have in place first?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/build-with-claude/define-success#next-steps",
        "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering#before-prompt-engineering"
      ],
      "correct_answer": "Before prompt engineering, Anthropic highly recommends having a clear definition of success criteria for your use case, some ways to empirically test against those criteria, and a first draft prompt you want to improve."
    },
    {
      "id": "d06d859e",
      "question": "How does the Messages API handle mid-response prompting compared to the Text Completions API?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/api/migrating-from-text-completions-to-messages#inputs-and-outputs",
        "https://docs.anthropic.com/en/api/migrating-from-text-completions-to-messages#putting-words-in-claudes-mouth"
      ],
      "correct_answer": "The Messages API allows you to continue a response by making the last input message have the \"assistant\" role, whereas the Text Completions API lets you pre-fill part of Claude's response directly in the prompt string."
    },
    {
      "id": "b01ae76d",
      "question": "How does Claude's response differ when given a role through a system prompt compared to not having a specific role in the financial analysis example?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/system-prompts#example-2-financial-analysis"
      ],
      "correct_answer": "When given the role of CFO through a system prompt, Claude provides a much more insightful, structured, and actionable financial analysis compared to not having a specific role. The role-based response breaks down key financial metrics, provides strategic commentary, and makes specific recommendations."
    },
    {
      "id": "3e0b683d",
      "question": "What are some quantitative metrics that can be used to measure the success of a sentiment analysis model, and how might specific targets for those metrics be determined?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/build-with-claude/define-success#building-strong-criteria"
      ],
      "correct_answer": "Quantitative metrics for evaluating a sentiment analysis model include task-specific metrics like F1 score, as well as generic metrics like accuracy, precision, and recall. Specific targets should be based on industry benchmarks, prior experiments, AI research, or expert knowledge, and should represent an improvement over the current baseline."
    },
    {
      "id": "d17c5f03",
      "question": "What is a power user tip mentioned in the documentation for creating high-performance prompts using XML tags?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering#how-to-prompt-engineer",
        "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/use-xml-tags#tagging-best-practices"
      ],
      "correct_answer": "Combining XML tags with other prompt engineering techniques like multishot prompting (using <examples> tags) or chain of thought (using <thinking> and <answer> tags) to create super-structured, high-performance prompts."
    },
    {
      "id": "e2576d21",
      "question": "How can you use an LLM like Claude to automatically grade the outputs of other LLMs based on a rubric?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/build-with-claude/develop-tests#tips-for-llm-based-grading",
        "https://docs.anthropic.com/en/api/messages-examples#multiple-conversational-turns"
      ],
      "correct_answer": "You can use an LLM like Claude to grade the outputs of other LLMs by providing it with the output to grade along with a detailed rubric. Instruct the LLM to think through its reasoning and then output a simple 'correct' or 'incorrect' result based on how well the output matches the criteria in the rubric."
    },
    {
      "id": "0e17a981",
      "question": "How can you access and deploy Voyage embeddings on AWS Marketplace?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/build-with-claude/embeddings#voyage-on-the-aws-marketplace"
      ],
      "correct_answer": "To access Voyage embeddings on AWS, subscribe to the model package on AWS Marketplace, select the model to deploy, agree to the terms, and copy the Product ARN for your selected region. Then create a JupyterLab space in SageMaker Studio, upload Voyage's notebook, and follow the instructions to deploy the model package using the ARN."
    },
    {
      "id": "2e893e5f",
      "question": "When using tools just to get Claude to produce JSON output following a particular schema, what key things should you do in terms of tool setup and prompting?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/build-with-claude/tool-use#tool-use-examples",
        "https://docs.anthropic.com/en/docs/build-with-claude/tool-use#json-output"
      ],
      "correct_answer": "When using tools to get JSON output, you should provide a single tool, set the tool_choice to explicitly instruct the model to use that tool, and ensure the tool name and description are from the model's perspective since it will pass the input to the tool."
    },
    {
      "id": "84eaf6d1",
      "question": "What are the key differences between the legacy Claude Instant 1.2 model and the Claude 3 Haiku model in terms of capabilities and performance?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/about-claude/models#legacy-model-comparison",
        "https://docs.anthropic.com/en/docs/about-claude/models#model-comparison",
        "https://docs.anthropic.com/en/docs/about-claude/models#legacy-models"
      ],
      "correct_answer": "The Claude 3 Haiku model has vision capabilities, is faster, more performant, and more intelligent than the legacy Claude Instant 1.2 model. Claude 3 Haiku also has more up-to-date training data."
    },
    {
      "id": "ac6df7d9",
      "question": "What is one key benefit of using examples when prompt engineering with Claude?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/multishot-prompting#why-use-examples"
      ],
      "correct_answer": "One key benefit of using examples in prompts is that they reduce misinterpretation of instructions, leading to more accurate outputs from Claude."
    },
    {
      "id": "2f2e851c",
      "question": "According to the Anthropic documentation, what is one key advantage of using prompt engineering instead of fine-tuning when it comes to adapting an AI model to new domains or tasks?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering#when-to-prompt-engineer",
        "https://docs.anthropic.com/en/docs/resources/glossary#fine-tuning"
      ],
      "correct_answer": "Prompt engineering allows you to easily adapt AI models to new domains by providing domain-specific context directly in the prompts, without needing to retrain the model through fine-tuning."
    },
    {
      "id": "1be7fb77",
      "question": "How can I quickly get started using the Claude for Sheets extension with a pre-made template?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/build-with-claude/claude-for-sheets#claude-for-sheets-workbook-template",
        "https://docs.anthropic.com/en/docs/build-with-claude/claude-for-sheets#get-started-with-claude-for-sheets"
      ],
      "correct_answer": "You can make a copy of Anthropic's provided Claude for Sheets workbook template to quickly get started using the extension with your own work."
    },
    {
      "id": "9a6c9802",
      "question": "How does the \"index\" field in the \"content_block_delta\" event relate to the text being streamed in a response?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/api/messages-streaming#basic-streaming-request",
        "https://docs.anthropic.com/en/api/messages-streaming#text-delta"
      ],
      "correct_answer": "The \"index\" field in each \"content_block_delta\" event indicates which content block the text delta applies to. Multiple deltas with the same index consecutively stream the text for a single content block in the response."
    },
    {
      "id": "8ec5561c",
      "question": "How can you include an image as part of a Claude API request, and what image formats are currently supported?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/api/messages-examples#vision",
        "https://docs.anthropic.com/en/docs/build-with-claude/vision#about-the-prompt-examples"
      ],
      "correct_answer": "To include an image in a Claude API request, provide it as a base64-encoded image in an \"image\" content block within the \"messages\" array. The currently supported image formats are JPEG, PNG, GIF, and WebP."
    },
    {
      "id": "e97019e7",
      "question": "What is the relationship between time to first token (TTFT) and latency when evaluating a language model's performance?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/resources/glossary#ttft-time-to-first-token",
        "https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/reduce-latency#how-to-measure-latency",
        "https://docs.anthropic.com/en/docs/resources/glossary#latency"
      ],
      "correct_answer": "TTFT is a specific measure of latency that captures the time it takes for a language model to generate the first token of its response after receiving a prompt. It is an important component of a model's overall latency and responsiveness, especially for interactive applications."
    },
    {
      "id": "012db0c7",
      "question": "How can providing Claude with examples of handling certain edge cases like implicit requests or emotional prioritization help improve its performance in routing support tickets?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/about-claude/use-cases/ticket-routing#adapting-to-common-scenarios",
        "https://docs.anthropic.com/en/docs/about-claude/use-cases/ticket-routing#prompting-claude-for-ticket-routing"
      ],
      "correct_answer": "Providing edge case examples to Claude in the prompt can meaningfully improve its performance in correctly routing support tickets in scenarios where it may otherwise misclassify them, such as implicit requests, emotional prioritization, ambiguous intent vs. routing, or issue prioritization."
    },
    {
      "id": "124ad490",
      "question": "How does the stop_reason of \"tool_use\" relate to the overall workflow of integrating external tools with Claude?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/api/messages-examples#tool-use-and-json-mode",
        "https://docs.anthropic.com/en/docs/build-with-claude/tool-use#how-tool-use-works"
      ],
      "correct_answer": "When Claude determines that one of the user-provided tools can help answer the user's query, it constructs a tool use request. This causes the API response to have a stop_reason of \"tool_use\", signaling Claude's intent to use the tool. The user must then extract the tool input from Claude's request, run the actual tool code client-side, and continue the conversation by sending the tool results back to Claude."
    },
    {
      "id": "4cc35077",
      "question": "According to the documentation, what error event and corresponding HTTP error code may be sent during periods of high usage for the Anthropic API when using streaming responses?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/api/messages-streaming#error-events",
        "https://docs.anthropic.com/en/api/streaming#error-event-types",
        "https://docs.anthropic.com/en/api/errors#http-errors"
      ],
      "correct_answer": "During periods of high usage, an overloaded_error event may be sent in the event stream, which would normally correspond to an HTTP 529 error code in a non-streaming context."
    },
    {
      "id": "544c05c2",
      "question": "What are the two types of deltas that can be contained in a content_block_delta event when streaming responses from the Anthropic API?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/api/messages-streaming#text-delta",
        "https://docs.anthropic.com/en/api/messages-streaming#delta-types"
      ],
      "correct_answer": "The two types of deltas that can be contained in a content_block_delta event are text_delta and input_json_delta."
    },
    {
      "id": "9a11efff",
      "question": "On what date did Claude 3.5 Sonnet and tool use both become generally available across the Anthropic API, Amazon Bedrock, and Google Vertex AI?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/release-notes/api#june-20th-2024",
        "https://docs.anthropic.com/en/release-notes/api#may-30th-2024"
      ],
      "correct_answer": "Claude 3.5 Sonnet became generally available across those platforms on June 20th, 2024, while tool use became generally available on May 30th, 2024."
    },
    {
      "id": "89903ad7",
      "question": "In what order did Anthropic launch Claude.ai and the Claude iOS app in Canada and Europe?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/release-notes/claude-apps#june-5th-2024",
        "https://docs.anthropic.com/en/release-notes/claude-apps#may-13th-2024"
      ],
      "correct_answer": "Anthropic launched Claude.ai and the Claude iOS app in Europe in May 2024, and then launched them in Canada the following month in June 2024."
    },
    {
      "id": "c07779d4",
      "question": "When the API response from Claude has a stop_reason of \"tool_use\", what does this indicate and what should be done next to continue the conversation?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/build-with-claude/tool-use#json-output",
        "https://docs.anthropic.com/en/docs/build-with-claude/tool-use#how-tool-use-works"
      ],
      "correct_answer": "A stop_reason of \"tool_use\" signals that Claude has decided to use a tool and has constructed a formatted tool use request. To continue the conversation, the tool name and input should be extracted from Claude's request, the actual tool code should be executed client-side, and then a new user message containing a tool_result content block should be sent to Claude."
    },
    {
      "id": "8372a611",
      "question": "What Python libraries are used in the example code snippet for evaluating tone and style in a customer service chatbot?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/build-with-claude/develop-tests#example-evals"
      ],
      "correct_answer": "The example code snippet for evaluating tone and style in a customer service chatbot uses the anthropic Python library to interact with the Claude AI model."
    },
    {
      "id": "3d41bc6b",
      "question": "What are the two main ways to authenticate when using the Anthropic Python SDK to access Claude models on Amazon Bedrock?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/api/claude-on-amazon-bedrock#install-an-sdk-for-accessing-bedrock",
        "https://docs.anthropic.com/en/api/claude-on-amazon-bedrock#making-requests"
      ],
      "correct_answer": "The two main ways to authenticate are: 1) Directly providing the aws_access_key, aws_secret_key, and optionally aws_session_token, or 2) Using the default AWS credential providers, such as the ~/.aws/credentials file or the AWS_SECRET_ACCESS_KEY and AWS_ACCESS_KEY_ID environment variables."
    },
    {
      "id": "d8099da7",
      "question": "When deciding whether to implement leak-resistant prompt engineering strategies, what two factors should be considered and balanced?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/reduce-prompt-leak#strategies-to-reduce-prompt-leak",
        "https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/reduce-prompt-leak#before-you-try-to-reduce-prompt-leak"
      ],
      "correct_answer": "When deciding to use leak-resistant prompt engineering, the potential reduction in prompt leaks should be balanced against the risk of degraded model performance due to the added complexity of the prompt."
    },
    {
      "id": "9761e499",
      "question": "How can selecting the appropriate Claude model based on your specific requirements help reduce latency in your application?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/reduce-latency#1-choose-the-right-model",
        "https://docs.anthropic.com/en/docs/intro-to-claude#model-options"
      ],
      "correct_answer": "Choosing the right Claude model that best fits your needs in terms of speed and output quality is one of the most straightforward ways to reduce latency in your application. Anthropic offers a range of Claude models with different capabilities and performance characteristics to allow you to choose the optimal balance of intelligence, speed, and cost for your use case."
    },
    {
      "id": "fb6179c4",
      "question": "How can you stream responses from the Anthropic API using the Python SDK?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/api/messages-streaming#streaming-with-sdks",
        "https://docs.anthropic.com/en/api/client-sdks#python"
      ],
      "correct_answer": "You can stream responses from the Anthropic API using the Python SDK by using the client.messages.stream() method and iterating over the stream.text_stream attribute in a for loop."
    },
    {
      "id": "cf0334f8",
      "question": "How can you guide Claude's response by pre-filling part of the response, and what API parameter is used to generate a short response in this case?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/api/messages-examples#putting-words-in-claudes-mouth",
        "https://docs.anthropic.com/en/api/messages-examples#basic-request-and-response"
      ],
      "correct_answer": "You can shape Claude's response by pre-filling part of it in the last position of the input messages list. To get a short response like a single multiple choice answer, you can set the \"max_tokens\" parameter to a small value like 1."
    },
    {
      "id": "50564356",
      "question": "What is more important when building an eval set for an AI system - having a larger number of test cases with automated grading, or having fewer high-quality test cases graded by humans?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/build-with-claude/develop-tests#eval-design-principles",
        "https://docs.anthropic.com/en/docs/build-with-claude/develop-tests#building-evals-and-test-cases"
      ],
      "correct_answer": "When building an eval set, it is better to prioritize having a larger volume of test cases with slightly lower signal automated grading over having fewer questions with high-quality human hand-grading."
    },
    {
      "id": "7096e819",
      "question": "What are the two required fields in a content_block_delta event for a text delta type?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/api/messages-streaming#delta-types",
        "https://docs.anthropic.com/en/api/messages-streaming#text-delta"
      ],
      "correct_answer": "The two required fields in a content_block_delta event for a text delta type are \"index\" and \"delta\", where the \"delta\" field contains a \"type\" of \"text_delta\" and the \"text\" being added."
    },
    {
      "id": "9bdcd7a7",
      "question": "What are two interactive ways to learn how to use Claude's capabilities, such as uploading PDFs and generating embeddings?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/quickstart#next-steps",
        "https://docs.anthropic.com/en/docs/welcome#develop-with-claude"
      ],
      "correct_answer": "The Anthropic Cookbook provides interactive Jupyter notebooks demonstrating how to upload PDFs, generate embeddings, and more. The Developer Console offers a prompt generator tool for easier, more powerful prompting."
    },
    {
      "id": "c417a6d5",
      "question": "Why does breaking a task into distinct subtasks for chained prompts help improve Claude's accuracy on the overall task?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-prompts#how-to-chain-prompts",
        "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-prompts#why-chain-prompts"
      ],
      "correct_answer": "Breaking a task into distinct subtasks for chained prompts improves Claude's accuracy because each subtask gets Claude's full attention, reducing errors compared to tackling the entire complex task at once."
    },
    {
      "id": "8b4a2fc0",
      "question": "How does the streaming format for Messages responses differ from Text Completions streaming responses?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/api/migrating-from-text-completions-to-messages#streaming-format"
      ],
      "correct_answer": "Messages streaming responses can contain multiple content blocks of varying types, making the streaming format more complex compared to Text Completions which only include completion, ping, and error server-sent-events."
    },
    {
      "id": "9aca7b76",
      "question": "What are two ways to start experimenting with Claude as a user, according to Anthropic's documentation?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/about-claude/models#get-started-with-claude"
      ],
      "correct_answer": "According to the documentation, users can start experimenting with Claude by visiting claude.ai or using Anthropic's web Console."
    },
    {
      "id": "6c0f4d5c",
      "question": "How can using chain prompts help reduce errors and inconsistency in complex tasks handled by Claude?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/chain-prompts#why-chain-prompts",
        "https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/increase-consistency#chain-prompts-for-complex-tasks"
      ],
      "correct_answer": "Chain prompts break complex tasks into smaller subtasks, allowing Claude to give its full attention to each one. This reduces errors and inconsistencies that may occur when trying to handle a complex workflow all at once."
    },
    {
      "id": "62f954f3",
      "question": "What HTTP status code does an overloaded_error event correspond to in a non-streaming context for the Anthropic API?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/api/streaming#error-event-types",
        "https://docs.anthropic.com/en/api/messages-streaming#error-events"
      ],
      "correct_answer": "In a non-streaming context, an overloaded_error event would normally correspond to an HTTP 529 status code."
    },
    {
      "id": "14f1a19f",
      "question": "What are the two ways to specify the format in which Voyage AI returns embeddings through its HTTP API?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/build-with-claude/embeddings#voyage-http-api"
      ],
      "correct_answer": "When making a request to Voyage AI's embedding endpoint, you can either leave the encoding_format parameter unspecified to get the embeddings as lists of floating-point numbers, or set encoding_format to \"base64\" to get the embeddings compressed to Base64 encodings."
    },
    {
      "id": "b210bd3e",
      "question": "When streaming API requests that use tools, how are the input JSON deltas for tool_use content blocks sent, and how can they be accumulated and parsed by the client?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/api/messages-streaming#input-json-delta",
        "https://docs.anthropic.com/en/api/messages-streaming#streaming-request-with-tool-use"
      ],
      "correct_answer": "When streaming requests with tool use, the input JSON deltas for tool_use content blocks are sent as partial JSON strings in multiple content_block_delta events. The client can accumulate these partial JSON strings and parse the complete JSON object once a content_block_stop event is received, using a library like Pydantic for partial JSON parsing or helpers provided in Anthropic's SDKs."
    },
    {
      "id": "6ad104a4",
      "question": "What are the two interactive prompt engineering tutorials that Anthropic offers, and how do they differ?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/build-with-claude/claude-for-sheets#prompt-engineering-interactive-tutorial",
        "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering#prompt-engineering-tutorial"
      ],
      "correct_answer": "Anthropic offers a GitHub prompting tutorial that covers prompt engineering concepts in-depth with examples, and a lighter-weight Google Sheets prompting tutorial that utilizes Claude for Sheets."
    },
    {
      "id": "8d198f73",
      "question": "What are some of the key capabilities that make Claude suitable for enterprise use cases requiring integration with specialized applications and processing of large volumes of sensitive data?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/intro-to-claude#enterprise-considerations"
      ],
      "correct_answer": "Claude offers a 200K token context window, tool use for integration into specialized applications, multimodal input capabilities for richer context, and is uniquely positioned to serve high-trust industries processing large volumes of sensitive data with enterprise-grade security and data handling."
    },
    {
      "id": "e3d79e9c",
      "question": "As of June 2024, in which regions are Anthropic's Claude.ai API and iOS app available?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/release-notes/claude-apps#may-1st-2024",
        "https://docs.anthropic.com/en/release-notes/claude-apps#june-5th-2024",
        "https://docs.anthropic.com/en/release-notes/claude-apps#may-13th-2024"
      ],
      "correct_answer": "As of June 2024, Anthropic's Claude.ai API and iOS app are available in the United States, Canada, and Europe."
    },
    {
      "id": "c4595f69",
      "question": "What are the two main approaches for integrating Claude into a support ticket workflow, and how do they differ in terms of scalability and ease of implementation?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/about-claude/use-cases/ticket-routing#integrate-claude-into-your-support-workflow",
        "https://docs.anthropic.com/en/docs/about-claude/use-cases/ticket-routing#introduction"
      ],
      "correct_answer": "The two main approaches for integrating Claude into a support ticket workflow are push-based using webhooks, and pull-based. The push-based approach is more web-scalable but requires exposing a public endpoint which has IT security implications. The pull-based approach is easier to implement but makes unnecessary calls to the support ticket system."
    },
    {
      "id": "1586025c",
      "question": "When did Anthropic release a prompt generator tool to help guide Claude in generating high-quality prompts, and through what interface is it available?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/release-notes/api#may-10th-2024"
      ],
      "correct_answer": "On May 10th, 2024, Anthropic released a prompt generator tool that is available through the Developer Console."
    },
    {
      "id": "d44cb7a1",
      "question": "Which Claude 3 model provides the best balance of intelligence and speed for high-throughput tasks like sales forecasting and targeted marketing?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/api/claude-on-vertex-ai#api-model-names",
        "https://docs.anthropic.com/en/docs/intro-to-claude#claude-3-family"
      ],
      "correct_answer": "The Claude 3 Sonnet model balances intelligence and speed, making it well-suited for high-throughput tasks like sales forecasting and targeted marketing."
    },
    {
      "id": "504f7f0b",
      "question": "How can you calculate the similarity between two Voyage embedding vectors, and what is this equivalent to since Voyage embeddings are normalized to length 1?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/build-with-claude/embeddings#faq",
        "https://docs.anthropic.com/en/docs/build-with-claude/embeddings#voyage-embedding-example"
      ],
      "correct_answer": "You can calculate the similarity between two Voyage embedding vectors using the dot product, which is equivalent to cosine similarity since Voyage embeddings are normalized to length 1."
    },
    {
      "id": "c832aa3f",
      "question": "How can using examples in prompts improve Claude's performance on complex tasks?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/multishot-prompting#why-use-examples",
        "https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/increase-consistency#chain-prompts-for-complex-tasks"
      ],
      "correct_answer": "Well-chosen examples in prompts can boost Claude's ability to handle complex tasks by reducing misinterpretation of instructions, enforcing consistent structure and style, and serving as a guide for the desired output."
    },
    {
      "id": "4f4bffdb",
      "question": "What are the two types of content block deltas that can be emitted when streaming responses with tool use, and what does each delta type contain?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/api/messages-streaming#input-json-delta",
        "https://docs.anthropic.com/en/api/messages-streaming#text-delta",
        "https://docs.anthropic.com/en/api/messages-streaming#streaming-request-with-tool-use",
        "https://docs.anthropic.com/en/api/messages-streaming#delta-types"
      ],
      "correct_answer": "When streaming responses with tool use, the two types of content block deltas are text deltas and input JSON deltas. Text deltas contain a \"text\" field with a string of the incrementally generated text. Input JSON deltas contain a \"partial_json\" field with a string containing part of the JSON object specifying the tool's input."
    },
    {
      "id": "d4450a54",
      "question": "What are two key capabilities of Claude that enable it to build interactive systems and personalized user experiences?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/build-with-claude/text-generation#text-capabilities-and-use-cases"
      ],
      "correct_answer": "Claude's question answering and text analysis capabilities enable it to build intelligent, interactive systems like chatbots and personalize user experiences by understanding sentiment and preferences."
    },
    {
      "id": "e2aa4790",
      "question": "What are the key event types included in a raw HTTP stream response when using message streaming, and what is the typical order they occur in?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/api/messages-streaming#event-types",
        "https://docs.anthropic.com/en/api/messages-streaming#raw-http-stream-response"
      ],
      "correct_answer": "A raw HTTP stream response includes a message_start event, followed by one or more content blocks (each with a content_block_start, content_block_delta events, and content_block_stop), a message_delta event, and a final message_stop event. Ping events may also be dispersed throughout."
    },
    {
      "id": "5a8635d2",
      "question": "What is the maximum number of images that can be included in a single request using the Anthropic API compared to the claude.ai interface?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/build-with-claude/vision#about-the-prompt-examples",
        "https://docs.anthropic.com/en/docs/build-with-claude/vision#faq"
      ],
      "correct_answer": "The Messages API allows including up to 20 images per request, while the claude.ai interface has a lower limit of up to 5 images per turn."
    },
    {
      "id": "9dc406cc",
      "question": "When Claude's response is cut off due to hitting the max_tokens limit and contains an incomplete tool use block, what should you do to get the full tool use?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/build-with-claude/tool-use#troubleshooting-errors"
      ],
      "correct_answer": "If Claude's response hits the max_tokens limit and has an incomplete tool use block, you should retry the request with a higher max_tokens value to get Claude's full response including the complete tool use."
    },
    {
      "id": "aa1cd66b",
      "question": "What two steps are needed before running a classification evaluation on Claude according to the documentation?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/about-claude/use-cases/classification#3-run-your-eval",
        "https://docs.anthropic.com/en/docs/about-claude/use-cases/classification#2-develop-your-test-cases"
      ],
      "correct_answer": "Before running a classification evaluation on Claude, you need to 1) develop your test cases, and 2) take a look at Anthropic's guide to developing test cases."
    },
    {
      "id": "d34c0f56",
      "question": "How can you use the content parameter in the messages list to influence Claude's response?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/api/messages-examples#basic-request-and-response",
        "https://docs.anthropic.com/en/api/messages-examples#putting-words-in-claudes-mouth"
      ],
      "correct_answer": "You can provide content in the last position of the messages list, with the \"assistant\" role, to pre-fill part of Claude's response. This allows you to shape the assistant's output."
    },
    {
      "id": "77486ab3",
      "question": "What are two key advantages of prompt engineering over fine-tuning when it comes to model comprehension and general knowledge preservation?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering#when-to-prompt-engineer",
        "https://docs.anthropic.com/en/docs/resources/glossary#fine-tuning"
      ],
      "correct_answer": "Compared to fine-tuning, prompt engineering is far more effective at helping models understand and utilize external content like retrieved documents. Prompt engineering also preserves the model's broad general knowledge, while fine-tuning risks catastrophic forgetting where the model loses its general capabilities."
    },
    {
      "id": "43abd3af",
      "question": "What are the two main steps to get started with making requests to Claude models on Anthropic's Bedrock API?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/api/claude-on-amazon-bedrock#install-and-configure-the-aws-cli",
        "https://docs.anthropic.com/en/api/claude-on-amazon-bedrock#making-requests"
      ],
      "correct_answer": "To get started making requests to Claude models on Anthropic's Bedrock API, you need to: 1) Install and configure the AWS CLI, and 2) Install an SDK for accessing Bedrock, such as the Python SDK shown in the example code."
    },
    {
      "id": "0a4078a0",
      "question": "How can you check which Claude models are available in a specific AWS region using the AWS CLI?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/api/claude-on-amazon-bedrock#subscribe-to-anthropic-models",
        "https://docs.anthropic.com/en/api/claude-on-amazon-bedrock#list-available-models"
      ],
      "correct_answer": "You can list the available Claude models in a specific AWS region by running the command `aws bedrock list-foundation-models --region=<region> --by-provider anthropic --query \"modelSummaries[*].modelId\"`, replacing `<region>` with the desired AWS region such as `us-west-2`."
    },
    {
      "id": "6de4b0f2",
      "question": "What argument can be passed to the voyageai.Client.embed() method or the Voyage HTTP API to specify whether the input text is a query or a document?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/build-with-claude/embeddings#voyage-python-package",
        "https://docs.anthropic.com/en/docs/build-with-claude/embeddings#voyage-http-api"
      ],
      "correct_answer": "The input_type argument can be passed with a value of \"query\" or \"document\" to specify the type of input text being embedded."
    },
    {
      "id": "aadfaa87",
      "question": "How do the streaming API delta formats differ between tool_use content blocks and text content blocks?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/api/messages-streaming#input-json-delta",
        "https://docs.anthropic.com/en/api/messages-streaming#text-delta"
      ],
      "correct_answer": "Tool_use content block deltas contain partial JSON strings for the input field, whereas text content block deltas directly contain the text delta. Tool_use deltas may have delays between streaming events as the model emits one complete key-value pair at a time."
    },
    {
      "id": "c3a053df",
      "question": "What are the image file size limits when uploading images to Claude using the API versus on claude.ai?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/build-with-claude/vision#faq"
      ],
      "correct_answer": "When uploading images to Claude, the API has a maximum file size limit of 5MB per image, while on claude.ai the limit is 10MB per image."
    },
    {
      "id": "f6c21a30",
      "question": "What is one key consideration when selecting a Claude model for an enterprise use case that needs low latency?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/intro-to-claude#model-options",
        "https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/reduce-latency#1-choose-the-right-model"
      ],
      "correct_answer": "When selecting a Claude model for an enterprise use case that requires low latency, it's important to choose the model that best balances speed and output quality based on the specific requirements of the use case."
    },
    {
      "id": "86d2a94c",
      "question": "What embedding model does Anthropic recommend for code retrieval, and how does its performance compare to alternatives according to Voyage AI?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/build-with-claude/embeddings#how-to-get-embeddings-with-anthropic",
        "https://docs.anthropic.com/en/docs/build-with-claude/embeddings#available-voyage-models"
      ],
      "correct_answer": "For code retrieval, Voyage AI recommends using the voyage-code-2 embedding model, which they claim performs 17% better than alternatives and achieves state-of-the-art results on general-purpose corpora as well."
    },
    {
      "id": "142b8567",
      "question": "What are two ways the Anthropic Cookbook can help developers learn to use Anthropic's APIs?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/welcome#develop-with-claude",
        "https://docs.anthropic.com/en/docs/quickstart#next-steps"
      ],
      "correct_answer": "The Anthropic Cookbook provides interactive Jupyter notebooks that demonstrate how to upload PDFs and work with embeddings to help developers learn to use Anthropic's APIs."
    },
    {
      "id": "79f3daa2",
      "question": "How does the size of the context window impact a language model's ability to utilize retrieval augmented generation (RAG)?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/resources/glossary#context-window",
        "https://docs.anthropic.com/en/docs/resources/glossary#rag-retrieval-augmented-generation"
      ],
      "correct_answer": "The size of the context window determines how much retrieved information can be passed to the language model to augment its knowledge when generating a response using RAG. A larger context window allows more relevant retrieved information to be utilized by the model, improving the accuracy and groundedness of the generated text."
    },
    {
      "id": "6e0b6937",
      "question": "How can the Evaluation tool in Anthropic's Claude platform help improve prompts and build more robust AI applications?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/test-and-evaluate/eval-tool#understanding-results",
        "https://docs.anthropic.com/en/docs/test-and-evaluate/eval-tool#creating-test-cases"
      ],
      "correct_answer": "The Evaluation tool helps identify edge cases where prompts might falter, allows rating individual results to determine prompt performance, ensures consistent performance across inputs, and enables prompt refinement for better reliability. Reviewing results across test cases helps spot patterns to make informed adjustments that lead to more robust AI applications."
    },
    {
      "id": "fdb1a88a",
      "question": "Which Claude model has the fastest comparative latency according to the comparison tables?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/about-claude/models#model-comparison",
        "https://docs.anthropic.com/en/docs/about-claude/models#legacy-model-comparison"
      ],
      "correct_answer": "The Claude 3 Haiku model has the fastest comparative latency"
    },
    {
      "id": "bad75951",
      "question": "How can you build up a conversation with multiple turns using the Anthropic Messages API in Python?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/api/client-sdks#python",
        "https://docs.anthropic.com/en/api/messages-examples#multiple-conversational-turns"
      ],
      "correct_answer": "To have a multi-turn conversation using the Anthropic Messages API in Python, send the full conversation history in the messages parameter each time, including any prior user and assistant messages. The API is stateless, so the entire context must be provided with each request."
    },
    {
      "id": "4d389de9",
      "question": "How can using XML tags to provide a specific role or context help improve Claude's analysis of a legal contract compared to not using a role prompt?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/use-xml-tags#examples",
        "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/system-prompts#example-1-legal-contract-analysis"
      ],
      "correct_answer": "Providing Claude with a specific role, such as being the General Counsel of a company, using XML tags can help it catch critical legal issues and risks in a contract that it might miss without the role context, potentially saving the company millions of dollars."
    },
    {
      "id": "7cd7d72d",
      "question": "What are the key differences between how Claude 3 Opus and Claude 3 Sonnet handle missing information when making tool calls?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/build-with-claude/tool-use#chain-of-thought",
        "https://docs.anthropic.com/en/docs/build-with-claude/tool-use#tool-use-examples"
      ],
      "correct_answer": "When required parameters are missing, Claude 3 Opus is more likely to ask the user for the missing information, while Claude 3 Sonnet is more likely to try to infer reasonable values on its own to proceed with the tool call."
    },
    {
      "id": "8019b9f5",
      "question": "What steps should be taken to ensure a reliable deployment of an automated ticket routing system using Claude into a production environment?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/about-claude/use-cases/ticket-routing#additional-considerations",
        "https://docs.anthropic.com/en/docs/about-claude/use-cases/ticket-routing#integrate-claude-into-your-support-workflow"
      ],
      "correct_answer": "To ensure a reliable production deployment of Claude for ticket routing, key steps include implementing retry logic to handle errors, conducting thorough staging and load testing, setting up error handling and logging, using a gradual rollout process, providing documentation and training, and establishing monitoring and alerting."
    },
    {
      "id": "2c3d41c0",
      "question": "How should you evaluate a model's performance on a ticket routing classifier?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/about-claude/use-cases/ticket-routing#evaluating-the-performance-of-your-ticket-routing-classifier",
        "https://docs.anthropic.com/en/docs/about-claude/use-cases/ticket-routing#integrate-claude-into-your-support-workflow"
      ],
      "correct_answer": "You should evaluate performance in terms of accuracy, cost, and speed."
    },
    {
      "id": "c3f8cb89",
      "question": "What two methods does Anthropic recommend for learning how to prompt engineer with Claude before diving into the techniques?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering#how-to-prompt-engineer",
        "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering#prompt-engineering-tutorial"
      ],
      "correct_answer": "Anthropic recommends trying their interactive GitHub prompting tutorial and Google Sheets prompting tutorial to learn prompt engineering concepts before diving into the techniques in the documentation."
    },
    {
      "id": "d4a4f9bb",
      "question": "What are the key differences between a pretrained large language model and Claude in terms of their training and capabilities?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/resources/glossary#llm",
        "https://docs.anthropic.com/en/docs/resources/glossary#pretraining"
      ],
      "correct_answer": "Pretrained large language models are trained on unlabeled text data to predict the next word given the previous context, but are not inherently good at answering questions or following instructions without prompt engineering. In contrast, Claude is a large language model that has been further fine-tuned and trained using RLHF to be more helpful, honest, and capable of performing a wider range of useful tasks."
    },
    {
      "id": "8853f420",
      "question": "What are some key advantages of using prompt engineering instead of fine-tuning to adapt a pretrained language model for a specific task or domain?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/resources/glossary#fine-tuning",
        "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering#when-to-prompt-engineer",
        "https://docs.anthropic.com/en/docs/resources/glossary#pretraining"
      ],
      "correct_answer": "Prompt engineering is typically faster, more cost-effective, requires less data and compute resources, and preserves the model's general knowledge compared to fine-tuning. It also allows for greater flexibility, rapid iteration, and transparency."
    },
    {
      "id": "618c064a",
      "question": "How can you authenticate with GCP before running requests to access Claude models on Vertex AI?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/api/claude-on-vertex-ai#making-requests",
        "https://docs.anthropic.com/en/api/claude-on-vertex-ai#accessing-vertex-ai"
      ],
      "correct_answer": "Before running requests to access Claude models on Vertex AI, you may need to run `gcloud auth application-default login` to authenticate with GCP."
    },
    {
      "id": "093",
      "question": "What new capabilities and features were introduced by Anthropic on May 10th, 2024 and how do they enable users to create and tailor prompts for specific tasks?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/release-notes/api#may-10th-2024"
      ],
      "correct_answer": "According to the information provided, on May 10th, 2024, Anthropic introduced a new \"Prompt Generator\" tool in the Developer Console. This tool is designed to help users guide Claude to generate high-quality prompts tailored to their specific tasks. The text states that the Prompt Generator \"makes it easy to guide Claude to generate a high-quality prompts tailored to your specific tasks.\" This indicates that the Prompt Generator feature provides users with the ability to create customized prompts for Claude, going beyond the standard prompting capabilities. By combining this information with the details about the Claude iOS app and the Claude Team plan released around the same time, we can infer that Anthropic was expanding its platform and tools to provide users with more advanced capabilities for interacting with and leveraging the Claude AI assistant for their specific needs and use cases."
    },
    {
      "id": "dee02469",
      "question": "On what date did both the Claude 3.5 Sonnet model and the Artifacts feature in Claude.ai become available?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/release-notes/api#june-20th-2024",
        "https://docs.anthropic.com/en/release-notes/claude-apps#june-20th-2024"
      ],
      "correct_answer": "Both Claude 3.5 Sonnet and the Artifacts feature in Claude.ai became available on June 20th, 2024."
    },
    {
      "id": "8367b42d",
      "question": "When putting words in Claude's mouth to shape the response, what header and value can you use in the request to limit Claude's response to a single token?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/api/messages-examples#basic-request-and-response",
        "https://docs.anthropic.com/en/api/messages-examples#putting-words-in-claudes-mouth"
      ],
      "correct_answer": "You can use \"max_tokens\": 1 in the request to limit Claude's response to a single token when putting words in its mouth."
    },
    {
      "id": "d82625d3",
      "question": "What does the temperature parameter do when working with large language models?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/resources/glossary#temperature",
        "https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/reduce-latency#2-optimize-prompt-and-output-length"
      ],
      "correct_answer": "Temperature is a parameter that controls the randomness of the model during generation"
    },
    {
      "id": "6e1e9bb2",
      "question": "What are two ways to specify API parameters when calling the Claude API using Claude for Sheets?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/test-and-evaluate/eval-tool#tips-for-effective-evaluation",
        "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prefill-claudes-response#how-to-prefill-claudes-response",
        "https://docs.anthropic.com/en/docs/build-with-claude/claude-for-sheets#enter-your-first-prompt"
      ],
      "correct_answer": "When calling the Claude API using Claude for Sheets, you can specify API parameters in two ways: 1) As additional arguments after the prompt and model in the CLAUDE() function, like =CLAUDE(prompt, model, \"max_tokens\", 3). 2) By passing in an API key to be used just for a specific cell, like \"api_key\", \"sk-ant-api03-j1W...\""
    },
    {
      "id": "5bb18b73",
      "question": "How does prefilling the response with an opening curly brace ({ ) affect Claude's output when extracting structured data from text?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prefill-claudes-response#example-1-controlling-output-formatting-and-skipping-the-preamble"
      ],
      "correct_answer": "Prefilling Claude's response with { causes it to skip the preamble explanation and directly output the extracted data as a JSON object, resulting in a more concise response that is easier for programs to parse without additional processing."
    },
    {
      "id": "6d9b42c3",
      "question": "What are some helpful resources provided by Anthropic to dive deeper into building with images using Claude?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/build-with-claude/vision#dive-deeper-into-vision",
        "https://docs.anthropic.com/en/docs/build-with-claude/vision#about-the-prompt-examples"
      ],
      "correct_answer": "Anthropic provides a multimodal cookbook with tips on getting started with images and best practices, as well as API reference documentation for the Messages API that includes example API calls involving images."
    },
    {
      "id": "ccd10bfd",
      "question": "How do you specify the API key when creating a new Anthropic client in the Python and TypeScript SDK examples?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/api/client-sdks#typescript",
        "https://docs.anthropic.com/en/api/client-sdks#python"
      ],
      "correct_answer": "In both the Python and TypeScript examples, you can specify the API key as a string parameter when creating a new Anthropic client object. If no API key is provided, it defaults to using the ANTHROPIC_API_KEY environment variable."
    },
    {
      "id": "2fa26c55",
      "question": "What are two key benefits of using the Anthropic Evaluation tool when developing prompts for an AI classification application?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/about-claude/use-cases/classification#2-develop-your-test-cases",
        "https://docs.anthropic.com/en/docs/test-and-evaluate/eval-tool#understanding-results"
      ],
      "correct_answer": "The Evaluation tool helps identify edge cases where the prompt might falter, and ensures consistent performance across a range of test case inputs. This allows you to refine the prompt for better reliability in the AI classification application."
    },
    {
      "id": "c7132d11",
      "question": "What are the key differences between a pretrained language model like Claude's underlying model, and the final version of Claude available through Anthropic's API?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/docs/resources/glossary#pretraining",
        "https://docs.anthropic.com/en/docs/resources/glossary#llm",
        "https://docs.anthropic.com/en/docs/resources/glossary#fine-tuning"
      ],
      "correct_answer": "The pretrained language model that forms Claude's foundation is not inherently good at answering questions or following instructions. To create the helpful, honest and safe Claude assistant available through the API, the pretrained model underwent fine-tuning and reinforcement learning from human feedback (RLHF)."
    },
    {
      "id": "feb91b26",
      "question": "What is the IPv6 address range used by Anthropic?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/api/ip-addresses#ipv6"
      ],
      "correct_answer": "The IPv6 address range used by Anthropic is 2607:6bc0::/48."
    },
    {
      "id": "32c48e52",
      "question": "When using the Python SDK to create a message with Claude, what are two ways you can specify your API key?",
      "correct_chunks": [
        "https://docs.anthropic.com/en/api/messages-examples#multiple-conversational-turns",
        "https://docs.anthropic.com/en/api/client-sdks#python"
      ],
      "correct_answer": "When using the Python SDK, you can specify your API key either by passing it as the api_key parameter when initializing the Anthropic client, or by setting it as an environment variable named ANTHROPIC_API_KEY which the client will use by default."
    }
  ]