{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f444d0f8-6172-4201-92ea-83c5f15bfff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import broadcast\n",
    "import spark_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a34996d-d2d8-48e6-ae08-99e166707a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing environment variables for Spark\n",
      "Creating a spark session...\n",
      "Spark session created\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <br/>\n",
       "            <p><b>Spark Context</b></p>\n",
       "            <dl>\n",
       "              <dt>Cluster Name</dt>\n",
       "                <dd><code>spark-cluster-mluser</code></dd>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://spark-cluster-mluser:7077</code></dd>\n",
       "              <dt>App Id</dt>\n",
       "                <dd><code>app-20220311073053-0004</code></dd>\n",
       "              <dt>App Name</dt>\n",
       "                <dd><code>Enrich flights data</code></dd>\n",
       "              <dt>Driver IP</dt>\n",
       "                <dd><code>172.17.0.4</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark context started.\n"
     ]
    }
   ],
   "source": [
    "submit_args = \"--conf spark.hadoop.fs.s3a.endpoint=http://minio-ml-workshop:9000 \\\n",
    "--conf spark.hadoop.fs.s3a.access.key=minio \\\n",
    "--conf spark.hadoop.fs.s3a.secret.key=minio123 \\\n",
    "--conf spark.hadoop.fs.s3a.path.style.access=true \\\n",
    "--conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem \\\n",
    "--conf spark.hadoop.fs.s3a.multipart.size=104857600 \\\n",
    "--packages org.apache.hadoop:hadoop-aws:3.2.0,org.postgresql:postgresql:42.3.3\"\n",
    "\n",
    "spark = spark_util.getOrCreateSparkSession(\"Enrich flights data\", submit_args)\n",
    "spark.sparkContext.setLogLevel(\"INFO\")\n",
    "print('Spark context started.')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "899d425b-35fa-4176-87dd-6e42fd4f3234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition count:31\n"
     ]
    }
   ],
   "source": [
    "df_flights = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:postgresql://pg-flights-data:5432/postgres\") \\\n",
    "    .option(\"dbtable\", \"flights\") \\\n",
    "    .option(\"user\", \"postgres\") \\\n",
    "    .option(\"password\", \"postgres\") \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .option(\"numPartitions\", 31) \\\n",
    "    .option(\"partitionColumn\", \"day\") \\\n",
    "    .option(\"lowerBound\", 0)\\\n",
    "    .option(\"upperBound\", 31)\\\n",
    "    .load()\n",
    "\n",
    "print(f\"Partition count:{df_flights.rdd.getNumPartitions()}\")\n",
    "\n",
    "df_airlines = spark.read\\\n",
    "                .options(delimeter=',', inferSchema='True', header='True') \\\n",
    "                .csv(\"s3a://airport-data/airlines.csv\")\n",
    "df_airports = spark.read\\\n",
    "                .options(delimiter=',', inferSchema='True', header='True') \\\n",
    "                .csv(\"s3a://airport-data/airports.csv\")\n",
    "\n",
    "#df_flights.printSchema()\n",
    "#df_airlines.printSchema()\n",
    "#df_airports.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3d4431b-faea-4c6b-8077-3da74deee9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df_airlines = df_airlines.select([col(c).alias(\"AL_\"+c) for c in df_airlines.columns])\n",
    "df_o_airports = df_airports.select([col(c).alias(\"ORIG_\"+c) for c in df_airports.columns])\n",
    "df_d_airports = df_airports.select([col(c).alias(\"DEST_\"+c) for c in df_airports.columns])\n",
    "#df_airlines.printSchema()\n",
    "#df_o_airports.printSchema()\n",
    "#df_d_airports.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3185158-19ed-44e2-bbad-327bc64e9fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- day_of_week: integer (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- flight_number: integer (nullable = true)\n",
      " |-- tail_number: string (nullable = true)\n",
      " |-- origin_airport: string (nullable = true)\n",
      " |-- destination_airport: string (nullable = true)\n",
      " |-- scheduled_departure: string (nullable = true)\n",
      " |-- departure_time: string (nullable = true)\n",
      " |-- departure_delay: integer (nullable = true)\n",
      " |-- taxi_out: integer (nullable = true)\n",
      " |-- wheels_off: string (nullable = true)\n",
      " |-- scheduled_time: integer (nullable = true)\n",
      " |-- elapsed_time: integer (nullable = true)\n",
      " |-- air_time: integer (nullable = true)\n",
      " |-- distance: integer (nullable = true)\n",
      " |-- wheels_on: string (nullable = true)\n",
      " |-- taxi_in: integer (nullable = true)\n",
      " |-- scheduled_arrival: string (nullable = true)\n",
      " |-- arrival_time: string (nullable = true)\n",
      " |-- arrival_delay: integer (nullable = true)\n",
      " |-- diverted: integer (nullable = true)\n",
      " |-- cancelled: integer (nullable = true)\n",
      " |-- cancellation_reason: string (nullable = true)\n",
      " |-- air_system_delay: integer (nullable = true)\n",
      " |-- security_delay: integer (nullable = true)\n",
      " |-- airline_delay: integer (nullable = true)\n",
      " |-- late_aircraft_delay: integer (nullable = true)\n",
      " |-- weather_delay: integer (nullable = true)\n",
      " |-- AL_IATA_CODE: string (nullable = true)\n",
      " |-- AL_AIRLINE: string (nullable = true)\n",
      " |-- ORIG_IATA_CODE: string (nullable = true)\n",
      " |-- ORIG_AIRPORT: string (nullable = true)\n",
      " |-- ORIG_CITY: string (nullable = true)\n",
      " |-- ORIG_STATE: string (nullable = true)\n",
      " |-- ORIG_COUNTRY: string (nullable = true)\n",
      " |-- ORIG_LATITUDE: double (nullable = true)\n",
      " |-- ORIG_LONGITUDE: double (nullable = true)\n",
      " |-- DEST_IATA_CODE: string (nullable = true)\n",
      " |-- DEST_AIRPORT: string (nullable = true)\n",
      " |-- DEST_CITY: string (nullable = true)\n",
      " |-- DEST_STATE: string (nullable = true)\n",
      " |-- DEST_COUNTRY: string (nullable = true)\n",
      " |-- DEST_LATITUDE: double (nullable = true)\n",
      " |-- DEST_LONGITUDE: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_flights = df_flights\\\n",
    "    .join(broadcast(df_airlines), df_flights.airline == df_airlines.AL_IATA_CODE)\\\n",
    "    .join(broadcast(df_o_airports), df_flights.origin_airport == df_o_airports.ORIG_IATA_CODE)\\\n",
    "    .join(broadcast(df_d_airports), df_flights.destination_airport == df_d_airports.DEST_IATA_CODE)\n",
    "\n",
    "#df_flights.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d3ffaf2-53d5-41ef-863b-e389f6c47562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5332914"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_location = \"s3a://flights-data/flights\"\n",
    "\n",
    "df_flights.cache() #this is to make sure the DAG is not recalculated when we call the .count() later\n",
    "df_flights.write.mode(\"overwrite\")\\\n",
    "    .option(\"header\",\"true\")\\\n",
    "    .format(\"parquet\").save(output_location)\n",
    "\n",
    "df_flights.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ea1e0f6-1e30-429d-87d6-0f8b80470ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e88c07-6d17-49f9-a8a3-90efd4fb1c20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
