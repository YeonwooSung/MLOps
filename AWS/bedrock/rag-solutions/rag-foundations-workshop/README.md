# AIM307 2023 - Retrieval Augmented Generation with Amazon Bedrock

Welcome to re\:Invent 2023! Large language models (LLMs) are often limited by the data they were trained on and donâ€™t always provide up-to-date responses, or worse, they make things up. To overcome this limitation, you can supplement prompts with up-to-date information using embeddings stored in vector databases, a process known as Retrieval Augmented Generation (RAG). With supplemental information in the prompt providing more context, the LLM can respond more accurately and is less likely to hallucinate.

In this workshop you will learn how to build a Retrieval Augmented Generation (RAG) system powered Amazon Bedrock. Throughout this workshop you will learn how to...

1. Use the Amazon Bedrock API to leverage generative AI (GenAI) models in an easy to use manner
2. Use Anthropic's Claude model for text generation
3. Build a conversational interface to a large language model
4. Use Amazon's Titan Text Embeddings model to create high quality text embeddings 
5. Ingest embeddings into a local vector database to power a semantic search capability
6. Combine the power of large language models with semantic search to create a RAG application
7. Combine the power of large language models with APIs to create a RAG application which interacts with APIs

Go ahead and open [this notebook](./notebooks/01_workshop_setup.ipynb) to get started building with Amazon Bedrock!

