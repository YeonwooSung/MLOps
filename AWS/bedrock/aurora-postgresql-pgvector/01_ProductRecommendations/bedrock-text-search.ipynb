{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c01cb58e",
   "metadata": {},
   "source": [
    "# Building AI-Powered semantic product catalog search \n",
    "### Using a pretrained LLM and Amazon Aurora PostgreSQL extension `pgvector` \n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## Contents\n",
    "\n",
    "\n",
    "1. [Background](#Background)\n",
    "1. [Architecture](#Architecture)\n",
    "1. [Setup](#Setup)\n",
    "1. [Amazon Bedrock Model Hosting](#Amazon-Bedrock-Model-Hosting)\n",
    "1. [Load data into PostgreSQL](#Open-source-extension-pgvector-in-PostgreSQL)\n",
    "1. [Evaluate Search Results](#Evaluate-PostgreSQL-vector-Search-Results)\n",
    "\n",
    "## Background\n",
    "\n",
    "\n",
    "Semantic search is a type of search technique that aims to understand the intent and context of a user's query, rather than simply matching keywords or phrases. It goes beyond traditional keyword-based search by considering the meaning of words, the relationships between them, and the overall context of the query to deliver more relevant search results. Semantic search is important because it can help users to find the information they are looking for more quickly and easily.\n",
    "\n",
    "Here are some examples of how semantic search is used today:\n",
    "- Amazon uses semantic search to help customers find the products they are looking for. For example, if you search for \"blue running shoes,\" Amazon will return results for shoes that are both blue and designed for running, even if you didn't use both of those keywords in your query.\n",
    "- Netflix uses semantic search to recommend movies and TV shows to its users. For example, if you watch a lot of documentaries, Netflix will recommend other documentaries that you may be interested in.\n",
    "- Google uses semantic search to improve the relevance of its search results. For example, if you search for \"capital of France,\" Google will return results for Paris, even though you didn't explicitly mention Paris in your query.\n",
    "\n",
    "\n",
    "In this notebook, we'll build the core components of a textually similar Products. Often people don't know what exactly they are looking for and in that case they just type an item description and hope it will retrieve similar items. Other times, they have a photo of a product and looking for similar products matching those items.\n",
    "\n",
    "One of the core components of searching textually similar items is a fixed length sentence/word embedding i.e. a  “feature vector” that corresponds to that text. The reference word/sentence embedding typically are generated offline and must be stored so they can be efficiently searched. In this use case we are using a pretrained SentenceTransformer model `amazon.titan-embed-g1-text-02` from [Amazon Titan](https://aws.amazon.com/bedrock/titan/)\n",
    " \n",
    "To enable efficient searches for textually similar items, we'll use [Amazon Bedrock](https://aws.amazon.com/bedrock/) to generate fixed length sentence embeddings i.e “feature vectors” and use the Nearest Neighbor search in Amazon Aurora for PostgreSQL using the extension [pgvector](https://github.com/pgvector/pgvector). The PostgreSQL `pgvector` extension lets you store and search for points in vector space and find the \"nearest neighbors\" for those points. Use cases include recommendations (for example, an \"other songs you might like\" feature in a music application), image recognition, and fraud detection.\n",
    "\n",
    "Here are the steps we'll follow to build textually similar items: \n",
    "- Generate feature vectors for the products description from kaggle dataset using Amazon Titan Embedding model. \n",
    "- Store the generated vectors in Amazon Aurora for PostgreSQL as vector datatype along with the metadata \n",
    "- Explore some sample text queries, and visualize the results.\n",
    "\n",
    "## Architecture\n",
    "\n",
    "![](./static/arch_product_recommendation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ae57bd",
   "metadata": {},
   "source": [
    "**Step 1.** We will download the Kaggle dataset and generate embeddings using `amazon.titan-embed-g1-text-02`  from Amazon Titan and store it in the Amazon Aurora PostgreSQL instance with pgvector extension\n",
    " \n",
    "**Step 2.** Search for a product with a keyword, which will be converted to embeddings and searched in the Amazon Aurora PostgreSQL database with Approximate Nearest Search and provide the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7045906",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Install required python libraries for the workshop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f11c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install all the required prerequiste libraries - approx 3 min to complete\n",
    "%pip install -U pgvector pandarallel boto3 psycopg numexpr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f3cadd",
   "metadata": {},
   "source": [
    "## Download Amazon Product Catalog from Kaggle\n",
    "\n",
    "The [dataset](https://www.kaggle.com/datasets/promptcloud/amazon-product-dataset-2020) consists of 9000+ Amazon products along with the different descriptions of the product. The data was already downloaded as a csv file and we will load it into pandas dataframe to further process it. We will be combining the data in the colums `About Product`, `Product Specification` and `Technical Details` as `all_descriptions` to be used to convert to vector embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc29ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data of csv\n",
    "df = pd.read_csv('data/amazon.csv')\n",
    "df = df[['Uniq Id','Product Name','Category','About Product','Product Specification','Technical Details','Image']]\n",
    "\n",
    "df = df.dropna(subset=['About Product'])\n",
    "df = df.fillna('')\n",
    "df.rename(columns={'Uniq Id': 'id', \n",
    "                   'Product Name': 'product_name',\n",
    "                   'Category':'category',\n",
    "                   'About Product':'product_description',\n",
    "                   'Product Specification':'product_specification',\n",
    "                   'Technical Details':'product_details',\n",
    "                   'Image':'image_url'}, inplace=True)\n",
    "\n",
    "df['all_descriptions'] = df['product_description'] + df['product_specification'] + df['product_details']\n",
    "\n",
    "print(\"Total number of records : {}\".format(len(df.index)))\n",
    "\n",
    "display(df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caa2f4b",
   "metadata": {},
   "source": [
    "##  Amazon Bedrock Model Hosting\n",
    "\n",
    "In this section we will deploy the pretrained `amazon.titan-embed-g1-text-02` from Amazon Titan SentenceTransformer model into Amazon Bedrock and generates 1536 dimensional vector embeddings for our product catalog descriptions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33e8f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "bedrock = boto3.client(service_name=\"bedrock\")\n",
    "bedrock_runtime = boto3.client(service_name=\"bedrock-runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5702a52",
   "metadata": {},
   "source": [
    "Function to convert the text into vector embeddings. This function will be called for all the individual product descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf96a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(query):\n",
    "    \n",
    "    payLoad = json.dumps({'inputText': query })\n",
    "    \n",
    "    response = bedrock_runtime.invoke_model(\n",
    "        body=payLoad, \n",
    "        modelId='amazon.titan-embed-g1-text-02',\n",
    "        accept=\"application/json\", \n",
    "        contentType=\"application/json\" )\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "    return(response_body.get(\"embedding\"))\n",
    "    \n",
    "description_embeddings = generate_embeddings(df.iloc[1].get('all_descriptions'))\n",
    "\n",
    "print (\"Number of dimensions : {}\".format(len(description_embeddings)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e0f848",
   "metadata": {},
   "source": [
    "In this code block, we will scan through all the data in the dataframe for the text stored in the `all_descriptions` column and convert it as embeddings using Amazon Titan Embeddings model and store it as `description_embeddings` column in the same dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621ee8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for all the products descriptions - approx 3 min to complete\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "pandarallel.initialize(progress_bar=True, nb_workers=8)\n",
    "\n",
    "# Generate Embeddings for all the products \n",
    "df['description_embeddings'] = df['all_descriptions'].parallel_apply(generate_embeddings)\n",
    "\n",
    "df.head()\n",
    "\n",
    "print(\"Completed generation of embeddings for all the products descriptions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453e107d",
   "metadata": {},
   "source": [
    "## Open-source extension pgvector in PostgreSQL\n",
    "\n",
    "`pgvector` is an open-source extension for PostgreSQL that allows you to store and search vector embeddings for exact and approximate nearest neighbors. It is designed to work seamlessly with other PostgreSQL features, including indexing and querying.\n",
    "\n",
    "One of the key benefits of using pgvector is that it allows you to perform similarity searches on large datasets quickly and efficiently. This is particularly useful in industries like e-commerce, where businesses need to be able to quickly search through large product catalogs to find the items that best match a customer's preferences. It supports exact and approximate nearest neighbor search, L2 distance, inner product, and cosine distance.\n",
    "\n",
    "To further optimize your searches, you can also use pgvector's indexing features. By creating indexes on your vector data, you can speed up your searches and reduce the amount of time it takes to find the nearest neighbors to a given vector.\n",
    "\n",
    "In this step we'll get all the product descriptions of *Amazon Products* dataset and store those embeddings into Amazon Aurora PostgreSQL vector type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f2a150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg\n",
    "from pgvector.psycopg import register_vector\n",
    "import boto3 \n",
    "import json \n",
    "import numpy as np\n",
    "\n",
    "client = boto3.client('secretsmanager')\n",
    "\n",
    "response = client.get_secret_value(SecretId='apgpg-pgvector-secret')\n",
    "database_secrets = json.loads(response['SecretString'])\n",
    "\n",
    "dbhost = database_secrets['host']\n",
    "dbport = database_secrets['port']\n",
    "dbuser = database_secrets['username']\n",
    "dbpass = database_secrets['password']\n",
    "\n",
    "dbconn = psycopg.connect(host=dbhost, user=dbuser, password=dbpass, port=dbport, connect_timeout=10, autocommit=True)\n",
    "\n",
    "dbconn.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "register_vector(dbconn)\n",
    "\n",
    "dbconn.execute(\"DROP TABLE IF EXISTS products;\")\n",
    "\n",
    "dbconn.execute(\"\"\"CREATE TABLE IF NOT EXISTS products(\n",
    "                   id text primary key, \n",
    "                   product_name text, \n",
    "                   category text, \n",
    "                   product_description text, \n",
    "                   product_specification text,\n",
    "                   product_details text,   \n",
    "                   image_url text,\n",
    "                   description_embeddings vector(1536));\"\"\")\n",
    "\n",
    "for _, x in df.iterrows():\n",
    "    dbconn.execute(\"\"\"INSERT INTO products\n",
    "                  (id, product_name, category, product_description, product_specification, product_details, image_url, description_embeddings) \n",
    "                   VALUES(%s, %s, %s, %s, %s, %s, %s, %s);\"\"\", \n",
    "                   (x.get('id'), x.get('product_name'), x.get('category'), x.get('product_description'), x.get('product_specification'), x.get('product_details'), x.get('image_url'), x.get('description_embeddings')))\n",
    "\n",
    "dbconn.execute(\"\"\"CREATE INDEX ON products \n",
    "                   USING hnsw (description_embeddings vector_cosine_ops) \n",
    "                   WITH  (m = 16, ef_construction = 64);\"\"\")\n",
    "\n",
    "dbconn.execute(\"VACUUM ANALYZE products;\")\n",
    "\n",
    "dbconn.close()\n",
    "print (\"Vector embeddings has been successfully loaded into Aurora PostgreSQL tables \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a93851",
   "metadata": {},
   "source": [
    "## Evaluate PostgreSQL vector search results\n",
    "\n",
    "In this step we will use pretrained `amazon.titan-embed-g1-text-02` model from Amazon Titan to generate embeddings for the query and use the embeddings to search the Amazon Aurora PostgreSQL to retrive the nearest neighbours and retrive the relevent product images along with its descriptions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2053a4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from IPython.display import display, Markdown, Latex, HTML\n",
    "\n",
    "\n",
    "def similarity_search(search_text):\n",
    "    \n",
    "    embedding = numpy.array(generate_embeddings(search_text))\n",
    "    dbconn = psycopg.connect(host=dbhost, user=dbuser, password=dbpass, port=dbport, connect_timeout=10)\n",
    "    register_vector(dbconn)\n",
    "    \n",
    "    r= dbconn.execute(\"\"\"SELECT id, image_url, product_name, product_description, product_details\n",
    "                         FROM products \n",
    "                         ORDER BY description_embeddings <=> %s limit 3;\"\"\",(embedding,)).fetchall()\n",
    "   \n",
    "    img_td = \"\"\n",
    "    for x in r:\n",
    "        url = x[1].split(\"|\")[0]\n",
    "        img_td = img_td + \"\"\"<tr><td><img src={} width=\"1000\"></td>\"\"\".format(url)\n",
    "        img_td = img_td + \"\"\"<td style=\"text-align: left; vertical-align: top;\"> <h3>{}</h3> <p>{}</p></td></tr>\"\"\".format(str(x[2]),str(x[4]))\n",
    "       \n",
    "    display(HTML(\"\"\"<table>{}</table>\"\"\".format(img_td)))\n",
    "    dbconn.close()\n",
    "\n",
    "print(\"Created similarity_search function successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8812e7",
   "metadata": {},
   "source": [
    "Using the above `similarity_search` function, let's try some more search queries on the product catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2256368a",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_search(\"suggest something for 5 year old\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3d246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_search(\"suggest something for halloween\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1396f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_search(\"suggest something for home office\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2393a33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_search(\"suggest something for december\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdef498",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_search(\"suggest something for thanksgiving\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab838a1",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this workshop you have learnt how semantic search works in searching through a product catalog for an e-commerce application. \n",
    "\n",
    "### Take aways\n",
    "- Adapt this notebook to experiment with different models available through HuggingFace or Amazon Bedrock such as Anthropic Claude and AI21 Labs Jurassic models.\n",
    "- Change the input dataset and experiment with your organizational data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
